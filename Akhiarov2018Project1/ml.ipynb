{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание Basic code.\n",
    "## По мотивам статьи: 2014 - On the Importance of Text Analysis for Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# load modules\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, vstack\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  # quality measure from paper\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  # basic classifier from paper\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "#import lightgbm as lgb\n",
    "#import catboost as ctb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = os.listdir('data/8K')\n",
    "\n",
    "tickers_freq = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    f = open('data/8K/'+ticker, 'r')\n",
    "    f_lines = f.readlines()\n",
    "    f.close()\n",
    "    raw_8k_reports = pd.Series(' '.join(f_lines).split('</DOCUMENT>')[:-1])\n",
    "    tickers_freq[ticker] = raw_8k_reports.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195140"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_freq_series.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JPM      835\n",
       "NWSA     717\n",
       "C        513\n",
       "CHK      499\n",
       "EXC      480\n",
       "ADS      463\n",
       "LH       451\n",
       "WFC      427\n",
       "CLF      420\n",
       "OKE      419\n",
       "XEL      401\n",
       "PCG      364\n",
       "SSI      359\n",
       "SWN      346\n",
       "TDW      343\n",
       "MET      334\n",
       "IRC      333\n",
       "F        332\n",
       "SLXP     326\n",
       "ENDP     324\n",
       "ATW      321\n",
       "COF      318\n",
       "DO       313\n",
       "BAC      311\n",
       "PNC      309\n",
       "CAT      308\n",
       "WMB      305\n",
       "CAKE     304\n",
       "DTE      303\n",
       "CMS      303\n",
       "        ... \n",
       "PSX       10\n",
       "ETN        8\n",
       "ZION       0\n",
       "MOG.A      0\n",
       "BIO        0\n",
       "DST        0\n",
       "WPI        0\n",
       "PCS        0\n",
       "HELE       0\n",
       "KFT        0\n",
       "NOG        0\n",
       "BRE        0\n",
       "VAC        0\n",
       "FSS        0\n",
       "BRK.B      0\n",
       "GKSR       0\n",
       "WXS        0\n",
       "CENTA      0\n",
       "JW.A       0\n",
       "WFR        0\n",
       "AIN        0\n",
       "HUB.B      0\n",
       "PPL        0\n",
       "IQNT       0\n",
       "OYOG       0\n",
       "SBNY       0\n",
       "VVI        0\n",
       "BF.B       0\n",
       "MHP        0\n",
       "BBCN       0\n",
       "Length: 1500, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_freq_series = pd.Series(tickers_freq)\n",
    "tickers_freq_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b4c8167a72a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbasdir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ko'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m55\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#pd.DataFrame(basdir.items())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasdir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#pd.DataFrame.from_dict(basdir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[0;32m    421\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "\n",
    "basdir['ok'] = 5\n",
    "basdir['ko'] = 55\n",
    "#pd.DataFrame(basdir.items())\n",
    "pd.DataFrame(basdir.items())\n",
    "#pd.DataFrame.from_dict(basdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 of 12 | ticker: AAPL\n",
      "iteration 2 of 12 | ticker: ADBE\n",
      "iteration 3 of 12 | ticker: AMZN\n",
      "iteration 4 of 12 | ticker: GOOG\n",
      "iteration 5 of 12 | ticker: HPQ\n",
      "iteration 6 of 12 | ticker: IBM\n",
      "iteration 7 of 12 | ticker: INTC\n",
      "iteration 8 of 12 | ticker: MSFT\n",
      "iteration 9 of 12 | ticker: NVDA\n",
      "iteration 10 of 12 | ticker: JPM\n",
      "iteration 11 of 12 | ticker: NWSA\n",
      "iteration 12 of 12 | ticker: C\n",
      "finished. time elapsed: 136.77 sec\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "# tickers for {Apple, Adobe, Amazon, Google, HP, IBM, Intel, MicroSoft, NVidia}\n",
    "tickers = ['AAPL', 'ADBE', 'AMZN', 'GOOG', 'HPQ', 'IBM', 'INTC', 'MSFT', 'NVDA', 'JPM', 'NWSA', 'C']\n",
    "#tickers = os.listdir('data/8K')\n",
    "sp500_ticker = 'gspc' # S&P500 ticker from paper\n",
    "\n",
    "reports_dataset = pd.DataFrame(columns=['ticker', 'date', 'time', 'text', 'movement', 'movement_normalized', 'label'])\n",
    "\n",
    "for iter_, ticker in enumerate(tickers):\n",
    "    ############################################\n",
    "    ################## PART 1 ##################\n",
    "    ############################################\n",
    "    \n",
    "    print('iteration %i of %i | ticker: %s' % (iter_+1, len(tickers), ticker))\n",
    "    \n",
    "    # load data\n",
    "    \n",
    "    # 1. stock quotes\n",
    "    price = pd.read_csv('data/price_history/'+ticker+'.csv')\n",
    "    price = price[price['Date'] > '2001-12-31']\n",
    "    price = price.sort_values('Date').reset_index(drop=True)\n",
    "    sp500 = pd.read_csv('data/price_history/'+sp500_ticker+'.csv')\n",
    "    sp500 = sp500[sp500['Date'] > '2001-12-31']\n",
    "    sp500 = sp500.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # 2. 8K reports\n",
    "    f = open('data/8K/'+ticker, 'r')\n",
    "    f_lines = f.readlines()\n",
    "    f.close()\n",
    "    raw_8k_reports = pd.Series(' '.join(f_lines).split('</DOCUMENT>')[:-1])\n",
    "\n",
    "    def transform_8k_report_to_dataframe(report):\n",
    "        # transform 8k report to pd.DataFrame row\n",
    "        #\n",
    "        # report: string\n",
    "        # result: pd.DataFrame\n",
    "\n",
    "        result = pd.DataFrame(columns=['ticker', 'date', 'time', 'text'], index=[0])\n",
    "\n",
    "        result['ticker'] = report.split('FILE:')[1].split('/')[0]\n",
    "\n",
    "        datetime_ = report.split('TIME:')[1].split('\\n')[0]\n",
    "        datetime_ = datetime.datetime.strptime(datetime_, '%Y%m%d%H%M%S')\n",
    "        result['date'] = str(datetime_.date())  # date in format 'yyyy-mm-dd'\n",
    "        result['time'] = str(datetime_.time())  # time in format 'hh:mm:ss'\n",
    "\n",
    "        # Leave only the part of text\n",
    "        text = report.split('ITEM:')[-1]\n",
    "        # Delete unnecessary sentences\n",
    "        text = text.replace('QuickLinks', '').replace('Click here to rapidly navigate through this document', '')\n",
    "        # Delete '\\n' & etc. Leave out only text of report\n",
    "        text = ' '.join(text.split())\n",
    "        result['text'] = text\n",
    "\n",
    "        return result\n",
    "\n",
    "    reports = pd.DataFrame(columns=[])\n",
    "    for report in raw_8k_reports:\n",
    "        row = transform_8k_report_to_dataframe(report)\n",
    "        reports = pd.concat([reports, row], axis=0)\n",
    "    reports.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    del f_lines, raw_8k_reports, report\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    ################## PART 2 ##################\n",
    "    ############################################\n",
    "    \n",
    "    # create binary markup {MOVE, STAY} for price data\n",
    "    # aggregate UP and DOWN labels to MOVE label\n",
    "\n",
    "    price_movement = pd.DataFrame(columns=['date', 'movement', 'movement_normalized', 'label'])\n",
    "\n",
    "    # i = row num, j = row values\n",
    "    for i, j in price.iloc[:-1,:].iterrows():\n",
    "        row = pd.DataFrame(columns=['date', 'movement', 'movement_normalized', 'label'], index=[0])\n",
    "        row['date'] = j['Date']\n",
    "\n",
    "        column_next = 'Open'  # value from paper\n",
    "        column_prev = 'Close'  # value from paper\n",
    "        price_change = (price.loc[i+1, column_next] - price.loc[i, column_prev]) / price.loc[i, column_prev]\n",
    "        sp500_change = (sp500.loc[i+1, column_next] - sp500.loc[i, column_prev]) / sp500.loc[i, column_prev]\n",
    "        row['movement'] = price_change\n",
    "\n",
    "        price_change_normalized = price_change - sp500_change  # price_change normalization, described in paper\n",
    "        row['movement_normalized'] = price_change_normalized\n",
    "\n",
    "        if price_change_normalized >= 0.01: # value from paper\n",
    "            row['label'] = 'MOVE'  # price movement: UP\n",
    "        elif price_change_normalized <= -0.01: # value from paper\n",
    "            row['label'] = 'MOVE'  # price movement: DOWN\n",
    "        else:\n",
    "            row['label'] = 'STAY'  # price movement: STAY\n",
    "            \n",
    "        #le = LabelEncoder()\n",
    "        #row['label'] = le.fit(['UP', 'DOWN', 'STAY']).transform(row['label'])\n",
    "\n",
    "        price_movement = pd.concat([price_movement, row], axis=0)\n",
    "\n",
    "    price_movement.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    del price, sp500\n",
    "    \n",
    "    # merge stock quotes and text\n",
    "\n",
    "    reports = pd.merge(reports, price_movement, on='date', how='left')\n",
    "    reports.dropna(axis=0, inplace=True)\n",
    "\n",
    "    del price_movement\n",
    "    \n",
    "    # combine tickers\n",
    "    \n",
    "    reports_dataset = pd.concat([reports_dataset, reports], axis=0)\n",
    "    \n",
    "    del reports\n",
    "\n",
    "reports_dataset.reset_index(drop=True, inplace=True)\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>movement</th>\n",
       "      <th>movement_normalized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2002-08-02</td>\n",
       "      <td>18:59:57</td>\n",
       "      <td>Financial statements and exhibits -- Items 1 t...</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>16:47:30</td>\n",
       "      <td>Financial statements and exhibits -- Items 1 t...</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2003-03-20</td>\n",
       "      <td>19:36:01</td>\n",
       "      <td>Financial statements and exhibits Items 1 thro...</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2003-04-16</td>\n",
       "      <td>16:21:56</td>\n",
       "      <td>Regulation FD Disclosure -- Item 7. Financial ...</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2003-07-16</td>\n",
       "      <td>16:04:06</td>\n",
       "      <td>Regulation FD Disclosure Item 7. Financial Sta...</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2003-10-15</td>\n",
       "      <td>16:29:50</td>\n",
       "      <td>Financial statements and exhibits Item 7. Fina...</td>\n",
       "      <td>-0.041096</td>\n",
       "      <td>-0.041096</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2004-01-14</td>\n",
       "      <td>16:30:52</td>\n",
       "      <td>Financial statements and exhibits Item 7. Fina...</td>\n",
       "      <td>-0.053306</td>\n",
       "      <td>-0.053306</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2004-04-14</td>\n",
       "      <td>16:27:33</td>\n",
       "      <td>Financial statements and exhibits Item 7. Fina...</td>\n",
       "      <td>0.081832</td>\n",
       "      <td>0.081832</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2004-07-14</td>\n",
       "      <td>16:29:34</td>\n",
       "      <td>Financial statements and exhibits Item 7. Fina...</td>\n",
       "      <td>0.104124</td>\n",
       "      <td>0.104124</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2004-10-13</td>\n",
       "      <td>16:31:13</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.086541</td>\n",
       "      <td>0.086541</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-01-11</td>\n",
       "      <td>13:39:42</td>\n",
       "      <td>Results of Operations and Financial Condition ...</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-01-12</td>\n",
       "      <td>16:26:42</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.126031</td>\n",
       "      <td>0.126031</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-02-11</td>\n",
       "      <td>09:00:56</td>\n",
       "      <td>Other Events Check the appropriate box below i...</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-03-02</td>\n",
       "      <td>17:04:51</td>\n",
       "      <td>Amendments to Articles of Incorporation or Byl...</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>16:28:53</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-04-25</td>\n",
       "      <td>18:48:38</td>\n",
       "      <td>Entry into a Material Definitive Agreement Che...</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-06-06</td>\n",
       "      <td>13:25:04</td>\n",
       "      <td>Other Events Check the appropriate box below i...</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-07-13</td>\n",
       "      <td>16:28:45</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-08-15</td>\n",
       "      <td>17:00:19</td>\n",
       "      <td>Entry into a Material Definitive Agreement Che...</td>\n",
       "      <td>-0.006082</td>\n",
       "      <td>-0.006082</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>16:59:43</td>\n",
       "      <td>Entry into a Material Definitive Agreement Che...</td>\n",
       "      <td>-0.010275</td>\n",
       "      <td>-0.010275</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>16:28:09</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.056988</td>\n",
       "      <td>-0.056988</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-10-14</td>\n",
       "      <td>16:49:24</td>\n",
       "      <td>Departure of Directors or Principal Officers; ...</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>20:09:40</td>\n",
       "      <td>Entry into a Material Definitive Agreement Che...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>12:11:22</td>\n",
       "      <td>Results of Operations and Financial Condition ...</td>\n",
       "      <td>0.036854</td>\n",
       "      <td>0.036831</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-01-18</td>\n",
       "      <td>16:28:38</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-04-19</td>\n",
       "      <td>16:29:16</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>0.058797</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-04-21</td>\n",
       "      <td>16:40:55</td>\n",
       "      <td>Entry into a Material Definitive Agreement Che...</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-07-19</td>\n",
       "      <td>16:29:23</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-08-03</td>\n",
       "      <td>21:52:48</td>\n",
       "      <td>Financial Statements and Exhibits UNITED STATE...</td>\n",
       "      <td>-0.036499</td>\n",
       "      <td>-0.036492</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2006-08-11</td>\n",
       "      <td>16:41:26</td>\n",
       "      <td>Financial Statements and Exhibits UNITED STATE...</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2009-04-22</td>\n",
       "      <td>16:29:53</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2009-06-02</td>\n",
       "      <td>17:02:46</td>\n",
       "      <td>Amendments to Articles of Incorporation or Byl...</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2009-07-21</td>\n",
       "      <td>16:29:42</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.042686</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>21:43:42</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>-0.009013</td>\n",
       "      <td>-0.007796</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2009-10-19</td>\n",
       "      <td>16:29:43</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.056568</td>\n",
       "      <td>0.055903</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>16:27:45</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>16:31:42</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>16:39:35</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>-0.005384</td>\n",
       "      <td>-0.004114</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-04-20</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.058097</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-07-20</td>\n",
       "      <td>16:33:28</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>0.049460</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>16:29:51</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.045912</td>\n",
       "      <td>-0.040788</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>17:27:46</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>06:19:03</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>0.022604</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>16:30:27</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.022604</td>\n",
       "      <td>0.022990</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-02-24</td>\n",
       "      <td>16:33:38</td>\n",
       "      <td>Submission of Matters to a Vote of Security Ho...</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-04-20</td>\n",
       "      <td>16:30:30</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>0.034611</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-06-15</td>\n",
       "      <td>17:12:37</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-07-19</td>\n",
       "      <td>16:29:56</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.051134</td>\n",
       "      <td>0.049680</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-08-26</td>\n",
       "      <td>17:07:55</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-10-06</td>\n",
       "      <td>06:29:36</td>\n",
       "      <td>Other Events Check the appropriate box below i...</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>-0.004265</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-10-18</td>\n",
       "      <td>16:31:02</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.049474</td>\n",
       "      <td>-0.047907</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2011-11-16</td>\n",
       "      <td>06:04:08</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>-0.002053</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-01-24</td>\n",
       "      <td>16:30:34</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.080945</td>\n",
       "      <td>0.081135</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-02-27</td>\n",
       "      <td>17:01:04</td>\n",
       "      <td>Submission of Matters to a Vote of Security Ho...</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-04-24</td>\n",
       "      <td>16:30:55</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>17:16:08</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-06-28</td>\n",
       "      <td>16:31:24</td>\n",
       "      <td>Departure of Directors or Certain Officers; El...</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>16:31:04</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.044032</td>\n",
       "      <td>-0.044062</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2012-10-25</td>\n",
       "      <td>16:31:16</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>STAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>16:31:00</td>\n",
       "      <td>Financial Statements and Exhibits Check the ap...</td>\n",
       "      <td>-0.105076</td>\n",
       "      <td>-0.105076</td>\n",
       "      <td>MOVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker        date      time  \\\n",
       "0    AAPL  2002-08-02  18:59:57   \n",
       "1    AAPL  2002-08-13  16:47:30   \n",
       "2    AAPL  2003-03-20  19:36:01   \n",
       "3    AAPL  2003-04-16  16:21:56   \n",
       "4    AAPL  2003-07-16  16:04:06   \n",
       "5    AAPL  2003-10-15  16:29:50   \n",
       "6    AAPL  2004-01-14  16:30:52   \n",
       "7    AAPL  2004-04-14  16:27:33   \n",
       "8    AAPL  2004-07-14  16:29:34   \n",
       "9    AAPL  2004-10-13  16:31:13   \n",
       "10   AAPL  2005-01-11  13:39:42   \n",
       "11   AAPL  2005-01-12  16:26:42   \n",
       "12   AAPL  2005-02-11  09:00:56   \n",
       "13   AAPL  2005-03-02  17:04:51   \n",
       "14   AAPL  2005-04-13  16:28:53   \n",
       "15   AAPL  2005-04-25  18:48:38   \n",
       "16   AAPL  2005-06-06  13:25:04   \n",
       "17   AAPL  2005-07-13  16:28:45   \n",
       "18   AAPL  2005-08-15  17:00:19   \n",
       "19   AAPL  2005-08-26  16:59:43   \n",
       "20   AAPL  2005-10-11  16:28:09   \n",
       "21   AAPL  2005-10-14  16:49:24   \n",
       "22   AAPL  2005-12-16  20:09:40   \n",
       "23   AAPL  2006-01-10  12:11:22   \n",
       "24   AAPL  2006-01-18  16:28:38   \n",
       "25   AAPL  2006-04-19  16:29:16   \n",
       "26   AAPL  2006-04-21  16:40:55   \n",
       "27   AAPL  2006-07-19  16:29:23   \n",
       "28   AAPL  2006-08-03  21:52:48   \n",
       "29   AAPL  2006-08-11  16:41:26   \n",
       "..    ...         ...       ...   \n",
       "53   AAPL  2009-04-22  16:29:53   \n",
       "54   AAPL  2009-06-02  17:02:46   \n",
       "55   AAPL  2009-07-21  16:29:42   \n",
       "56   AAPL  2009-08-03  21:43:42   \n",
       "57   AAPL  2009-10-19  16:29:43   \n",
       "58   AAPL  2010-01-25  16:27:45   \n",
       "59   AAPL  2010-03-01  16:31:42   \n",
       "60   AAPL  2010-03-12  16:39:35   \n",
       "61   AAPL  2010-04-20  16:30:00   \n",
       "62   AAPL  2010-07-20  16:33:28   \n",
       "63   AAPL  2010-10-18  16:29:51   \n",
       "64   AAPL  2010-11-17  17:27:46   \n",
       "65   AAPL  2011-01-18  06:19:03   \n",
       "66   AAPL  2011-01-18  16:30:27   \n",
       "67   AAPL  2011-02-24  16:33:38   \n",
       "68   AAPL  2011-04-20  16:30:30   \n",
       "69   AAPL  2011-06-15  17:12:37   \n",
       "70   AAPL  2011-07-19  16:29:56   \n",
       "71   AAPL  2011-08-26  17:07:55   \n",
       "72   AAPL  2011-10-06  06:29:36   \n",
       "73   AAPL  2011-10-18  16:31:02   \n",
       "74   AAPL  2011-11-16  06:04:08   \n",
       "75   AAPL  2012-01-24  16:30:34   \n",
       "76   AAPL  2012-02-27  17:01:04   \n",
       "77   AAPL  2012-04-24  16:30:55   \n",
       "78   AAPL  2012-05-24  17:16:08   \n",
       "79   AAPL  2012-06-28  16:31:24   \n",
       "80   AAPL  2012-07-24  16:31:04   \n",
       "81   AAPL  2012-10-25  16:31:16   \n",
       "82   AAPL  2013-01-23  16:31:00   \n",
       "\n",
       "                                                 text  movement  \\\n",
       "0   Financial statements and exhibits -- Items 1 t...  0.004152   \n",
       "1   Financial statements and exhibits -- Items 1 t...  0.005483   \n",
       "2   Financial statements and exhibits Items 1 thro...  0.012072   \n",
       "3   Regulation FD Disclosure -- Item 7. Financial ... -0.003021   \n",
       "4   Regulation FD Disclosure Item 7. Financial Sta...  0.016105   \n",
       "5   Financial statements and exhibits Item 7. Fina... -0.041096   \n",
       "6   Financial statements and exhibits Item 7. Fina... -0.053306   \n",
       "7   Financial statements and exhibits Item 7. Fina...  0.081832   \n",
       "8   Financial statements and exhibits Item 7. Fina...  0.104124   \n",
       "9   Financial Statements and Exhibits Check the ap...  0.086541   \n",
       "10  Results of Operations and Financial Condition ...  0.013786   \n",
       "11  Financial Statements and Exhibits Check the ap...  0.126031   \n",
       "12  Other Events Check the appropriate box below i...  0.018717   \n",
       "13  Amendments to Articles of Incorporation or Byl...  0.005666   \n",
       "14  Financial Statements and Exhibits Check the ap... -0.054337   \n",
       "15  Entry into a Material Definitive Agreement Che... -0.005408   \n",
       "16  Other Events Check the appropriate box below i... -0.008439   \n",
       "17  Financial Statements and Exhibits Check the ap...  0.063625   \n",
       "18  Entry into a Material Definitive Agreement Che... -0.006082   \n",
       "19  Entry into a Material Definitive Agreement Che... -0.010275   \n",
       "20  Financial Statements and Exhibits Check the ap... -0.056988   \n",
       "21  Departure of Directors or Principal Officers; ... -0.000370   \n",
       "22  Entry into a Material Definitive Agreement Che...  0.000000   \n",
       "23  Results of Operations and Financial Condition ...  0.036854   \n",
       "24  Financial Statements and Exhibits Check the ap... -0.015032   \n",
       "25  Financial Statements and Exhibits Check the ap...  0.058797   \n",
       "26  Entry into a Material Definitive Agreement Che... -0.002834   \n",
       "27  Financial Statements and Exhibits Check the ap...  0.126802   \n",
       "28  Financial Statements and Exhibits UNITED STATE... -0.036499   \n",
       "29  Financial Statements and Exhibits UNITED STATE...  0.006284   \n",
       "..                                                ...       ...   \n",
       "53  Financial Statements and Exhibits Check the ap...  0.042054   \n",
       "54  Amendments to Articles of Incorporation or Byl...  0.003656   \n",
       "55  Financial Statements and Exhibits Check the ap...  0.041449   \n",
       "56  Departure of Directors or Certain Officers; El... -0.009013   \n",
       "57  Financial Statements and Exhibits Check the ap...  0.056568   \n",
       "58  Financial Statements and Exhibits Check the ap...  0.014182   \n",
       "59  Financial Statements and Exhibits Check the ap...  0.004498   \n",
       "60  Departure of Directors or Certain Officers; El... -0.005384   \n",
       "61  Financial Statements and Exhibits Check the ap...  0.058097   \n",
       "62  Financial Statements and Exhibits Check the ap...  0.052404   \n",
       "63  Financial Statements and Exhibits Check the ap... -0.045912   \n",
       "64  Financial Statements and Exhibits Check the ap...  0.015641   \n",
       "65  Departure of Directors or Certain Officers; El...  0.022604   \n",
       "66  Financial Statements and Exhibits Check the ap...  0.022604   \n",
       "67  Submission of Matters to a Vote of Security Ho...  0.006941   \n",
       "68  Financial Statements and Exhibits Check the ap...  0.036769   \n",
       "69  Departure of Directors or Certain Officers; El...  0.000459   \n",
       "70  Financial Statements and Exhibits Check the ap...  0.051134   \n",
       "71  Departure of Directors or Certain Officers; El...  0.011992   \n",
       "72  Other Events Check the appropriate box below i... -0.004213   \n",
       "73  Financial Statements and Exhibits Check the ap... -0.049474   \n",
       "74  Departure of Directors or Certain Officers; El... -0.002053   \n",
       "75  Financial Statements and Exhibits Check the ap...  0.080945   \n",
       "76  Submission of Matters to a Vote of Security Ho...  0.004184   \n",
       "77  Financial Statements and Exhibits Check the ap...  0.098808   \n",
       "78  Departure of Directors or Certain Officers; El... -0.001291   \n",
       "79  Departure of Directors or Certain Officers; El...  0.015728   \n",
       "80  Financial Statements and Exhibits Check the ap... -0.044032   \n",
       "81  Financial Statements and Exhibits Check the ap... -0.000180   \n",
       "82  Financial Statements and Exhibits Check the ap... -0.105076   \n",
       "\n",
       "    movement_normalized label  \n",
       "0              0.004152  STAY  \n",
       "1              0.005483  STAY  \n",
       "2              0.011878  MOVE  \n",
       "3             -0.003021  STAY  \n",
       "4              0.016195  MOVE  \n",
       "5             -0.041096  MOVE  \n",
       "6             -0.053306  MOVE  \n",
       "7              0.081832  MOVE  \n",
       "8              0.104124  MOVE  \n",
       "9              0.086541  MOVE  \n",
       "10             0.013786  MOVE  \n",
       "11             0.126031  MOVE  \n",
       "12             0.018717  MOVE  \n",
       "13             0.005666  STAY  \n",
       "14            -0.054337  MOVE  \n",
       "15            -0.005408  STAY  \n",
       "16            -0.008439  STAY  \n",
       "17             0.063625  MOVE  \n",
       "18            -0.006082  STAY  \n",
       "19            -0.010275  MOVE  \n",
       "20            -0.056988  MOVE  \n",
       "21            -0.000370  STAY  \n",
       "22             0.000000  STAY  \n",
       "23             0.036831  MOVE  \n",
       "24            -0.015032  MOVE  \n",
       "25             0.058797  MOVE  \n",
       "26            -0.002834  STAY  \n",
       "27             0.126802  MOVE  \n",
       "28            -0.036492  MOVE  \n",
       "29             0.006340  STAY  \n",
       "..                  ...   ...  \n",
       "53             0.040786  MOVE  \n",
       "54             0.006017  STAY  \n",
       "55             0.042686  MOVE  \n",
       "56            -0.007796  STAY  \n",
       "57             0.055903  MOVE  \n",
       "58             0.015076  MOVE  \n",
       "59             0.003333  STAY  \n",
       "60            -0.004114  STAY  \n",
       "61             0.058106  MOVE  \n",
       "62             0.049460  MOVE  \n",
       "63            -0.040788  MOVE  \n",
       "64             0.011262  MOVE  \n",
       "65             0.022990  MOVE  \n",
       "66             0.022990  MOVE  \n",
       "67             0.005992  STAY  \n",
       "68             0.034611  MOVE  \n",
       "69             0.000372  STAY  \n",
       "70             0.049680  MOVE  \n",
       "71             0.011049  MOVE  \n",
       "72            -0.004265  STAY  \n",
       "73            -0.047907  MOVE  \n",
       "74            -0.001770  STAY  \n",
       "75             0.081135  MOVE  \n",
       "76             0.004206  STAY  \n",
       "77             0.098706  MOVE  \n",
       "78            -0.001390  STAY  \n",
       "79             0.014915  MOVE  \n",
       "80            -0.044062  MOVE  \n",
       "81            -0.000180  STAY  \n",
       "82            -0.105076  MOVE  \n",
       "\n",
       "[83 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_dataset[reports_dataset['ticker'] == 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class encoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "reports_dataset['label'] = le.fit_transform(reports_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 83\n",
      "ADBE 102\n",
      "AMZN 98\n",
      "GOOG 110\n",
      "HPQ 159\n",
      "IBM 253\n",
      "INTC 188\n",
      "MSFT 133\n",
      "NVDA 103\n"
     ]
    }
   ],
   "source": [
    "for iter_, ticker in enumerate(tickers):\n",
    "    print(ticker, reports_dataset[reports_dataset['ticker'] == ticker].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "################## PART 3 ##################\n",
    "############################################\n",
    "\n",
    "# split data to train / validation / test\n",
    "\n",
    "# features\n",
    "train_start, train_end = '2001-12-31', '2008-12-31'  # train period from paper\n",
    "x_train = reports_dataset[(train_start < reports_dataset['date']) & (reports_dataset['date'] <= train_end)]['text']\n",
    "\n",
    "val_start, val_end = '2008-12-31', '2010-12-31'  # validation period from paper\n",
    "x_val = reports_dataset[(val_start < reports_dataset['date']) & (reports_dataset['date'] <= val_end)]['text']\n",
    "\n",
    "test_start, test_end = '2010-12-31', '2012-12-31'  # test period from paper\n",
    "x_test = reports_dataset[(test_start < reports_dataset['date']) & (reports_dataset['date'] <= test_end)]['text']\n",
    "\n",
    "# target variable\n",
    "y_train = reports_dataset[(train_start < reports_dataset['date']) & (reports_dataset['date'] <= train_end)]['label']\n",
    "y_val = reports_dataset[(val_start < reports_dataset['date']) & (reports_dataset['date'] <= val_end)]['label']\n",
    "y_test = reports_dataset[(test_start < reports_dataset['date']) & (reports_dataset['date'] <= test_end)]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set len: 2056\n",
      "Val set len: 396\n",
      "Test set len: 707\n"
     ]
    }
   ],
   "source": [
    "print('Train set len:', x_train.shape[0])\n",
    "print('Val set len:', x_val.shape[0])\n",
    "print('Test set len:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation size\n",
    "cv_parts = 3\n",
    "cv_size = len(x_train) // cv_parts\n",
    "\n",
    "x_train_1 = x_train[0 : int(cv_size * 0.6)]\n",
    "x_train_2 = x_train[cv_size : cv_size + int(cv_size * 0.6)]\n",
    "x_train_3 = x_train[2 * cv_size : 2 * cv_size + int(cv_size * 0.6)]\n",
    "\n",
    "x_test_1 = x_train[int(cv_size * 0.6) : cv_size]\n",
    "x_test_2 = x_train[cv_size + int(cv_size * 0.6) : 2 * cv_size]\n",
    "x_test_3 = x_train[2 * cv_size + int(cv_size * 0.6) : ]\n",
    "\n",
    "y_train_1 = y_train[0 : int(cv_size * 0.6)]\n",
    "y_train_2 = y_train[cv_size : cv_size + int(cv_size * 0.6)]\n",
    "y_train_3 = y_train[2 * cv_size : 2 * cv_size + int(cv_size * 0.6)]\n",
    "\n",
    "y_test_1 = y_train[int(cv_size * 0.6) : cv_size]\n",
    "y_test_2 = y_train[cv_size + int(cv_size * 0.6) : 2 * cv_size]\n",
    "y_test_3 = y_train[2 * cv_size + int(cv_size * 0.6) : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Financial statements and exhibits -- Items 1 t...\n",
       "1       Financial statements and exhibits -- Items 1 t...\n",
       "2       Financial statements and exhibits Items 1 thro...\n",
       "3       Regulation FD Disclosure -- Item 7. Financial ...\n",
       "4       Regulation FD Disclosure Item 7. Financial Sta...\n",
       "5       Financial statements and exhibits Item 7. Fina...\n",
       "6       Financial statements and exhibits Item 7. Fina...\n",
       "7       Financial statements and exhibits Item 7. Fina...\n",
       "8       Financial statements and exhibits Item 7. Fina...\n",
       "9       Financial Statements and Exhibits Check the ap...\n",
       "10      Results of Operations and Financial Condition ...\n",
       "11      Financial Statements and Exhibits Check the ap...\n",
       "12      Other Events Check the appropriate box below i...\n",
       "13      Amendments to Articles of Incorporation or Byl...\n",
       "14      Financial Statements and Exhibits Check the ap...\n",
       "15      Entry into a Material Definitive Agreement Che...\n",
       "16      Other Events Check the appropriate box below i...\n",
       "17      Financial Statements and Exhibits Check the ap...\n",
       "18      Entry into a Material Definitive Agreement Che...\n",
       "19      Entry into a Material Definitive Agreement Che...\n",
       "20      Financial Statements and Exhibits Check the ap...\n",
       "21      Departure of Directors or Principal Officers; ...\n",
       "22      Entry into a Material Definitive Agreement Che...\n",
       "23      Results of Operations and Financial Condition ...\n",
       "24      Financial Statements and Exhibits Check the ap...\n",
       "25      Financial Statements and Exhibits Check the ap...\n",
       "26      Entry into a Material Definitive Agreement Che...\n",
       "27      Financial Statements and Exhibits Check the ap...\n",
       "28      Financial Statements and Exhibits UNITED STATE...\n",
       "29      Financial Statements and Exhibits UNITED STATE...\n",
       "                              ...                        \n",
       "1166    Other Events Check the appropriate box below i...\n",
       "1167    Completion of Acquisition or Disposition of As...\n",
       "1168    Financial Statements and Exhibits Check the ap...\n",
       "1169    Departure of Directors or Principal Officers; ...\n",
       "1170    Departure of Directors or Principal Officers; ...\n",
       "1171    Financial Statements and Exhibits Check the ap...\n",
       "1172    Other Events Check the appropriate box below i...\n",
       "1173    Other Events Check the appropriate box below i...\n",
       "1174    Other Events Check the appropriate box below i...\n",
       "1175    Other Events Check the appropriate box below i...\n",
       "1176    Financial Statements and Exhibits Check the ap...\n",
       "1177    Results of Operations and Financial Condition ...\n",
       "1178    Other Events Check the appropriate box below i...\n",
       "1179    Departure of Directors or Principal Officers; ...\n",
       "1180    Other Events Check the appropriate box below i...\n",
       "1181    Financial Statements and Exhibits Check the ap...\n",
       "1182    Entry into a Material Definitive Agreement Che...\n",
       "1183    Financial Statements and Exhibits Check the ap...\n",
       "1184    Financial Statements and Exhibits Check the ap...\n",
       "1185    Financial Statements and Exhibits Check the ap...\n",
       "1186    Financial Statements and Exhibits Check the ap...\n",
       "1187    Other Events Check the appropriate box below i...\n",
       "1188    Financial Statements and Exhibits Check the ap...\n",
       "1189    Departure of Directors or Principal Officers; ...\n",
       "1190    Departure of Directors or Principal Officers; ...\n",
       "1191    Other Events Check the appropriate box below i...\n",
       "1192    Other Events Check the appropriate box below i...\n",
       "1193    Other Events Check the appropriate box below i...\n",
       "1194    Financial Statements and Exhibits Check the ap...\n",
       "1195    Other Events Check the appropriate box below i...\n",
       "Name: text, Length: 747, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams created\n",
      "nmf 50 features created\n",
      "nmf 100 features created\n",
      "nmf 200 features created\n",
      "finished. time elapsed: 254.26 sec\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "################## PART 4 ##################\n",
    "############################################\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "# create features\n",
    "\n",
    "# 1. Unigrams\n",
    "# example: vectorizer_params = {}\n",
    "#          vectorizer = Vectorizer(**vectorizer_params)\n",
    "#          unigrams_train_features = vectorizer.fit_transform(x_train)\n",
    "# ...\n",
    "#vectorizer = CountVectorizer()\n",
    "#min_df=5\n",
    "#max_df=0.5\n",
    "vectorizer = TfidfVectorizer(min_df=3, max_df=0.95)\n",
    "unigrams_train_features = vectorizer.fit_transform(x_train)\n",
    "unigrams_val_features = vectorizer.transform(x_val)\n",
    "unigrams_test_features = vectorizer.transform(x_test)\n",
    "print('unigrams created')\n",
    "# To check feature names: vectorizer.get_feature_names()\n",
    "\n",
    "# 2. NMF vector for 50, 100, and 200 components\n",
    "# example: nmf_params = {}\n",
    "#          nmf = NMF(**nmf_params)\n",
    "#          nmf_train_features = nmf.fit_transform(unigrams_train_features)\n",
    "\n",
    "nmf50 = NMF(50)\n",
    "nmf_50_train_features = nmf50.fit_transform(unigrams_train_features)\n",
    "nmf_50_val_features = nmf50.transform(unigrams_val_features)\n",
    "nmf_50_test_features = nmf50.transform(unigrams_test_features)\n",
    "print('nmf 50 features created')\n",
    "# To check matrix shape: nmf_50_train_features.shape\n",
    "\n",
    "nmf100 = NMF(100)\n",
    "nmf_100_train_features = nmf100.fit_transform(unigrams_train_features)\n",
    "nmf_100_val_features = nmf100.transform(unigrams_val_features)\n",
    "nmf_100_test_features = nmf100.transform(unigrams_test_features)\n",
    "print('nmf 100 features created')\n",
    "\n",
    "nmf200 = NMF(200)\n",
    "nmf_200_train_features = nmf200.fit_transform(unigrams_train_features)\n",
    "nmf_200_val_features = nmf200.transform(unigrams_val_features)\n",
    "nmf_200_test_features = nmf200.transform(unigrams_test_features)\n",
    "print('nmf 200 features created')\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2056, 12811)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x12811 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2145 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_train_features[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2056, 50)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_50_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 50)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "# create features\n",
    "\n",
    "# CV 1\n",
    "\n",
    "vectorizer_cv_1 = TfidfVectorizer(min_df=3, max_df=0.95)\n",
    "unigrams_train_features_cv_1 = vectorizer_cv_1.fit_transform(x_train_1)\n",
    "unigrams_test_features_cv_1 = vectorizer_cv_1.transform(x_test_1)\n",
    "print('unigrams created')\n",
    "\n",
    "nmf50_cv_1 = NMF(50)\n",
    "nmf_50_train_features_cv_1 = nmf50_cv_1.fit_transform(unigrams_train_features_cv_1)\n",
    "nmf_50_test_features_cv_1 = nmf50_cv_1.transform(unigrams_test_features_cv_1)\n",
    "print('nmf 50 features created')\n",
    "\n",
    "nmf100_cv_1 = NMF(100)\n",
    "nmf_100_train_features_cv_1 = nmf100_cv_1.fit_transform(unigrams_train_features_cv_1)\n",
    "nmf_100_test_features_cv_1 = nmf100_cv_1.transform(unigrams_test_features_cv_1)\n",
    "print('nmf 100 features created')\n",
    "\n",
    "nmf200_cv_1 = NMF(200)\n",
    "nmf_200_train_features_cv_1 = nmf200_cv_1.fit_transform(unigrams_train_features_cv_1)\n",
    "nmf_200_test_features_cv_1 = nmf200_cv_1.transform(unigrams_test_features_cv_1)\n",
    "print('nmf 200 features created')\n",
    "\n",
    "# CV 2\n",
    "\n",
    "vectorizer_cv_2 = TfidfVectorizer(min_df=3, max_df=0.95)\n",
    "unigrams_train_features_cv_2 = vectorizer_cv_2.fit_transform(x_train_2)\n",
    "unigrams_test_features_cv_2 = vectorizer_cv_2.transform(x_test_2)\n",
    "print('unigrams created')\n",
    "\n",
    "nmf50_cv_2 = NMF(50)\n",
    "nmf_50_train_features_cv_2 = nmf50_cv_2.fit_transform(unigrams_train_features_cv_2)\n",
    "nmf_50_test_features_cv_2 = nmf50_cv_2.transform(unigrams_test_features_cv_2)\n",
    "print('nmf 50 features created')\n",
    "\n",
    "nmf100_cv_2 = NMF(100)\n",
    "nmf_100_train_features_cv_2 = nmf100_cv_2.fit_transform(unigrams_train_features_cv_2)\n",
    "nmf_100_test_features_cv_2 = nmf100_cv_2.transform(unigrams_test_features_cv_2)\n",
    "print('nmf 100 features created')\n",
    "\n",
    "nmf200_cv_2 = NMF(200)\n",
    "nmf_200_train_features_cv_2 = nmf200_cv_2.fit_transform(unigrams_train_features_cv_2)\n",
    "nmf_200_test_features_cv_2 = nmf200_cv_2.transform(unigrams_test_features_cv_2)\n",
    "print('nmf 200 features created')\n",
    "\n",
    "# CV 3\n",
    "\n",
    "vectorizer_cv_3 = TfidfVectorizer(min_df=3, max_df=0.95)\n",
    "unigrams_train_features_cv_3 = vectorizer_cv_3.fit_transform(x_train_3)\n",
    "unigrams_test_features_cv_3 = vectorizer_cv_3.transform(x_test_3)\n",
    "print('unigrams created')\n",
    "\n",
    "nmf50_cv_2 = NMF(50)\n",
    "nmf_50_train_features_cv_2 = nmf50_cv_2.fit_transform(unigrams_train_features_cv_3)\n",
    "nmf_50_test_features_cv_2 = nmf50_cv_2.transform(unigrams_test_features_cv_3)\n",
    "print('nmf 50 features created')\n",
    "\n",
    "nmf100_cv_2 = NMF(100)\n",
    "nmf_100_train_features_cv_2 = nmf100_cv_2.fit_transform(unigrams_train_features_cv_2)\n",
    "nmf_100_test_features_cv_2 = nmf100_cv_2.transform(unigrams_test_features_cv_2)\n",
    "print('nmf 100 features created')\n",
    "\n",
    "nmf200_cv_2 = NMF(200)\n",
    "nmf_200_train_features_cv_2 = nmf200_cv_2.fit_transform(unigrams_train_features_cv_2)\n",
    "nmf_200_test_features_cv_2 = nmf200_cv_2.transform(unigrams_test_features_cv_2)\n",
    "print('nmf 200 features created')\n",
    "\n",
    "\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of top words after Tf-Idf vectorization\n",
    "n_first = 0\n",
    "n_last = 100\n",
    "top_idx = np.ravel(unigrams_train_features.sum(axis=0).argsort(axis=1))[::-1][n_first:n_last] #- top 5\n",
    "top_values = np.ravel(unigrams_train_features.sum(axis=0))[top_idx].tolist()\n",
    "top_words = np.array(vectorizer.get_feature_names())[top_idx].tolist()\n",
    "len(top_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIcAAAKKCAYAAACnPzt/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XuYJGldJ/rvr6dnEJFL0zTIZeihcXBFl1u3WFyOgriCqAzoorCzykHG0SO6uF72gLtn4bC6ort4gTPi4Y46yGVBQZY7O+Cq9GAX4HCXPg0tAyOMTa/MwbPONP2ePzKKyanJqsrqyuqsqvfzeZ58qjLylxFvZEZERn7zjYhqrQUAAACAPu2adwMAAAAAmB/hEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANCx3fNuQJLc4Q53aBdccMG8mwEAAACwYywuLv5da23fWnVbIhy64IILcuTIkXk3AwAAAGDHqKrj09Q5rAwAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCoRlaPH4yl11xNIvHT867KQAAAABT2T3vBuwUi8dP5uIXH871p07nvN27cvklCzm4f8+8mwUAAACwKj2HZuTwsRO5/tTpnG7JDadO5/CxE/NuEgAAAMCahEMzsnBgb87bvSvnVHLu7l1ZOLB33k0CAAAAWJPDymbk4P49ufyShRw+diILB/Y6pAwAAADYFoRDM3Rw/x6hEAAAALCtOKwMAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6Nia4VBVnV9VV1TVx6rqI1X1tGH4s6rqs1X1weH26LHnPKOqjlbVJ6rqkZs5AwAAAACcud1T1JxK8vOttfdX1a2TLFbVO4bHfrO19p/Hi6vq3kmekOSbk9wlyTur6l6tta/MsuEAAAAAbNyaPYdaa9e01t4//H9dko8luesqT7koyataa//YWvtUkqNJHjiLxgIAAAAwW+s651BVXZDk/kmuHAb9dFVdVVUvrao9w7C7JvnM2NOuzoQwqaouraojVXXk2muvXXfDAQAAANi4qcOhqvq6JK9L8rOttS8leUGSeya5X5Jrkjx3qXTC09vNBrT2wtbaodbaoX379q274QAAAABs3FThUFWdm1EwdHlr7fVJ0lr7fGvtK62100lelBsPHbs6yfljT79bks/NrskAAAAAzMo0VyurJC9J8rHW2m+MDb/zWNnjknx4+P+NSZ5QVbeoqnskuTDJ+2bXZAAAAABmZZqrlT0kyY8k+VBVfXAY9ktJnlhV98vokLFPJ/mJJGmtfaSqXpPkoxld6eyprlQGAAAAsDWtGQ611v4sk88j9OZVnvMrSX5lA+0CAAAA4CxY19XKAAAAANhZhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx9YMh6rq/Kq6oqo+VlUfqaqnDcNvX1XvqKpPDn/3DMOrqp5XVUer6qqqesBmzwQAAAAAZ2aankOnkvx8a+2bkiwkeWpV3TvJ05O8q7V2YZJ3DfeT5HuSXDjcLk3ygpm3GgAAAICZWDMcaq1d01p7//D/dUk+luSuSS5K8oqh7BVJHjv8f1GS32sjh5PcrqruPPOWAwAAALBh6zrnUFVdkOT+Sa5McqfW2jXJKEBKcseh7K5JPjP2tKuHYcvHdWlVHamqI9dee+36Ww4AAADAhk0dDlXV1yV5XZKfba19abXSCcPazQa09sLW2qHW2qF9+/ZN2wwAAAAAZmiqcKiqzs0oGLq8tfb6YfDnlw4XG/5+YRh+dZLzx55+tySfm01zAQAAAJilaa5WVklekuRjrbXfGHvojUmeNPz/pCRvGBv+o8NVyxaS/P3S4WcAAAAAbC27p6h5SJIfSfKhqvrgMOyXkjwnyWuq6ilJ/ibJ44fH3pzk0UmOJvmHJE+eaYsBAAAAmJk1w6HW2p9l8nmEkuQRE+pbkqdusF0AAAAAnAXruloZAAAAADuLcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4Jh+Zg8fjJXHbF0SwePznvpgAAAACd2z3vBvRm8fjJXPziw7n+1Omct3tXLr9kIQf375l3swAAAIBO6Tl0lh0+diLXnzqd0y254dTpHD52Yt5NAgAAADomHDrLFg7szXm7d+WcSs7dvSsLB/bOu0kAAABAxxxWdpYd3L8nl1+ykMPHTmThwF6HlAEAAABzJRyag4P79wiFAAAAgC3BYWUAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDH1gyHquqlVfWFqvrw2LBnVdVnq+qDw+3RY489o6qOVtUnquqRm9VwAAAAADZump5DL0/yqAnDf7O1dr/h9uYkqap7J3lCkm8envM7VXXOrBoLAAAAwGytGQ611v40yRenHN9FSV7VWvvH1tqnkhxN8sANtA8AAACATbSRcw79dFVdNRx2tmcYdtcknxmruXoYdjNVdWlVHamqI9dee+0GmgEAAADAmTrTcOgFSe6Z5H5Jrkny3GF4Tahtk0bQWntha+1Qa+3Qvn37zrAZAAAAAGzEGYVDrbXPt9a+0lo7neRFufHQsauTnD9Werckn9tYEwEAAADYLGcUDlXVncfuPi7J0pXM3pjkCVV1i6q6R5ILk7xvY00EAAAAYLPsXqugqv4wycOS3KGqrk7yzCQPq6r7ZXTI2KeT/ESStNY+UlWvSfLRJKeSPLW19pXNaToAAAAAG1WtTTwl0Fl16NChduTIkXk3AwAAAGDHqKrF1tqhteo2crUyAAAAALY54RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4dAWtnj8ZC674mgWj5+cd1MAAACAHWr3vBvAZIvHT+biFx/O9adO57zdu3L5JQs5uH/PvJsFAAAA7DB6Dm1Rh4+dyPWnTud0S244dTqHj52Yd5MAAACAHUg4tEUtHNib83bvyjmVnLt7VxYO7J13kwAAAIAdyGFlW9TB/Xty+SULOXzsRBYO7HVIGQAAALAphENb2MH9e4RCAAAAwKZyWBkAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOLRDLB4/mcuuOJrF4yfn3RQAAABgG9k97wawcYvHT+biFx/O9adO57zdu3L5JQs5uH/PvJsFAAAAbAN6Du0Ah4+dyPWnTud0S244dTqHj52Yd5MAAACAbUI4tAMsHNib83bvyjmVnLt7VxYO7J13kwAAAIBtwmFlO8DB/Xty+SULOXzsRBYO7HVIGQAAADA14dAOcXD/HqEQAAAAsG4OKwMAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADo2JrhUFW9tKq+UFUfHht2+6p6R1V9cvi7ZxheVfW8qjpaVVdV1QM2s/EAAAAAbMw0PYdenuRRy4Y9Pcm7WmsXJnnXcD9JvifJhcPt0iQvmE0zAQAAANgMa4ZDrbU/TfLFZYMvSvKK4f9XJHns2PDfayOHk9yuqu48q8YCAAAAMFtnes6hO7XWrkmS4e8dh+F3TfKZsbqrh2E3U1WXVtWRqjpy7bXXnmEzAAAAANiIWZ+QuiYMa5MKW2svbK0daq0d2rdv34ybAQAAAMA0zjQc+vzS4WLD3y8Mw69Ocv5Y3d2SfO7MmwcAAADAZjrTcOiNSZ40/P+kJG8YG/6jw1XLFpL8/dLhZwAAAABsPbvXKqiqP0zysCR3qKqrkzwzyXOSvKaqnpLkb5I8fih/c5JHJzma5B+SPHkT2gwAAADAjKwZDrXWnrjCQ4+YUNuSPHWjjQIAAADg7Jj1CakBAAAA2EaEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB0TDgEAAAB0TDjUmcXjJ3PZFUezePzkvJsCAAAAbAG7590Azp7F4ydz8YsP5/pTp3Pe7l25/JKFHNy/Z97NAgAAAOZIz6GOHD52ItefOp3TLbnh1OkcPnZi3k0CAAAA5kw41JGFA3tz3u5dOaeSc3fvysKBvfNuEgAAADBnDivryMH9e3L5JQs5fOxEFg7sdUgZAAAAIBzqzcH9e4RCAAAAwFc5rAwAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADomHAIAAAAoGPCIQAAAICOCYcAAAAAOiYcAgAAAOiYcAgAAACgY8IhAAAAgI4JhwAAAAA6JhwCAAAA6JhwCAAAAKBjwiEAAACAjgmHAAAAADomHAIAAADo2O6NPLmqPp3kuiRfSXKqtXaoqm6f5NVJLkjy6SQ/1Fo7ubFmAgAAALAZZtFz6OGttfu11g4N95+e5F2ttQuTvGu4zzazePxkLrviaBaPy/UAAABgJ9tQz6EVXJTkYcP/r0jy7iT/+yZMh02yePxkLn7x4Vx/6nTO270rl1+ykIP798y7WQAAAMAm2GjPoZbk7VW1WFWXDsPu1Fq7JkmGv3ec9MSqurSqjlTVkWuvvXaDzWCWDh87ketPnc7pltxw6nQOHzsx7yYBAAAAm2SjPYce0lr7XFXdMck7qurj0z6xtfbCJC9MkkOHDrUNtoMZWjiwN+ft3pUbTp3Oubt3ZeHA3nk3CQAAANgkGwqHWmufG/5+oar+KMkDk3y+qu7cWrumqu6c5AszaCdn0cH9e3L5JQs5fOxEFg7sdUgZAAAA7GBnHA5V1a2S7GqtXTf8/91Jnp3kjUmelOQ5w983zKKhnF0H9+8RCgEAAEAHNtJz6E5J/qiqlsbzytbaW6vqL5O8pqqekuRvkjx+480EAAAAYDOccTjUWjuW5L4Thp9I8oiNNAoAAACAs2OjVysDAAAAYBsTDrEhi8dP5rIrjmbx+Ml5NwUAAAA4Axu9lD0dWzx+Mhe/+HCuP3U65+3elcsvWXASawAAANhm9BzijB0+diLXnzqd0y254dTpHD52Yt5NAgAAANZJOMQZWziwN+ft3pVzKjl3964sHNg77yYBAAAA6+SwMs7Ywf17cvklCzl87EQWDux1SBkAAABsQ8IhNuTg/j1CIQAAANjGHFbGWePKZgAAALD16DnEWeHKZgAAALA16TnEWeHKZgAAALA1CYc4K1zZDAAAALYmh5VxVqznymaLx0+6AhoAAACcJcIhzppprmy2nnMTCZEAAABg44RDbCmTzk00KfhxgmsAAACYDeccYkuZ9txETnANAAAAs6HnEFvKtOcmWgqRbjh12gmuAQAAYAOqtTbvNuTQoUPtyJEj824G24xzDgEAAMDKqmqxtXZorTo9h9i2pjnBNQAAALA65xxix1s8fjKXXXE0i8dPzrspAAAAsOXoOcSO5qpmAAAAsDo9h9jR1ntVM72MAAAA6I2eQ+xo67mq2Xp6GTkZNgAAADuFcIgd7eD+Pbn8koWpgpxJvYwm1TtUDQAAgJ1EOMSON+1VzabtZTRtiJToYQQAAMDWJxyCwbS9jKYNkfQwAgAAYDsQDsGYaXoZTRsiraeHEQAAAMyLcAjOwDQh0npOhg0AAADzIhyCTbKek2EDAADAvAiHYBNNezJsAAAAmJdd824AMDp59WVXHM3i8ZMzrQUAAIC16DkEc7aeq5q5AhoAAACzpucQzNmkq5rNonbaHkZ6IgEAAPRNzyGYs/Vc1Wza2ml7GK2315KTawMAAOw8wiGYs/Vc1Wza2kk9jCbVTlvncDYAAICdSzgEW8B6rmo2Te20PYymrZs2RFoybS+jWdcBAACwfsIh2IGm7WE0bd16Dn2b9SFtm3Xom8AJAABgRDgEO9S0vZGmqVvPoW+zPqRtMw59c5gcAADAjVytDJjKwf178tSHf8PUh7SdU5nqkLZZ1W3WVd8AAAB2Oj2HgJma9SFtm3Ho23pqAQAAdrpqrc27DTl06FA7cuTIvJsBbHObcc4hJ9cGAAC2q6pabK0dWqtOzyFgx5j1Vd/meXLtpXpBEgAAsNmccwhgBdOem2jWdcmNQdJz3/6JXPziw1k8fnLV2suuOLpqDQAAwEr0HAJYwbTnJpp1XbJ5V2nTEwkAAFhOOASwgnmdXDuZPkiad4jkXEsAALD9CYcAVjHteYw2o26WV2nbrBBp1uda2oywSTAFAACrEw4BbFHTBEnzCpHWUzvrYGozAqylWlemAwCgR8IhgG1uHiHSempnHUxtRoC1Xa5MJ5gCAGAzCIcAOjHLEGk9tbMOpjYjwJp1MLWeAGuewdQ8zy8lwAIA2DqEQwDcxLTnRVpP7SyDqc0IsLbDlenmdRjfemoFWAAA25NwCIAtY9Yn9p62djtcmW5eh/Gtp1aA5Qp/AMD2JBwCgGz9K9PN6zC+9dQKsPq6wp+gCwB2DuEQAMzZPIKpeZ5fSoC1/a/wt1knZwcA5kM4BACdmtf5paatE2Bt3Sv8bdbJ2fUwAoD5EA4BAFuWAGtrXuFv1nXr7WEkSAKA2arW2rzbkEOHDrUjR47MuxkAANvKTjnn0GVXHM1z3/6JnG7JOZX83Hd/Y5768G9YcXzzPCcTAGwnVbXYWju0Vp2eQwAA29S8rvA367r19G6a9zmZtnLIthPbCMDZIRwCAGCu1nN43rzOybQdTuy909q4VL/VAyyhGLATCIcAAJi79fREmsc5mbbDib13Whu3Q4A1zx5qwiZgloRDAABsK7M8Wfh2uDLdTjr5+GYcQriTQraee2AB8yUcAgBgR9opV6abdd12aeN2CLDm1UNtp/XAWqoXTMH8CIcAAGAKW/3E3jutjdshwJpXD7Wd1gNr3ocGOg8VCIcAAIAtaqsHWLMeZ689sOYVTO2081DBRgiHAAAAtogee2DNK5jaSeehWqqdV++mefbAYjaEQwAAADvYVu+BNa9gaiedh2qevZvm2QNrqdb5qjZOOAQAAMBczSOY2knnoZpn76Z59sCa94nUdxLhEAAAAF3aKeehmmfvpnn2wJpngLXTCIcAAABgi5pliLSe2nmeh2pehwauJ8Daaaq1Nu825NChQ+3IkSPzbgYAAACwjTjn0OqqarG1dmjNOuEQAAAAwM4zbTi062w0BgAAAICtSTgEAAAA0DHhEAAAAEDHhEMAAAAAHRMOAQAAAHRMOAQAAADQMeEQAAAAQMeEQwAAAAAdEw4BAAAAdEw4BAAAANAx4RAAAABAx4RDAAAAAB3btHCoqh5VVZ+oqqNV9fTNmg4AAAAAZ25TwqGqOifJZUm+J8m9kzyxqu69GdMCAAAA4MxtVs+hByY52lo71lq7Psmrkly0SdMCAAAA4AxtVjh01ySfGbt/9TDsq6rq0qo6UlVHrr322k1qBgAAAACr2axwqCYMaze509oLW2uHWmuH9u3bt0nNAAAAAGA1mxUOXZ3k/LH7d0vyuU2aFgAAAABnaLPCob9McmFV3aOqzkvyhCRv3KRpAQAAAHCGdm/GSFtrp6rqp5O8Lck5SV7aWvvIZkwLAAAAgDNXrbW1qza7EVXXJjk+73bMyB2S/N0c6uY5bW08u3XznLY2nt26eU5bG89u3TynrY1nt26e09bGs1s3z2lr49mtm+e0tXFr1s1z2tp4duu2g/2ttbVP9Nxac5vhLcmRedTNc9raqI1badraqI1badraqI1badraqI1badraqI1bado9zos2zq6NO+W2WeccAgAAAGAbEA4BAAAAdEw4NHsvnFPdPKetjWe3bp7T1sazWzfPaWvj2a2b57S18ezWzXPa2nh26+Y5bW08u3XznLY2bs26eU5bG89u3Y6xJU5IDQAAAMB86DkEAAAA0DHhEAAAAEDHhEMAAAAAHRMO8VU1cv6823E29TjPAAAAME44dBZU1e8Pf5+2CeO+U1V933C740bG1UZnJ//jKaZ5TlX9wUamdTZU1UOq6lbD//+yqn6jqvaP10w7z2cw7ddV1fdW1arr2PC+zWQ9rKoHrHZbVntOVf3rdYz766vqMVX1/VX19SvU3GKaYetRVQ+ZZtg6xrerqn5oytr9VfVdw/+3rKpbr1B3zpTj+7Vphk05rl1V9eAzee4q45x6mZi0Ldvo9q2q7jHNsHWO855Ly2BVPayq/lWcC3KBAAAgAElEQVRV3W4D46thW/Lvh/t3r6oHbqSNU0xzXe/10ufNWsPGHrvNSsv2WM1dq+rBVfXtS7dp27PC+G61tN2rqnsN25ZzNzLOraCq9lTVfWY0rltNWbfmdmqFbfPtN9i+mW/vZ214Pb5x3u04U+v5TF/jOfesqt1nqc33GdbnH1i6bWBcdxraf/+qutMM2nb7CbcNbXeq6lvWUTvT/Zl1TPddUw779qX1paoeWlW/UFXfO4PpP7Sqnjz8v2+jn+vLxv0fp6zb8LZ5Pftws972TLu9Xs8yPuzz3WXYj7l7Vd19Vu1do41r7uudybZvjWn+2vD38Wfw3Jl9rm8Xrla2QcMH1n9McpfW2vdU1b2TPKi19pKxmo8m+Z4kb0zysCQ1Po7W2heHuuuSrPiGtNZus2zaP5TkPyV59zDO/yXJL7bW/ssKbX1wkguSfHUnobX2e8tqLkvy8tbaX64y26mqtyX5/tba9avVDbXfl+Q/JNk/TLtGk77Z/DwtycuSXJfkxUnun+TprbW3L6u7RZIfnDAvz15Wd1WS+ya5T5LfT/KSJD/QWvuOM5nnoXbN93uo+64kT06ykOS1w/g/PmF8f5DkQUlel+RlrbWPrTLtVd+/qrpilaa31tp3Lhvfu1trD1vlOUt1lyT590n+W0bv3XckeXZr7aXL6t7fWlseQn11WFV9KJOX76Xl4WYb37XGOTZsqmVnqP3T1tqqX26r6seTXJrk9q21e1bVhUl+t7X2iAm1n0ryXzJ6/z66yjgntfuqFeb7B5L8WpI7ZvT63Gydqar3ttYetNp8jNV+bZKfT3L31tqPD/Pzja21Ny2rm3aZmDQvH2it3X/ZsNsl+dHcfLn9V1OOc7G1dnDZsH1JfnzCOH9swjg/mOTQUPu2jLbB39hae/SyunsleUGSO7XWvmXYEXhMa+2Xl9W9IMnpJN/ZWvumqtqT5O2ttW9dVrfqdqKqnp/Vt/U3eX3W+V7f5HUcvhRe1Vq797K6QxmtM7fOaPn6H0l+rLW2uKzu15L8cJKPJvnKjU1sj1lWN9V2eahdzOjzak+Sw0mOJPmH1trF08zj2HjWtU1Z53ZiquWsqt6d5DFDzQeTXJvkPa21n1tW9zVJnpLkm5N8zSrje/DQtq9rrd29qu6b5Cdaaz81oY1Tbaeq6r8meWxr7Ybh/p2TvGnCuvWQJM/KzT+rD0yY9rTb5l9P8stJ/r8kb83oM/lnW2t/sKzu8Une2lq7rqr+XZIHJPnl1tr7J0x7mn2Z70/yn5Oc11q7R1XdL6PPrceM1axrn2vseffIaNn56Aqf6+tZzlacl/V+pg/POZzRa3dVRu/ftwz/703yk+NtWG27V2uEOq2110+Y9ksz2t/6SEbbyaV2Ll/GV123hvfqd5PcNslnh4fvltE26qfGl4nhC+0XWmv/s6oqyf86zP9Hk7yotXZqrPbTSc5PcnJ4bW6X5JokX0jy4+Pbvmk/u6rqz5Kcl+TlSV7ZWvsfk16voXbadWatfb3HZPS58z9XmtZQ9zVJvjbJFbnpd4/bJHlLa+2bxmp/K8kDh2m+Lckjkrwlo/29D7TWfnGsdqp1eqh9Zkafwd/YWrtXVd0lyWtbaw9ZVrfmZ3BVPW/56JP8SJLfG16j5e/NuzPdtvleSX4xN273Moxv+T7zVPtw02x7pp3nsdpPDvPwsozeu4nbrWmX8ar6mSTPTPL53HRdPeMQZB37UWvu641t+74mo+Xnr4b5uU+SK1trDx2rnWZ/+UMZbReuXD7tFebl3Zli2dmpzsovCTvcyzNaWf/tcP+vk7w6oyBiye9mtAE9kGR8x7sy2jE5kCSttVsnSVU9O8nfZhRoVJKLM9qBX+7fJvnW1toXhuftS/LOjL6o3kSNfjm+Z0YL+Vd38DNsVMc8PMlPDhuYLycrfnH/dJI/r6o3DnUZ5uE3JrTzt5L8QJIPrbRBG/xYa+23q+qRSfZlFK68LMnyHao3JPn7jF7Lf1xlfKdaa62qLkry2621l1TVkybUTTvPyXTvd1pr70zyzqq6bZInJnlHVX0myYuS/MHSTnpr7V9W1W2GmpdVVRvG/4etteuWxjfN+9dae/gqr8Ukf15V/9fQ/vH3cPnO+C8muX9r7cTQlr1J/iLJS4f7X5/krkluWVX3z013QL52bDzfN23DqupBSR6cZF9VjW+Mb5NkUk+daZedZPRe/EJuPt9fHKt5akY7SlcOj32yVu6Zd58kT0jy4hr1hnhpkle11r40zMv/luSnktyzRoHlklsn+fMVxvnrGYWvK4aFSd5eVT+Y5PVrrFfJ6LVYzCiITJKrMwot37SsbtVloqqemORfJLnHsO6Pz8uJCdN9c0Zf/j+UG3dAbqKq/klGX5hvu+wLyW0y9iV6zBuS/PeMtnVfmfD4uNOttVNV9bgkv9Vae35VfWBC3YsyWs7/7yRprV1VVa/MaAd43Le11h6wNI7W2smqOm/C+F6e1bcTR9Zo93JrvtdV9Ywkv5TRevilsYduSPLCCU95aUZftP778PyHDm1evt17bEY79qtta5Ppt8tJUq21f6iqpyR5fmvt18ffl6p6f5LXZ7Qd/H9WGc/U25TBerYT0y5nt22tfalGIfrLWmvPXLaeL/n9JB9P8sgkz87oc33S+v2bQ80bk6S19le1ck+tabdTf5zktcMydP4w7l+YUPeSJP86o/dw4jyvY3u/5Ltba/9mWAevTvL4jL6sLv8i+X+01l47LIePzOjL1QuSfNuy6U+7L/OsjF6bdydJa+2DVXXBeMG0+1xV9cettccO/1+U0T7Nu5P8alX9amvt5cumPdVytta8tNYePnymPKi1ttJnxXKfTvKU1tpHhmncO6Nt23/IaJ0ab8Nq273vX2UabRjXcgttWQi9grXWrZdnFIheOT6wqhYyeh3vOzb4zRm9z0nynIxezz9O8p1JvjXJeDD11iR/1Fp72zC+707yqCSvSfI7uemytuZnV5K01h5ao1D2x5Icqar3ZbQdeMdYu6fen5ly+X51ki9X1VuS/GGSt7XWJr2OP5HkZ5PcJaN1emld/VKSy5bV/rOMgsRbZhTI3XXYRj8nyQcyWk6WTLtOJ8njMgpH358krbXP1eSeqtN8Bv9ARuvd28fm5Qm56feqcdNum1+b0fe0F2XC8ji2D3dgyn24Z2WNbc9g2v2OJLlXku/KaDl7flW9OqMfnf96Wd20y/jTMvpcn7TftjTft0nyjIyC2be01l459tjvtJv/YLHq/KxnX2/p+0xVvSrJpa21Dw33vyU3/+yaZn/5rUn+Lsmtlu0fTeyskOmXnZ2ptea2gVuSvxz+fmBs2AdXqH1BRh9qPzPc7rtC3ZVTDvvQsvu7lg8be+xjGe2QrzU/+5Pcb7yNSfZPqHvmpNsK47wiya4ppn3V8Pe3kzxu+es6VvfhKd+b92S0YfvrJF+f0YfwzV6fYZ5vdpvB+703ow/mIxntjP9wkucnefeE2jsMtZ/O6NeaTyb5mfW+f0Pt1yb5d0leONy/MMn3rfC+LL/9twl178roF5Cl++cleefY/ScNz71u2bjemFFPrTNZr75jWKauWbaM/VySC8902RmGf2rC7dik9W1pHBkF6VdN0e5vz2jH6stJXpHkGzLaMbogo5248WXs9quM58+nmNZ1Ge20Xp/Rzt51Sb60Qu2RCcvtX613mRja/bAk7x3eo6XbA5LsnjC+908xHxdltMN/Yvi7dHtekgdPqJ+4vq0w7iszCl4/nOQew7CbbT8y5Xo9jO+cpfnK6IvfpG3U1NuJKedjPe/1r2bUI+fbxt6fb59mGVth2Fsy6sWyVhun2i4vvS4ZBZWHk3zzMOxDY49/KqNw4G+SvC+jwOIuZ/r6jY13PduJqd6vjL483jmjLyzfOj6d5fO8rA3nZvL29srl7Zq0rk6qzSrbqYyCpD8Z2nuz9Wp8fGvM77q290k+Mvx9UZJHrTQ/Y/Pwq0n+xUrvTabfl5n0Oq702qy6z7VsHH+RG7cld1hhXqbdl5l2Xt67jmV80nbrg5Mey+y3Uy9Jcu8zaeOyxz+5ymNHl93/6Nj/ixnb11z+3mT4HJw0bMJrs+Zn17L6czLqOfnZ4X39+NL6kHXsz0yzTGS0/dyTUe+rd2XU++N3k3zHCvU/M0X7Pzz8/ZqMep3ccmy+Prqsdqp1ehj+vvHXM8mtJq2H0yyLGYUxv5XklRmFV8myfbdl9dNumxfXeG1um3Xsw2XKbc+Zrn8Z/aD92Yx60r0no/B4Xct4Rtvsm+2zLXve6zIKXB+b0fb9dUlusdL6sdb8ZJ37eiu9HhOWizX3l8dq3zBl3VTLzk696Tm0cV8eelK05Ku/bPz9CrUfzyhZf31GaeXvV9WLWmvPX1b3laq6OMmrhvE+MZN/XXlLjQ7v+sPh/g9n9GvHJB/OKCC5Zo35eWySS8bbmNEHwE3a2Fr7P5Nk+AWgtdb+31XG+W+SvLmq3pOxX5TbzXsZLVbV25PcI8kzhnFP+sXmL6rqn7YhSV7FD2fUy+EprbW/rVH34/+0vKi1dnz4tfLC1trLhh5YX7fCOKd6v6vq9Un+SUav3/e11v52eOjVVXVkrO77M/ol4J5D7QNba1+o0WFAH8uNr/u0719yYy+RpfOUTOwl0qbvafTZJFdW1Rsymu+Lkrxv6Rew4X18RVX9YGvtdWuNbHjNnp/kmzIKms5J8uU2lty31t6T5D1V9fLW2vEp2jjtspPW2jTHu7+nqpZ6YfyzjH41+pMV5uecJN+b0a/DFyR5bpLLMzps5s1JrmutHayqO045L8noF8hXZ/QL6Pg68/qx/1c9T8wy11fVLXPjcnvPTOjdsdYyMbT/eG7sgbSW36/RoS9vyk3n44tj/78hyRuq6kGttfdOMc43VdWjW2srbevGPTnJTyb5ldbap2p0OMikXzf/bnhNll6ff57J69rzkvxRkjtW1a8k+ecZBbHLrbqdqKo/WXpskjZ0P6+qh7RRj4F9bY1DCMYcS/KnGf3a98GMDm19b0a/pI97X9X/3955h0tSVXv7/Q1pSENWyelDkKuACBIVQeAaQDCBSBJRUVBAFL3IVRADogQFFRBkQIIKKBJUJIchSI4CVwEDQTGQFJDg+v5Yu6arq6u7d/fpc7rPzHqf5zwzXb27alfaYe21fkvH4/2H4e3lFUrx/NbwIHwGuE2uUVG+h9XQwNx2GXzV8gB8hfNuSSvhg9WCx83s08CnJb0B7wNvkXQP7k30PegYFtRuNTC7nSD/OTsED8OYYWY3pnP5bU25F9K/T6TVzz/j7UWVP8nDSix5pe1NvYcRdGmnKl4Kwr2GbgPWl7R+TR98uaRv4P1/+V7fUvr/KfTQ3gPnS7oXD0HZM/Wvdc/yw+l53Bw4TB6mWKfHl9sX3iXp/cAcybNjb9ywU0e3MVf5GZvTzB4EMLO/Sap7fnKfs9xz6cVL9D55+OuP0uftgf9L1/OFStmsdk+uO1MNh2wJF8UXRK6T9Gf8+Wnnhd3t3fqlPBTyB8Cf0rZl8TCvCytl/yRpMzO7DF9cWxb4Q2p/q/xD0mdpvjaPpz68en+69l0A8tCZ3fAxwMW4B8Mt8vCp6/B7dqU8/Ow1xdi5AznPhJnZ4/jY/AS5N992wNckLWNmy1YKH6PuoZg/l3Q1fo9PBM6UhyhugvcnZXLfadJ+jgcWTtfzg6neVbo+i+be9PtKeh1wWnpGOml25rbN50vaE+/bW+61mT2J9987pGfl5fh1XEDSAmb2x8r+ctue3HFH4bG/Ex5G9xd88f48fDH/LLytgfxn/AG8v/857edlK5vZu9P/fybpQOAyeVhjHR3Pp4+xHsA9kk7Ex22WrsE9af+F91HX8XJp2zaZx/0iec/OLEloDo2RNJA+BnfHvAtfSX6PmbW4n8ld0jYws3+lz/PjK0LVeNUV8BWnjfCX4Ro8nvf3lXKH4SvZG+Od8FW4W+9na459Od6I3EDzy1ONgc2t46txY0YhkvY3YBdLrsyVshcB/6TinlvtJOXu02vhK6rz4KtyS1eNZ3INp1Xwxq3TACQLZcZEp7LF/f4vPK6+9n5LehuwOn4P/wPMAI6tTvAk/QA40cyqnS+S3ox7Exm+YtL1/qXf3WRm66ikASPpdjNbs1LuC3XXozroS9enLeX7mDOIlBvH3od3aOvgA77/Z2YHUkHSxcB7LcXxyzVefmRm/10pVzw7D5jZE6kjXbrNezgfvmK3nJl9RDX6O2l/uwNb4s/Xr/D71NJgSnoAn9h+38yurXx3NG4k+hludD2q+vuaCRqSple3Ua/dsAj+LpSvd92ztAVuxFgdXwnZCPiAmV1RKZerqdU1xjuV2wv4Cr7CVVw7s3oNk1yNl6fx1cfnaUx26gwBSNrHzL6VsW0lPPRqQ3zV9EFgp2qbm8quhusxCLjUalyZu/ULkjap/qZMMo7OjMNXTYx+O+Sx9esC15vZWqm+XzSz7SvlCmNMcV+KMOfiXm6Wyu3apo6nVPb3G9xT7kG6tMuS3mtmZ7XbVne+aXC7BbC9me3W5TLUktNOqGFwEv6c/Rt/ztoZnHKP/SF85XUN3IC/APAFMzuuUm5xvP/fPB3zImAfq3H/79ZO9dJ2p/KX1xer1bZZGNeiK0LersR1NZ6slJsH92Z9ysxeSmOKBczsL5Vy8+HhD3eah8ctiU+mq6FYuWOZ+fCwzvK1+VK1D05lV6DDmEvSSzRCzufB+44/y413N9WMjzo+Z2oYh7P69VKb9xI+IW/7LMoXAfakMS6cgYeTPAfMZ6WFvJx2T9Jx+P3bFDcavAf3Btm95ti/w/vW6ljvD5Vyxfm0fbckvRVfiFo6ff8QcF7VoCTPNvsDfJHpyXTehWfNp83s0lLZxXGPnfK1+WL63XJm9rtS2ay+S9JVuLHjbDN7tvLdzmZ2aunzZXXvUvou+5lQjb5f6bvla653baiatWr0bJC2X58m+e/EvTfPNrP/VMouQuOdng+YZo1F0GqdtqD0Hlop5K5UJrsPTuWFP+cbmNlOdWVyketGVqm71x/HQ8Y66vTktj1tznnH6v1LZf8Pn3NNN7OHKt991swKweWsZ7xd31AZz9+De/b+p7RtV3zBfwEzW76f81FvWktTgY/R6GeuIs2l2oyTS6fSGDtKmmEeAlru38vjnerYtViY67htViWMQwNALvi5Kv6Q3WdJT6am3J24e9pz6fNU3A3vNX0etxeB29rJSDEJ6bWOkq4FDjSzy9PnNwFfNbOWrDqFsSLjfD6Eryg3rXhXO1N5xrFF8Ek3eGPxRNEA1TQCM39KfSNwGykm2hrGlHbXcSrwcVwT4Wl8ZeiYmkb/TDz84/S0aQdgETPrSSk/dxJZ+c21+OT1GnN9lJXx1fbXV8p9qvRxKq7fcU91Mt5DXbMGkWoYr2ZeY0nXtnl26kSOy0av1czsXrXJXmD1YqY/xj2rdkkd07z4c7ZWn+e9gHXwnJNnrNgWN/QdV/2+OkHr4bhZ70sqeyo+YH8WN6r+2sz+VlPulyStHDNbM7Vtt9a8/7+je4w3ku7HdXpajlVT9lpch6JJ78TyvBPa7TNLOLv03fx4WMLTbb6vzeZhpZXDNDFcHx/cd+0XutT/enyV7O00VgLLx60T9r7RzNZN7dp6ZvZvSbdVn+/UllUFpM3qBaTnxjUPaHcuqmSCLNWxbqDbTbz+R2b2vrr9VX4zzVwXoDaTi7Wu8hd6MiuZ2SHpfr7CzG7odqwOdcgWZx0P0r1ZDe/r7rOMJBEDOu5PcMNnYSTcGQ+Vf1elXFcR3vTO3GFmXTM/5Y5lcpEbHfc2sxbDfcZvFwZeZTWr4JKWplXg9qr0Xc/9+njSqd0r+unSvwvg3jBb1pRta/yoKbsorQsbbc9b7nn7WIfvX4W3UXPihqQbqwaNXuil7+phn0fg53wWzZp+P+3lmZD0Jqss7HQ57j14uF/XCZ98gWhpvD15xCpG3FK5V+OLTeX7VxWFnwM3Bm3eQ1079sE91jErCUAPdfsd/ky01emp+c0cwPyWNCgr361o7tE885yLbTVllXP/ekUdoj9S33aRuYZqeftb8HnPKpXtc1hjAaDTOOpKkjZRaSx/V7v2P43RlzOz+9p8P3BDTk6/NSsTYWWD4fU0BthrS2ppJBPT8fCcc9LnbakIGQOoeyaHXsXRehlsZNURb+xmrjKa2RVqn3r3EklbWk2mjgr70Fjx3lRpxbumXMfQN0sq9pYfdvO8mZlcDJoO5wG+QvUU7l0BbvQ5FRfkK7OqNXvqXC7p9urO1MUDwxoeBIdZxSNM7jlWd18Pxicpy0o6HV8NbVlpN7MjKvs7nCSCWtm+BL5SUO1gq4PADUuDyC+mgVCdaOUzaUJzW+p8HsVXEev4j6Tlism3fIW33EHuh2frOaL1pxitoTTgrrLby8WVMbNn06SxfM51WZCexPWjvlwZHMwraW/avK+pQzssXZdftjnPJiQtgz/PxUr2DNx7oLxilPu+gL/XG+OeFyvh1/4qq3jQAIub2ZlycWPMxZzrQlr/0s0wlLgbD0vKYb7qM94OuVtzsZJ0hbVmXcsSzlZz2E3590CtV9fPaaw2TQVWBO7D343iN/+RdIR5drEWT8rKcVbBNVaqg+xixXIr3INkM1pFN9sNFB9Kk9af4eLrjwOP1JT7Gb4qfguNkIA6z7g34QaA3+PnvaykXa3ioWYenrsmDaP91WZ2e2VfbwXeBiyt5swz04CZWYU6GYYk7WZmxYrhGfg1upnGfZm5G1KyhxLfJWWbw0MOnsa9edatlEMutnqZJU+YdE3fZGY/qxTtKM4qaSczO63ds1Y8Y+oxg136zdtxg/P96dxXlLRHtZ1RvgfmQviqc0dvoEQ55ADgi3KDZLGvbOHq9M7cXm7rO1yHK9PksLhnN5SNBsoM2Sx9fkkuMt3VONRmUlpnGKrN8EcKzyn16/MDz6bzfyVu5KvtI9JYYeO0n6trnsOiXDXjXHGedd6aTRm5Su1e+VkrvGGekXtV/x1mhrBUuVcuQHs+HcI7VL+wUSxqFYajKjcUz1HV6Jv4Bx6CVtybFsNQusafprWvrhsnZPVdGW14mUXx61c+npFCz9L+VgQetcYC7bx4GFPjB8kwlGskISNUTW0yxEmqyxB3EK49uDoeOv9WfIzSNO9J79YzkhZq04aUj9/1WeyljoncJABZxi78+ep4HmlfZ+Dh7C/hfdNCko40s6qsxU+AtS1FaiTOBspZu2a2Z5VhalHHugxoXZ9xVaI/JLVEf5jZZ+rOz8wulPTVmq8elHQhLph+Wd1vE/OZ2Q2V83mxrmAa630Dl6BYUfWZ347BdS/psq0r6j0ZzixJGIfGiPIzZ2BmR8rT4xXufruZWV3mnG6ZHM7ABxCHAv9T2v50tdNUj140PdTxAUmfxxsX8DjQOtdMcCHMz0jqFgbynLmrIJLmMfcIWbVmf7vj4XNF6NthJA+eNsfvRl1M9IltymYZfYBb5ZoO16c6rke94S5HZR98Ul+dOL+1ZhtmdpE8VfT6+D3cx/JWv+ajdTIF7v30Y3wS9lFckPSvNeVyB5E7443sx3Gh2WVxD4Y6DgRmyFcawCctHym+NLOPpH9z9ZMgT3/nl/i7V2RnKCarT+GZVMqZXHKzGl0r6UjyJl7T07ELo+NOadsWpTK57wtmdlm6huuSsvPhBo2qcShXQy03xvsl3BB1OZ31aiBT40WePWVdGl55+0ja2MzKbeG1+EB4cZoNh0/jaZ0LetFtwlo9qNbGM8JUydUImY5Pxo/C78tulAwc6b39kVy/4NzK5P4I6vuZd6b/Hpyu+0K06nQALGNmb+lQt4IjcAPIfenYr8R1iqpp0PfBFzWKZ+A0Sd+z5rDgR/DB8jtoNnY9jbcFOXwRv26YWZGtbAY+8b7aalKLl8jNNgeeYKFYJME8POgg/JkvM1f69224h+Y/KoPewvDd7VnrNYMd+L3Z1BqhAivjBsyqgWEJK6XYTuddl9XsJHwiuV36vDN+revSmj+b3rsZ6dgb0egDwCdkH8ANAGUj69N4Vr0qSwJ3y7M9lb0qqpOf7fDJwhX4u3KMpP3NrMjSenjNvrvRLUvja/EwiLpJ6cdqxki5Gf6uAt6Q3udL8Wdge3wSOxNJ38VDNgt9yY9K2sLM9qrZZ9eMcyVyMnJdkCbu38ANyUb78dG8eDtf9ioyWheJui1s/A3XtiuzdOn4M8cpPRoMiqxUJ9L92uT2XR3b8DKWFw57Fg29yKIeZ1EyYPdhJFkc+E16t9qFL55Mfoa496TPt5rZbslI1e6ZeA64Mxmoy+9W9TrmPIu91BFcruC9krYxs1OS0eZX1Z3mGrvI0+kB99J6Sq5j9gt8nH4zSfNUvWVo7bU9y33GvwfsZ83RHyfQ/Ox1YmY/XGJVfGy8F/B9SRfgixAzKuWytZbwd6s289s4GXLmxkO+56S5z34Kf+5nC8I4NHbWIdNdE2YONlpCXSp0XEG3kjhaxvF69aLpWEdJp5rZzvhkeAUa3jtXUuOd0uOxc1e8RXOj9xJtOuMczOxweUz0U3jj9gWriYlOdDT6qOFxMhewi6Q/ps/L46uIVTp6YKgPLzFJl5rZm/FJQnVbuVzZO2YK7r30pZpdLmZm35drtVyJi6DWeSxlDSKtEWbyLO09XYqyF0paBzcI3YYbYp6tK6vugosFB9HqWfWBSpmNrFlz6k5J15jZRpKq8e25Hi+9TLyWsIZ3BMDJkvatlMl9X5CLCc+PG1GvxkNH61z098O9x1aWdA1JK6em3DR8VbXbJOBntE6m27EP8LlkRH6eNgZsfBK+VrEyLOkUXGNipnHIMoWzrc+QvtLvb5HU4nWCX8f5gRclPUf7c5nXzC6VpFTng+WioFU9gGVrJve1oXGV+nXyGM0VkJ7LSu7cZvZ/kuaqKbc7bnxpa7Q39yS6XdJpZla7Uph+2y5lrK0+ivIAACAASURBVKisoicKz7hj5LoHt+KGoqrx8wW5m38xKF2C9hOROqHTujFTR3FWMyvS+nZr66oaTtN8c/vwCuAxK+mk4JOXuvf6JTV7YC5PvXdNR2+gCh/DhakXSp8fxxcOyudzivKFq3PfxQMptV/pel+Cr7j3G5JVTIjKIZVlz9PptJ+UnkzrpPQBfAzQzTgk83Thu+NhGl9vc703AV5djDNTm9fuvX3SMj1UgalmVuvRVmBmxZjgJ2myN7XNgkau8QO6L2x8BveY3N8aKawftPpkEieTbzB40cyOzaxjbt+V24bnegTPaaXQUDN7vsaAfTK9GUkOzjiP+av7S8e/Xq3e9M+Ze7u9mNqpx6hfWAQfh/68zXdluj6LPdYR8pMA5Bq7/pj+5k5/7Zgr9ZHbAt82sxeUIhMSq+KLrQvTvND4NL7AUj63Xtuz3Ge8a/RHr/2wuebWmfiC+yL44uOVtBpq9sKNU6tJepikTdThfJ5UjdcU42DIsd6T4cyShHFo7PSSRSqXXrLxTDSvSwPLXfFVkkLUCzoYaJThEm35K965oW9ZqBGydXHNtuJzrtFnK3qjmwdGL15iU3Hvn8VTw1x241+q5thb0dBuWhj4hZlVQ1eg0cE+Kg9jeARfDW6i2yBS0plmtp3qQ7aweo2nWl0dKuFi6s2D72JJt9DZs2oBSesVAxFJr6eRwa46qc19X3uZeP0tGaGKleIdKIVDpfPIfV/AvWVehwskP4kPlq6zioBmMnZsQhetnNxJQFqt66pXk8r24sWzMB5GAH7eTah33bHp1D+TVTHs8uB1Cu623OJFZ2YLqkZTo4bn5Horv5WLXT6MG2mrTJG0iHmGmiLsoq/+u/T+zQnsJhdU7yQgfZOk79PwEt2R1hA3yDDal9/9usFe6dgvxz1PHq85RkvWF6v3jHs1rZ5xudnmwM/7SOA7qc6foOa8zex/kiGsEGd9BhfSLc756OpvKr+visKug/dxC/pHPQF8sNw2q7HafLekX+ADcsM9DW+sOUxHD8wS3byBytyDe76ujL+PT+J9cXVCcYHc820Fmg33TdpW1iVcrMSUyva/U2PIa9PP1IYGW3fP014npbkZ/iRf/d4RN65C/Yr3fcByNLxplqX1Ohd0zThXomtGLrkw8+lm9oS5ftl8kvY0s+9Wd5Zp/IAuCxvmC3Y/Ao6S9Cfc0NJuAbaXe9MxK1XpPOYAtrA8oePcNhzyPIL/KukdZnZeqss2uCdVmZ6ex0wDQy8Z4m5M9+8EvE38J66x10LV6N2BnOxwvdQR4HtpLPy/+KLXAsDna8oVoZ0djV3WyNI8vzWHglU5Hg/Dvh24Ks2ZZmoOWR9Zu+Si2XVjlGo9s55x8qI/euqHUz03wb0f34r3RdvVFHsYf+4vx8PansLnlHUZENtmfisZck4zs/vr6jMGTpQnyegYij2rEoLUfaIes030uO+umRyGhVxb5WN4w/lw+Su8jnVx7VWX6O2B+63eJTq3HmtTytJm9aFvufvqKuytNmKrBf1amNUlK5V6EFyVh3XsixuCHqYxMXsKOMHMvl059t40wkCED+xPsNbscFvh3ibL4gO/aXj2ozp9orbeO5KWNLNH213Lumuo/MxLXQUX1Ua0unT8ckz9urinzwL4tXkK17m6G3i7mZ1ZKpv1vkq6Dl8JLU+8DjfXpqnWdTng27jni+Gd4T7VayRpY2AVM5suX0FfwGrEDEvlF8A9/D6NC/HOU1OmqweWMoUeVaNXA+xq9RnVhE+SVjSzL8mz0CxpFbFguZ7Q1/CBhfCJ7gFm1iLYnIs8BKxgKp6l5ZGaiXt5NfjFdF4/sVZB+lpNDWv13lsXn2QvjHvtLQR83ZJnYqncLnjq97Px52E74CtWyoTTw7n21JbJs03tRXNWzO9aJWQmGc52xQel4O3JKVYS+s09djJGTbdWd3QknWFm769sq3rGzWhjWChc+jtmm0vl5scnEuWsYV+uTgrUJfuhGtneNsLDFn6cPr8XuNnMPlnZ3x3AXmZ2dfq8MX69y/1RXb9RYNX3MP1mcfw5BG9P6wTp18Lf1yZvIKvP+nghDc2qsoB8VcvuQtwoUxWar5arhou9AW8vz66U+wae8a08nrjDWjX5vk5raLBSXTY2s60r5dtm2kwGvpWpn5Q+aGYfr+xrV2qoTpQlvRFvi68xs8PkXm/7Fu1OaZy5EN4P3pA+r4e3Jy1Cv+ot41zXjFyqF7OvFfWXhw6dQfOEc0cz26JatvSbTdL5XWg1YuqStsaNmyuY2Stqvs++N8rMSpXK/goP+e8o8F7Thk/D2/AW402ba9m0TR5uczo+jlM6p12sOZNar8/j+vjY7VW4t8UcwL9qxii5GeJOJYXx4l6S0+raiFQ2S5Mp51nspY6p7Dw0ki4U3q5mrRl0v4uHur4P+BRu7LrNKotgckPu9/Fx1nJyjb09zGzPunOv/HZOq3jL5o6jUtnFSh+n4v3Homb2hUq5rGc8GTu+SHO/frClBahUptd++EF8vHMmfk9qDWi5fUcq2zXzmzxj4NK4MaoIL+/mEd2RujauXbs3KxLGoT5JHZpwMeGyaJeAw8xsvTHuv6dMDhONpGPN7GOZZe+m2SV6Cp6u9r86/3J8USNka2Wg7Jq/ID5YG1N6zEEg6QIz26q0alBebm83qPlE1cDTZt934GlAizCQ+fFsVy0ePJl1zU2XWiu4aPVpw3MzL52FZ5zpJLhYDJqn4uGgt+PXcw08e9fGNb9ZCG8nn6h+VynX9X2tTLyEe758wCqivbkkQ8U6+ET0lXKdp7OsORyuKPtxfLL1Onz1uehAL6uUy72HZ+FCj++nJPRoZvtUyt0MvN8qejVm1qRXk747liQWbGavSoOXi8ysTix4SXyyJPze1abQ7ZfURl1SN6HK/H2WUbPHfa6Oe8wVRo26MNWhogEa7Xs87lH4s/1vPNz2KrwtezZ931NWsx6PnZX9MLU/W1rynJOHHVxkFa8VpfDVbtv6qGdHEfdUZh7cm6rsDdQymUpl22aX6bPc7bi3RlO4mDVr/BVl340b24rn7JyaMm2vo6Q7raQfpoxMm71MSlP5LI/JTqiRweq/aBW3l/WQsarN/rtm5ErjhDVL47c5cGNcy/gtx/jRQ91Ww6/1r/G+aGUzu0vSW8zswkrZnu5N5vGPxz1Dz6NZK+fISrl18Mnr8jQbIOo8oS/BQ8LKHsG7WWXRIJVdAL/H7TI+9WIkuQk3fJyFjxl2wReV6rS/uiJpM7ydfwMpwQX+HlY9NZE0g4Ym09YkTSYzO6hSbjyyw2UZpiu/WYE2xi5Jv8bbhvOsQ5YtuQfkV4GlzOytqe/ewMy+XymXNY7qUNcZdePWYVH0sxnlsvqEmt91yvw2Nz7mehOuA7mAmdX295nHuhl4pzWHYp9jka0s6IQ1MgvMVTMJnHcs+1aXTA6jQK5hKNGLS/REkh2yNV50Wzmw3gVXMbNjlKe/k6Xd1MPqRq7+VlfBxRId3c/V7MHXUXCxmITJ3dU/Yg0tg1fjq7flcy6vOJUzZ9RNkrLeVzO7DVhT7rZMmw7uM+a6E7WZiypGmncCryXpg5nZI/K0pHXMi4vC3mwdtF7Iv4dZQo/k69VAF7FgSauZa1MUnXMRqrCUpKWsPmyiX1bB26wmlJ/tJkssPO1vf1ozC7UYpZIxaMIMQuoxDFS+yniMmR1d2nawmR1cs+9yuN/c+KSqZSU7F0veN2p4xk3Hw70Lz7hqVrOZVUmf64zsl1N/3tV70zX7YWIpvJ0q+pYFqA/3vSFNTH+Yjr89LoK6dtp/2cMxK4xH9SLuG5nZAZVjn0tjRfdhOpOrWZVbLitcDMBcw6ibjlEvocFdM22a6/jkZpt8ExkZ/tQlE2hpnPkd3Bvn66nc1/G2eoPSvrKy4lXIycj1K1xD5Dj8Gfso7cOXu4ZD5yD3at4L98j5Pv5Mn5u+/mr1+N3ujaTNzENP6/T9ymH8ZR5Jf1PoLCZ/Ot6GdxJSLvgg7hFceFNek7a1vX9qkzmzl+cxlf+dUqpxYLqkprAg+ULYAbjBqQiLewxvE75mzZp3uQkuIF+Tqeuz2EsdEx2TLqiDN7mktevGFGb2p0rzXif6fDLeBx2YPv8f7jFalb/IHUdV6zoFf/8XLH2f9YxL+qaZ7as2WR1tDFEveLKXveg+V8jtE1BG5je5d+0baEhkXIB7tY2F3FDsWZIwDvWJ+hAK7oFeUlSPLGp2ib4nTdxnukQPs24A5iJnTwOvseEJj+Wm2swVXG3r/UGr/k6udlNuHXP1t3IEF4vvuunqHA4zPfi2LW0vttWxWrlTSquR1ZXNc2msOHUTFc16X+Vhf9Nx0cETUmf/P2Z2UalYcV1zMhc9b2amJHSoeu0LAKw1hWo7cu9hrtBjrl4NdBcL/hQeBlm36lcWj+2JNJF/CXclL/gzNZkAyc8EkisWXuzvhC77GwbF6mWujtp/45p0R5YM0e+gRgzVKvpSkrbFM5L0hVo9406iNDgsjOxWL2jbjrLBeCpuLK4zrOZkPwQPhbxVDQ/GTagXii3aourkaUNan/McDRNoL+JeNQ7lZrAD748+IPdq7aRZlVvuQnkoTzlcbObkVz3qiOFhwCclg2ERGrx7aicPrZTtmGmzj0lpVoY/8jOBrof3Z9fiY8wikUKZTlnx2hn7czJyfRafFH0MZoZXtstMVTZ+FOHQuSLVZT4MvM7M/in35Dhb0gppvFPVMcu5N5vgqbWbQgkTRmsihbK+zIL+0f5ZLZP4q9WE2NeRvBDaTb5zsxr28zw+k8ZYt8nDLR8tHa/gTPwabWrJE1fSK/BkHWdRalOUn+AC8jWZcp7F7DomuhkhymOJukWD6pjiT/KFV0vXc2/qx8KLm9mZkg5I5/CipLr+PXccVdS1qGMR0v7e0ve5z3gxFusnq2M3cucKuX0CdMn8lrgSHzMfimundgwFzcE8Gc7aNLRJP2kD9Gobecws/vr4wyepK+Ad/vKlv0UHsO8b07+3AfMU/x/2OfdxHpt0+ht2/Ur1PB3XixjGsW9N/96R/p0LuKxN2TnwhuoAfAJ0b5ty9+BuuznHXxvv4PYBXttPHYHzcdfry3GNil+lz+fh7rfV/V0MvKP0eRs8TGYs1/GWmm13tCn7Q3xw+6b0LJ6AhzqVy9zVw7Gz3lfg9vTvf6drs2ZdvVOZ93bbhk9ej8cz43wYH6h9os/r1+s9/BAuZr4JjQxJH60pNw+ux/JTXIvmk8U1qim7YzreQ7j2wH1112E8/trdh5pyN/ex703wCcHcg9jfqP7h3ibT0rP0HXzx6dYefn/9GI69Pz6BnrNLuZZ2ppe2B7iyZtsW+OD0r3hf8nvgTW1+/4rU3m2Da36N9ZrXtTN12+6gNDbBRUBb2kc8g8xrMo+9fN1fv+VS2XfhHo5H4S79g3guFwIW7lLm8/iK87vxCdqjwCGl73+FT0peUdr2Ctzj+OK665257ebqd22esbnxydBteAj8+zqcy0Y529L2Xev+Oux7UWCNDt+fAixSKX9SH/fsN5XPC+CLQkdWn+9e700PdXg1bkD9Q/q7GfivmnJvxscTO6Tn913Au9rscyW8ffwrDWPOSn3UrdfncXncwD0NNzofiXutlMvc1+F491U+H4V7sl+MG7g3wz2E6n67brp/y+CG658C6/fzLObWEffiugP3tH0BH0vcUWyv+e28+OLTOal+n8QTqlTLLY638X9J9+80PJtvtdwVwGKkcQU+bq97r4tx1BtpjKP2qJTZL/19qvRv8f/9xvB875Ozrcd9Zs1n6K1PuDvt5yzSvJE0li6VWRh4O25AvwzPXvmlMZ7LG+v+xrLPyfQXmkMjSPLk2A0XF94Mn6zNZWZvG2rFZlEkXUZD7LEcWz4W98rcY99gZq+XC6rtiQ9Mb7BW8bheBFe76u8Mso7qUX9LGYKLPdRtpgcfUM5W0FY3Sh4m9zEa+htXAcdas8Dd9/AQmRy316z3NYUsrCHpW7jmxzlqL+xZJ5LetE3SJ/B78Xr8Ov7KzC6mD9TQtqjF+tA7S15Ap9Tdgw6/aSsW3M5dulTHutCA3ON+O9W1LtNTudzB+ACuWyaQbscrYuH3HsT+xoMaD42ZX1HjqVF+ltN12gIXFK8L2Srfy8JFfhOrEWcfBGpkcrwcNwoX3gfTgF+a2atqflPWKyjq+C0zqwsPXIzGCmOT2LNawyGbsEroQtrXQTSye87ADRUt4TnK1DBRvYj758zsh5Vyv8GTRzxI9xXdbJQhnK9KhtAO2041s50zti2EX8einb8Sv461adhLv5uH1kyb99Xd93bfSToJv3dlj8k5rVXg9nozWz95TB2NexeebWYrV8rdjhsSvoRPOo8HXjCzlnTNOX1H5buO2kiSrsCN23Pixqm/4hPdlvC1uv6sXR/XiTQm2888FLvYNifuEbijmc1R2t713qhNqF2B1YTcycOuDrSU7lseKvhVM9uwUu40YDV8Elt4uprViwpfjxvOi/fuffiCznqlMkvgiz0r0Bxq/MFSmeznMbcflnQRPqk+xcz+kra9HPfK2cLqxc+7JrgYJLl1VO9JF87EPQuLsNsdcINyXaatnHqujYf7vhr3xl4CeI8lHaM2z2PRJ1n5eVQjCcaq+Dzl3FR2a1zn6UMd9jmT6jPepp0Yk+By7nymx33ujRtCb8cNQMsBp5nZGyrlXoUvxL0B97L9o5l1HNd2Oe75pY9T8XH2zdanDuVkI8LKRhDrLUX1yNKHG/iwGGbIXpFq8/N0TrWZlYo8sThd9Hf6rGNtOlDrUX/LPOXk+uoiuJhJz7pRyQh0FI24/zqy3V57eF9vToObFYEDkrt6k0aBXGTybcDSak6BPY3WkJaX4x5ft+CD5ks6nE9HSvewdoKGT6zK25oyZJT2c0jp/y9JWkLS3Jbh5ivPqHK3mX0nfV5QJc0Q6t2lZx6OmtCAHtgM+Jik3+MG4nb3e9f07/6VY/c6+Cm0b4oB4f40t5F9D6YGhVVCvzKYGVphZgfLRVDbDVjL97Jwkd+mvuhA2INGJseyMeYpfLJWR/kevYDXcfc2ZafiRuE5gdUlYQ19mf3wsJzccMgf4QbrIoPejnjoUcvkjPownpZJqZn9ME3yCxH3z1q9iPtb25xf36gknI97DsyFr7hXw6K2oDWU860125qEkJPRoEXgHm8T76KRSnnndPwWI7NcB628YHCFpONLhpI/SPoM9ZPSP1X3l/a1F278nZnhr6bcl5MR61M0MoHuW1NudzMrQo3/DGwjqWoM2wCfFC1RmShOw72OW1CeNtJC5mEdH8IzFx2kZimFMlMkLWIp41EysPYzz9iFSn9nrpW3i1yPq0zOvem1LQMXvr28dPwrVB+6vaaVxM27IGvOMHmaPNSqzLn4AuAltA81zn4ee+iHt8fHUFemfRnuIXMelXTk6hLGWynbUVdPnbXtzJoF6bPqWDX+ZLBq5TiXJ4Ns9VxWBD5Bq+GuaWxtZrfIF9xWxd+rqtG1eB4Lg0/Rd26NtxXlfRXhjRcBaxfjZfkCzFm97jMtFLwfWFHSeZXf96wPVqHjXKEfzDUMy2PhP0iqJnG4H/cOm4GH6e+WM+bsctxqNstlca232YLwHAqCSUTOSo3aeIFUDTc9HPNTNDrtYjL7BG5Fv009eu+oIvZcql+L2PN4IE8hfzCtg5Vy+t7alac+Bh3l407B9UQeMLMn5B4CS1spK4Y8NepaeLx22QDzNHC5ldKMpvLCU3zuhk/AzgS+nwxw/dSxbjXpjqqRJD0TBVNxzYx7qqulysz4ksreig9+LH2eAtzUbsV7kIzH/c487nZ4CuenJH0ev1ZfssGKa/eF2mT2KmhnfB1llJnJMZXNujfJeLo9rZ4DfRnjJd1slWx+km4ys3X62V/6/aXW6k3Usm08kGeafC0eYlF4ls1sU9Q5a+i1ZrZjKncAnm56XhrCtQKeB75nFXFt9ZA5S9KJuNHqlLRpZ+Cl0qr8IvikdBvcKF+elB7W77sg137ax5JGTHrnDq/zOsnY1ya4V9xH8QlSwdPA+Wb225rfdM0mmSbtW+LX5kAzu7GuT0hld8HD3s/Gr9F2wFcqBpGBMo735hzckFzUfSdgHTPbtlLuBOAoy8geKReGfwI3ABvebsxDMlCb2T/aPaOV/fR0zrn9sNxzdxnc+/Gfpe1NGeIk7Y8bHLoluCi83o6jNWPYzen7Jc3sUbn3TnnRRcDXreK9k1vHXpB0MnCcmV2fPq+Hh7TtWSl3O67L2SQ+Xje2VkZSmGTweXfJ4LMgnnG2RfdN0r24IfLf6fM8eHjVar3sM411VqRmQRUPB+t4PztRGduXM/eNaWwv6e20ilwfUvp+iiU9vfEijbXv6MEQPKkJz6FgtkfusXAM8Co8tn8OxpA5p8djL4YbKopsM1fjE5C/V8plr9T0awTqwOtww0PhZvl24Ebgo/IQtuPpzXunF7Hn8eD7eEx502ClTGEUkPQySh3SWDCz/8izC73f+xmuNLPzK2VuB26XdIZlpD42M5P0Z3w1+UU8fv1sSReb2Wc6/7pBeYKmVoH9FvF4q6SClXQ4Jc8RNcI8tse9GrplfAFfrJi5WpGu18w+Sn2EBuSSawSSNB/uCbKcmX1E0ir4qmNLWvBM/tdcuHJj3HPiCOBYXD9n2FS9m8q0eEu1aUf/aWYLVX8sF0X9Mi4EfCGuv7WvmZ02yBMoHW8zM7sMeFg14YlWH5KYe2+2xZ+Bjm1Zmlj8CDizi/H2cknvww294KmTf17ZV202w9L57J3KFeF0i6cJZTmcri5T2njQTTg/y/vTzA4FDpV0aNUQ1IZnJW1sZjPScTeiITxdZd2K58BlZc8B88yJ03GNlZZJKclTVD1m+MP1e8pZoP4hqa+wjtTvXynp5B6M2jnZJA/BNW5mJMPQSkCLoSn9/gdyj8HN8GftXTlGk7GQc2/UQxbQUt91NT7J/Wk6lyupF9feGNhVeeK626d/96hs/yCNNvUCSW+zmpT0vZxz5Sd1mdearoOaM8SdKKlthjjLT3AB8KKZHdvhXAr5g/9XfW6TIaivOvbIerhX2h/T5+XwJDp30nwvn7NSNs52KD8pzHK4cbvgedoLUp+KZ7I8J+3rnTSM2dn7TNf4D3KB50csySnIvfyXwb0I+2XgY3t5lsT58Kx4J+L94Q2VYkuld7tj1s4ej1tuK4qF3RZvslmV8BwKZnvSYOZ9uIvmOrhL8ypm9rkJOPbF+ApMMSnaERcz3bxSrutKjcYpjE+uh/DuYgAi9146G++cbjaz1Xvc311m9up+6jIIJP3aKjpINWXegU8Gl8I1YZbHPWP+q9Pvuuyzmk56B9wzpmWik4wOhwKr07xaUvZu2hsPc/ob3mn+zMxeUMoMYhXdii51Wwg3LB2Ka5MU4RUzzOzWjN8vgseWr5I+/wYPCTkfX81uos5oKOmnuJBjMZDcE89Ksm36/qDqbyr7HPfwUEk/xgc+u5jZq9OA6rpuK70d9nermb1W0qHAnWZ2hsYY9z8semlHi9VxSe/EjSufxD3j1qyWHVDdvmgeDjO95muzen2QrHsj6Ze4cHq7bEZFueXxyeH2+Krzj3FD0R8r5Z7G9eWKScUcNFb7zcymSSrCGzfC24gfp8/vxdvkT6Z97UMjnO5hmJmF52nc26ZdSN3AkPRpYBXcwHYoPhE+wyoeXGqElZZXvFe3RlhpuewiaZ/ltrGaJn4tfPK0EH7e/8C9AVpCoiTdgt/D+9PnlXDtn7XT5/KkdC1KqdVV8rZUwwsiyxMxGaDeZM1hWFeOZXVarlnzGVpX2lu0MpSpjTTK5NwbSX83s8Uk7YuHfzZhZqeU9lf0XefhE9LinSnKVr1yBuJ1Whm3LYBProuxXtP4Lfd5LJV/r5md1WlbMoRsYKUMccCpZvatfvokZerqqQfP80HXsbTfLI0iSe/H252LKudS9Sa9B2+7Ok6wJR2Ie9eVDT4/TobwuvJr44vE4HpDLWOzNvs808y+Wil3E7ChpfArufbYNWa2bqc6dzmfgY/t1dDqLP5dAPipmW1ZKnMxvshQ9vLb0cyq2et6Oe6upY8vAr83s7FmIp882AioYsdf/A3zD5+gQ3PGkGsn6Ngt2YqK+ozKHz4Ambv0eR7cUAI9ZCMq/T47I844nc/X8MwvG+Cu1mvj4UzlMrfjwp9F9oVN8cnUWI57BzCl9HkO2mdUm4ELM9+BG6YOBr5YKXMI7TM8vKrPOu6Du0x/Me3/DmoyoNHIBnIHHk7zGPDx0vdFitfn8Cwcxd+DeFhd3bFfhntWPIa7yJ8BvGxYz0mbOhZtxa2lbbePYX8X4J539+MZN+YZy/4GfK6rpX/XrvvrcG26tqO4EQA8U+BbxnodM89nCrDdoO8N8BM8HOp4XBvhaODoLvteBV9FfqnN94viq9mb0CG7Jy4wPVfp81y4ka1a7gvAtPT/z+MTh5Z7OI7Xfgu8zT0cF46tK3MrNLJspvtVl4XyQ6n9eTyd/7O0yfCZyk8rzr1DmTcDf8SN01fgq+eblr6/ExfRBl+Fv4mU2YeaPhAP7cnZtgveTn4Jb2/vBXYe47W+CNfGuic9OyfVHTuVbZtNEvhM+veY8nOd83xP5F/OvcGzVi2P9+uLVv8q+yv6rn+T2Xf1UNf5cD2W76XPqwBbVcqcimuUte3D+3ge696jWyqfszPEZZ7rg6Xr9mDp8wPl60gPmZ8HXcc+zulQPJvqlXjbczn12bjOwpMx5OxzbXzc1TZjcB/17LrPuuvFGPtgxmFsD/w6/Xs9vsgxD7742e1cJl2G71H6i7CyIIBnktX8Nnm4w6P4yu1E0DWEYAQ4A7heUuG+uzXwwxQe0I/LeLbY8zhReA0VugrFymB5ZfUFM/u7pCnyeObL5doiY2VhfAUbfFDUjnnN7FJJMl+1OljS1Xj2HQDMrFYUOn13T7vvvZ9dfgAAIABJREFUurA7nmb2XwDpnK/DJwhltir9/0XgL1byaLMkIijpWDP7WLeDyjOq7Ghm7+tQJjs0YBx5PnkLWarTyozNfXo74C24zsgTkpakWXdhmJSFlMvXu+59gd7a0fPlGgrPAnsmb4fn2pQdCOZhih+n0dZ2I/fenEcppLITabV7O9x76CWaszsWZT6ED+qXwcMS1sdDO+v0gZbCV9iLNmUB6sPF3mNmh2hI4YtmdrGkX5OkDCQtaq3egx3DSkvsg3tgXm9mm8pDT1q8BlXJViapU7aya3DjXnGNj8fbvYI5LHmGmdnv5ULOZyePg7qwyyxxbRufMKzFzOz78pCbItSsXaj5nHgGviNhZjtc6Bh+FhdgvZ8ab5sRIufeHIsbEVbCDSkFRVs20yO3176rR6bjnqdFxrOHcEPCBZUyG6c6rIQbTa82s2+VymQ9j+otwcWfJa1lKUOcuXfOVrhxsWdPNjNbMdWhVrutVO5JPBRph4zdDrSOffBOYCVrI3Ysz3BleJuclRTG3OtoYBqDkpbDvcnPKW+ziocq8FdJ7zCz81KZbdLv+jlmEUY7J7CbpAcY3Nj+AkkL423RzWnbiZUyf5O0E81ZO/sS11abkOCCCZynDJUIKwtme1KH+hi+6vpJfNL+XesjtXofxy5CCAoxtSlUQgjGuw45SHodPmARHmp0U5efdNrX8nXbbZzFf0vHP6hms1mzwN0leLjLoXj2t8dwXYoNa36be9y6dNIHmNmPaspeg7sPnw1choeEfM3apK8dFKljXNcacehTgRutEuaQjCIPmdm/08B0DeAHVtLP6OPYV5jZmzp8v7WZnZ/cfeuMQ9V4/oEjaUvgQDyU5yI8rOcDZnbFeB97WCRj2J40UqtfDRxbPCOlcj21o/LQoKfMs+nMDyxo9Rm0BkaanDyLh2GVhVnHXVw7GUfmwo1TZ5rZA23K3UnD+LFWYfwws+1ryu6GexVenjZtAhxspTCZVG5o4YuS9sC9Yp7F+7liwlDVrOoYVloqd6OZrSsXul4vtUF14tM/wbOVlUWm1zSzumxldamsFzGz96bvs1Kr9xIiM15Iut7M1peHgx+Na82cbTVhxvLU6ptbc8j4RWa2oVrDq5qYiHcmh9x7k7aPh8EnGyVh+fK7J+l2q4TTJiPduvh1/yjwrJWEh3t4HrMTXMj1EF+sa4MlbWR9htSUwoE2xnWBjgA+Z11C+9vsa1zq2MPxf4x7Uj/W5vtN8PbtMJoN/8K998bdGF8xbswLrIhnS6tmeVwZb++WTuUfwsPle573tBvTF4xlbJ/GHx/Dx8O1449kEPs2Hg1g+GLKPv0ct3Que6V/yyG3z9gEJc4ZNmEcCoJgKKgi9lyzsjFex+2aaStNVp/DO/Ud8Ynu6VYRCu/hmMI9AV6kkU761+0mw5LWxV3bF8ZX2RbCM3dc38/xe6jnfriOUbHqtC1wspl9s1LuNlxXZgVcrPQ8XJT3bWM49lfw86xO3Kvx/OviWYtWoJFUYayrU73UczHcm0P4BL6v1bbJQpuJ88JWySLT4z4HLeyde9wHaza3GCoy99VOfLh2tTQZeV5Ha5bEQyrlsowfpfJL4YaPe/CwlUesVX/nAtzAvHmqw7O4Rti4aDxVjv1bXCek43uS+oOjcS8aAy7FRcofq5Q7BxcG3jeVfRwPrXtbpVwv2crqJugzt+VOStWs3ZaTnGHgJE+Kq4FlcY/PabhxscW7rdM1kvQJGoauh8tF6POdGQ+GbTDoBUmFB+A15lpIK+PZ4V5fKnMpvmB4HX4fZ9S8Az2ds6S5LCW4SEb5Za1Ge2s8GKZhetBIugJfCLuRDh5Bysz6OhHIdYr2MLOqCHrx/QK4LeDpia1ZHmn88TQNXdam8UcypO5tZkcN+LjXmNlG3bbNqoRxKJjtSROGOk+ECRn8SFqD1pSXddlzZgk0DmLPY6zPPMB5Zvbf43yclhTVo0gaTBReYu1EDwuhz8/gq5rHjHXAJ+nyms1mFSFVSffh4T3VdLLj7nkm6Tzcdfk8S6F3szrdJs6lbVvhhszC+NFWCF8DFvYeBupdfPhCPI31LTSndK5m/ssyfqSydSFo19W8M/PhIXJ3mtlv5SFyrzGzi3o7695J5/0uM3uma+He970JblC+0CqhHpKuA/a35mxlh5vZBjX7OZmMVNZ91G9CF0B6nSjJPVQ/URjg5R7C3y5fo2F728wqpAWinfHQ7baep5KOwg24/8bDHa/C3+l2mfZyjn0F8A68Xb4N+CsufN4xA+ggGKZhetCk9qYFSxmCNQKeg3W0MVa9HPfkWsrM3ippddyI//1h1LEdOeMPdfE67/O4t+E6mkX/sSHuCT1pxihjIYxDwWxP8gQomIpnfFnUOmi6DPDYJ+ErEXfTmOia1WTPmVWQZ2jZDLgkrShtCuxgZh8ZUn2aMm2lbe/CXYNfhk9yx5TxLe3zO7gXzo0ZZdfBw5eqXgYjEe8sD5H5Jl7Hrc3sQU1QFjqlrHzjfZw2x94E14t5O55O9cfABVYJsZqVyJ04S/od8C7cANFxYKHM8IpBI2mXuu02hpDE5GX4rLlGziuB1YBfFiv1pXI9vx+djB/p++wQtGEhT80+Hfg1zavte1fKvRIPKXt5MhiuAbzDzL5cKjMFFzzveh3lITU/oKHt9jiVbGUlr6+5gFVxUWrD293f9NueSdoaF8md8AUQSZebWUsYWJuy6+JJAB5Jm5YEtjezm9v/KugXSTcDW5LheZo8OnYDPg28wszmqSuXedzCe+dDuNfQQRPlyTJMw/R4kBYDVjGzS9K5zWGNDIuj4DlYNvhNwTWeFqsufsqzbE4HDjSzNeVhibfaGDIljgc54w9lep33eNzX4WGaRf/xBPDBsexzMhGC1MFsj7WGCn1T0gyaY7THi/Wtx1TwswDjJfachZrDQOYAlsBj8st8HTd69CvsXMemwB6S/oB3YJ3E+k6nxjtmhNgN10L4SjIMrUjD7bcveljJOkjSiXjYSXmyOe7edtYQeJ0DN3B+GB9AjIQ22CCpTJx3kdQ0ca75yZ+Au7oZhhKDFvbOpZymdyoe4nELbkTol6uANyQj86W44O32eDhqmWslvcbM7szdcbEi3YHnzOw5SUiax8zulTSuumR9cDyum9atLTsBb/OOBzCzOySdAcw0DiUD3O2qF1it8mZcb2iB9PmfwLqpzym0Wraq/eXY+TJuAGhaABmnY1W5VtK3yZgomdmNyaC4Kt4f3Vs1agYD5Xpc0Lht0hG5aP4bcC+bP+D9y9VjPO6cySizHb6gM2Ekj8Gflj4/iicrmHRI+jCepGFRYGVcr+c4kpC99SauPV4sWPr/i3iCm5/UlFvczM6UdACAmb0o6aWackOhx/FHoQVaJCZolzQjm2QgX1PSNNyRpi6RwSxLGIeC2R55GE3BFFxLZcE2xQfNdZJWt7FnKJlMPJFWxa4CTpf0GK2ZM8aTjpm2En8ZsGEIXNwzl79ajUbEKJAMI58ru0ib2YO42PZYOJm0kpU+/x8+wakah3bDvTPmouRtR2kAOp4ko8bWuAFgbRqCt7MavU6cPwP8Qp4ZqWy0O7JcKIVXHIdnD1pW0umk8Iox1TYDM/tEpS4L0RCc7BeZ2TOSdgeOMc+o1xKKyfhkaXxInsnlZ8DFkh6n4QUyKryYGb4yn5nd4I9H47c15ZYE7pZnAiobP6qZgNZJf+fh1/r9uFbIRyWdZWZft/ELRR3mAkgxUSoveHSaKK1LI6z9tZImRNx/NiVngWhe3Ovs5ppxSb8cgmsDzkgGwZWA3w5o37MTewGvx70gSZ5QLxtulZoxs5bMjW34V4qaKBZo1scNW6NCL+OPC/DzKDoPA55SKbNdr6i3bJezHGEcCoLmVM0vAr/HQ8smglNwA9GfGU5a92GwDS72/EkaYs8TlgGg04QghZMB3CTXRfkZg/NOWRK4u+SCvCCuPVBXn6F5x3TDPLvUEpLmrgt1GQO5K1lrDsv1OT0T6+GGje8AV5jZKHp2jZk+Js5fwb0zpgJzd9ivSdqH5vCKfdqFV4wzzwCrdC3VGUnaAG/Ldk/b6sZWvRiHszCzd6b/HizX7FoIfzZHicslfQQ4n+a2rBpm8bfkQVZMVt5DvYdB7uRnMWBta2TiOgjP/vhGXO/q672cRI8MbQEkN6QMQNKpuAfEbTR0sIyxedIF7enaBpjZNwZ9UDM7Czir9PkB4N2DPs5swL/N7PnCgJ1CsUZCm0XS+XROwV41nu+HG85XlmuPLQG8Z/xq2Bs9jj9eR/NCwNvxhYA9ioWAPqpwEp7tski8sTO+eNmS7XJWJIxDQVBvdd6q6ACqK98D5iS80RnV8KGBY81CvqPmdbF16f/P4BPYgrF6pxyLe5oU/KtmW8FQvWMy+D1wjVygubx6P5Z3JXcl6/ohettNB95vZiPjfj1CLGpmW3YvBmSEV4wHlQH0FNw4e+YYd7svcABwjpndnVblW8TVx9FLpdh/txC0YfH+9O8BpW2Gi7aW2Qv4HrCapIeBB2kNzcPMrkwhqEWI4A1Wn1p6OaBsvH4BWN7MnpU03iGM2+DCuxO+ANJDeC74hGr1zFDQYIyMdxtQRdJnkifjMdQnXdm75mdBe66U9DlgXklb4OLT5w+5TgWH91h+ZdxYuSxuKFyPyWsTGI+FgJXNrGxA/aJcpHq2YLI+CEEwSF6HDzTPxQ1EW+Mrfn+agGP/cVTDh8YLjYPY86Aws93GcfcqD8KTfka7Nnho3jGZPJL+pjC4EMxiJWulLitZGwO7Djg8J5ergAOS5smEpWCfJFwiaUvLExrtRX9rkJQH0C8CfzCzh8ayw0KHqvT5ASAmXQkzW7FbGbnQ9Dpmtrlc4HuKtUmtLGk74BvAFfhzc4yk/c3s7ErRM3BD8rnp89bAD9P+x9uw/DLgUXOh+lNSKOrLgaq+4XhwMnnhueAr469gkmrABF0pQuNvGmotZh3+B/cOvRPYA/gFcOJQa5SwRsa0mQkS0uc5gDox88+b2VlJK29zPILiWNxINNkYj4WAZyVtbM3ZLvvOGDjZiGxlwWyPpIuAd1fCfc4ys7dMwLG/CyxMq8v9qHiIDBx5VqNBiz0PFEmn4KEuT6TPiwBH2BiyyEn6KT6hOTZt2hPY1My2rSl7AnDU7KRFJWkq8HHgv4GngetwDZfnKuWyUoePUx0nfQr28ULS08D8eDv2Ah2MvsO6h3Lh9GLSXuhHvdzMfj+GfV5O/ap832KYsxLyjD77AR0NqpKuMrM3ZuzvdmCLwltI0hK48HNLpjt5xpmN8WdxhplNyCRZ0k3AhkXYraS58VTW63b+5UCOfaOZravmTIC31bVR6dldC8+8WB5/VENQgiBgZp+xnJndN+y61CHpemDzkhfNAsBFZrZhpVyRwe5QPJPcGeU2YzIh6fPAO/EFfvCFgPNwg9f3zKzFAzVjn12zXc7KhOdQELRanZ/HBRongnnxQdkgw5dGnfEQex40axSGIQAze1yeknksfBQ4Gvhf/B5fime+qGOY3jFdGacJ8Q+Ap/CQCPCMH6dS0f+aaNf8Ciub2faSdkh1eVYVBd3ZFTNbUNKiuIbP1C5lh3UPz6Ih2Auus3IWzVnMeuXTpf9PxV30J1Jgf9SZjhtUi+v+EH7Nq952F0v6NK1ZtqraRFMqYWR/xz0YWzDPODOMtOxzlvXYkk5JWx2uAdOL0OzBE1SnYIi00aN5EvcoOr66ABPUI+kduNfi3MCKktbCRYpHyZg6tTAMAZjZP5OBvsrDko7HvYYOkzQPbdrRUcfMviTpFzQWAj5aWgjoxzA0BV/AKLKVYWZPDazCk4AwDgWBT0BvkHQO3oG+kwnSwhnnMKZRZTzEngfNFEmLmNnjAGnSO6b2Mk1o3pdZfNy91sbIeEyIV62s/l+evARGiWGlYB95JH0I2AdYBhe4XR+4lpTmd0QY+KQ9GSDKXCPPbBI4uQbVwitzr9K2Om2iCyX9Cvhh+rw9Ht4xSvxV0juKkHFJ2wATJbieLTQ7wjpVwWB5AH8Oyu/MX4BXAifgupdBdw7Cs5VdAWBmt0laYYj1qeNfktY2s1tgpvdkXTjUdvg483Aze0LSksD+E1jPgTLIhYAk+fBx4MzZzShUEMahYLbHzL4i6ZfAG9Km3cysLhXxwJG0DHAMnsrZgBl4ONOYdDBGnGkMXux50BwBXCvpbLxu2+HZmHqmV1HItGrxczN7dT/HmwjGaUJ8q6T1zex6AEnrAdeMcZ8DI01oh5KCfZKwD+6Bc72ZbSppNfIzS00UA5+0J8NxwRRc5PcVY9nnLEaWQTVHmyiV2z/p1hWrxN8zs3MGWN9B8FE8S9m38Tr+CdhlIg5sZrdI2gRYNR37PjN7oVxG0gwz2ziFgpb7pJHR/wsGymsrIZvnF2Gcku4eWq0mHy+a2ZMj7iy8L3CWpEfS5yVxY2ATZvYMpTG3mT1KaI+VyfVknSUJ41AQ4AMq4JYhHHo6LpxZhM7slLZtMYS6TAiTwVvKzH4g6WZcOFfAu8ag/1MWhewq8pZWLW6Xix7/sc9jjivjNCFeD9hFUnHOywH3SLqTEQipMxupFOyjyHNm9pwkJM1jZvdKWnXYlapQTNq/g7+LDzH2SfvNNN7rF/FMfru3LT37cTCtBtWZfYCkzczssmTwaaGNR+m1eEjgf/CUxSOFmd0PrJ/0PmRtxLXHg6TdtiduPDPgaknHlUOHzGzj9O+gkgkEo80S5fGEpOWAxdN3z7f/WVDhLknvB+ZI2ml7423RyGBmN6aFmcI4fG/VOBxk8UG8/dyzsr3qyTpLEoLUQTBE6oQi24lHTnZ69aAZJpI2N7NLKtt2NbO+ww0lrQt8DtezKgzztUYPSZfhXhg30LxqMRKx7UkLqTohPsRSZoc+91krUlwwZK0hAJJR4WQzG7kJ6bBJYbm74SuXm+ECjnOZ2duGWrEaBjlpT14xTZNx4NjQ8WiQNHAKg+r1ZYOqpIPN7GBJ0/Hrp/K/VkkCkMIXvwBclspsgrc9J03IyXRA0k5mdpqk/eq+N7MjJ6AOZ+KC/qelTTsAi5jZe9v/KpiVkfQ23Ov1fvydWRFvs64APmxm3xxe7SYPSbvnQBpe778Cvjxqbb2kDWkeZ2JmPxhahSYhbfr148xstshYFsahIBgiki7BU88WseA74GFto6TTMRAk/d3MFpO0Lz5xbGIshpdBI+kq4G7gU3iq9hOBf5tZrXZD5j7vw2O678RXvIF6o0cKC2hhVDQiZtcJsaTf4DoNE52CfVKRnt+FgAvLGj/DRtLLccHzpczsrZJWBzYws7o037n7PBMXUj89bYrJeAlJl1b7s/I2SZ+i1ShE+n+LQSW1oxua2d/T58WAa81s6F5qkvYws+MlHVT3vZmNe5ilpNsr2m2124LZiyQ4vBoNb5JZuq8eNPKU8F8zs5HW5ZF0KrAyrvv3Utpso7T4Ohlo068vbGbbDa9WE0eElQXBcPkg8G3gKHwwfC0ll/tZjL8k75Dd8HCtUWYT3DBUCCJ/wcx+2KF8Dn8ttE66YWZXpolskUXpBmvO0DNsTsE7zqPT59rMYrMgbx12BSYDo2LErOFkPGz3wPT5/3BNgb6NQ0wOIfUJJ4U3zQcsLmkRGkafacBSpaILpH9Xxdu7c1PZrYGranb9EO4ZU/A0rukzdMzs+PTvMLW2Rlq7LZh4ksfLfsDyZvZhSatIWtXMqhkDgzaY2UtJ3HnUWQdY3cLzY6zM1v16GIeCYLh8CdjVmrNiHU4jc8usxLG49sRKuP5OQbFiPEqxvIvgGjj349mXlpekMXa4B0k6EU9h3zFLm6Tt8JSpV+DX5xhJ+5vZ2WM4/iCZLTvOUQhtC8bE4mZ2pqQDAMzsRUkvdftRF2IyXs8eeIjhUrguU2Ecegr4TlGoMKRIughYuwj1k3QwnvK+ysPAryWdi/cb2+DZRvdL+xv30K1uSFoC+DCtoR0T0a+XtdsMWJ4R0m4LhsJ0/B3cIH1+CH+3wjjUG7dKOg+/duVw/1FKpnIXrv8Y4tJjY7bu18M4FATDZY3CMASuhC/ptcOs0HhhZsfgRo5jzexjw65PF67HXYhPSiFUh+Edw4Zj2OduuFv3XDTCytplaTsQWLfwFkqTjUuAUTEOzdYdZzBp+VcKQyoyZ60PPNnPjorJNv4+Vyfj/YrXzzKY2beAb0n6RGr7u7EczeK4z+PGlSr3p7+Cc9O/oySufC4eansJjdCOieIt+OJGkX31KuCJCa5DMFqsbGbbS9oBwMye1Yin3BpRFgX+jmvqFYxapt3Fgd9IuoHmRciR0KucRIx0gpTxJoxDQTBcpkhapOI5NEu/l5PAMASwObCJpC+Y2SGSDqd+otILa5rZazLLTqmEkf0dzwo2KszWHWcwadkPOA9YWdI1wBJAvzpiWw2sVrMwZnaMpFcDqwNTS9urAqmn4h5A5+ATrnfi4aszSbofC4y67gcwn5l9dkjH3hb4ED5hFX5dT8g00AWzJs+nRa7CKL4yJcNBkIdNgky7eHbIYOy8ZdgVGCaz9CQ0CCYBRwDXSjob77i3A74y3CoFwAG4d89mwCG4rsURNDSA+uF6SaubWY5XwYWSfkVDqHx74BdjOPagma07zmDSsjKuG7Us8G7cyNnXOChCDPNI4sxvwo1Dv8Cv/wygyThkZl+R9EsaHi+7mdmtlTIvSVp73Cs9di6Q9DYzG0abvTuwvpn9C0DSYcB1QBiHZkOSh9BxeEj/spJOBzYCPjDMek1GJB1ds/lJ4CYzO7fmuwlnhPX+JhWze/8e2cqCYMikjDmb4at8l2YaD4JxRNItZra2pFvN7LVp25gyvki6B5+cPoiv2rVkupI0j5n9O/3/XXg2MAFXmdk5/Z9REASS7jCzNSRtjGctOwL4nJmtN+SqzbIkb8I1gVvNbM0ktH+imW3d5/6OAFZhhHU/JD0NzI+38y/QaOunTcCx78RDkp9Ln6cCN/bgtRrMYki6GU+/vj7+LF5vZn8bbq0mH5K+h0sDFFpo78az2i4LPGBm+w6xbjPMbOPU9pQn9hPW9gSzDuE5FARDJhmDwiA0WryQQhgKN+wlKKWf75Mcb5vrgLUlnWpmOzNasexBMNkp9F/eDhxnZucm4eNg/HjWzP4j6UVJ04DHGFvygZHX/TCzYeofTccFu4vFhG0ZWza+YPJzPbCSmf182BWZ5Pw/YDMzexFA0rHARcAWwJ3DrJiZbZz+HSXttWCSEsahIAiCVo4GzgFeJukruC7J/45lh5luqnNL2hXYMHkOVfcxMhOgIJiEPCzpeFxT7DBJ8zBaWl6zIjdJWhg4Ac+Y9E/ghn53Nhl0PyS9sW67mV013sc2syMlXUHD67QlPC+Y7dgU2EPSH3Bvuxav5SCLpXGPwCKJwfzAUincNTScglmGCCsLgiCoQdJqwJtphPvdMwHH3BjYEdeeOq/ytU1QKuQgmCWRNB/uwXenmf1W0pLAa8zsoiFXbbZA0grANDO7Ywz7WAbXz9kI9xiaAexjZg8Noo6DQNL5pY9TgdcDN5vZZm1+EgTjhqTl67bP7roqvSJpd3yR8Ap8XPhGPDz5h8DBk0AoPwiyCONQEATBiCFpdzOLUIAgCCY1ki41szd329bD/i4GzsCzcAHsBOxoZluMrabjh6Rlga+b2Q7DrksQBP0jaSlgZ+Be3HPooYnwCAyCiSSMQ0EQBCOIpA2BFSiF/9akfw6CIBg5khDyfMDleLYypa+mAb80s1f1ud/bzGytbttGiZQx6o4QhQ6CyYukDwH7AMsAt+EC39eFR2AwqxGaQ0EQBCOGpFPxzGa30RDRNSrpn4MgCEaUPYB9gaVwrSHhbdjTwLfHsN+/SdoJD+UA2AEXqB4ZJB1DI2PQFGAt4Pbh1SgIggGwD7Aunu1t0yQ98MUh1ykIBk4Yh4IgCEaPdYDVLVw7gyCYhJjZt4BvSfoC8E0ze0rS54G18ayM/fJB3Lh0FG6AuRYYNZHqm0r/fxH4oZldM6zKBEEwEJ4zs+ckIWkeM7tX0qrDrlQQDJowDgVBEIwedwGvAB4ddkWCIAjGwHvM7JAktr8FcARwLLBen/v7ErCrmT0OIGlR4HDcaDQSmNkpw65DEAQD56GUefFnwMWSHgceGXKdgmDghOZQEATBiCHpcjwU4QZgZopUM3vH0CoVBEHQI5JuNbPXSjoUzxJ3RrFtLPvrtm2YSNoKN2Itjy/CFqnDpw21YkEQDARJmwALARea2fPDrk8QDJLwHAqCIBg9Dh52BYIgCAbAw5KOBzYHDpM0D67D0y9TJC1S8RwatbHsN4F34cawWIENglkMM7ty2HUIgvFi1DrUIAiC2Z4YeARBMIuwHfAW4HAze0LSksD+Y9jfEcC1ks7GNYe2A74y9moOlD8Bd4VhKAiCIJhsRFhZEATBiCBphpltLOlpGtluIMISgiAIAJC0OrAZ3i5eama/GXKVmpC0Lh5WdiXNYcFHDq1SQRAEQZBBGIeCIAiCIAiCYABIugj4J3An8J9iu5lF2usgCIJgpImwsiAIgiAIgiAYDIua2ZbDrkQQBEEQ9MpYRAGDIAiCIAiCIGhwiaQwDgVBEASTjggrC4IgCIIgCIIBkDTj5sf1hl4gNOOCIAiCSUIYh4IgCIIgCIIgCIIgCGZjQnMoCIIgCIIgCAaEpDWAFSiNs83sp0OrUBAEQRBkEMahIAiCIAiCIBgAkk4C1gDuppGtzIAwDgVBEAQjTYSVBUEQBEEQBMEAkPQbM1t92PUIgiAIgl6JbGVBEARBEARBMBiukxTGoSAIgmDSEZ5DQRAEQRAEQTAAJL0ROB/4M56xrMhWtsZQKxYEQRAEXQjjUBAEQRAEQRAMAEm/A/YD7qShOYSZ/WFolQqCIAiCDEKQOgiCIAiCIAgGwx/N7LxhVyIIgiAIeiU8h4IgCIIgCIJgAEj6LrAwHlr272J7pLJfzvP7AAABxElEQVQPgiAIRp3wHAqCIAiCIAiCwTAvbhTasrQtUtkHQRAEI094DgVBEARBEARBEARBEMzGRCr7IAiCIAiCIBgAkpaRdI6kxyT9RdJPJC0z7HoFQRAEQTfCOBQEQRAEQRAEg2E6cB6wFLA0rj00fag1CoIgCIIMIqwsCIIgCIIgCAaApNvMbK1u24IgCIJg1AjPoSAIgiAIgiAYDH+TtJOkOdLfTsDfh12pIAiCIOhGeA4FQRAEQRAEwQCQtBzwbWADPEvZtcDeZvbHoVYsCIIgCLoQxqEgCIIgCIIgGACSTgH2NbPH0+dFgcPN7IPDrVkQBEEQdCbCyoIgCIIgCIJgMKxRGIYAzOwfwGuHWJ8gCIIgyCKMQ0EQBEEQBEEwGKZIWqT4kDyH5hxifYIgCIIgi+isgiAIgiAIgmAwHAFcK+lsXHNoO+Arw61SEARBEHQnNIeCIAiCIAiCYEBIWh3YDBBwqZn9ZshVCoIgCIKuhHEoCIIgCIIgCIIgCIJgNiY0h4IgCIIgCIIgCIIgCGZjwjgUBEEQBEEQBEEQBEEwGxPGoSAIgiAIgiAIgiAIgtmYMA4FQRAEQRAEQRAEQRDMxvx/37oo4n7/PjUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212ffb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(top_values, '.')\n",
    "plt.xticks(range(len(top_words)), top_words, rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Убрать слова, встречающиеся менее 3 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term count created\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# unigrams_train_features = vectorizer.fit_transform(x_train)\n",
    "# unigrams_val_features = vectorizer.transform(x_val)\n",
    "# unigrams_test_features = vectorizer.transform(x_test)\n",
    "\n",
    "vectorizer_freq = CountVectorizer()\n",
    "freq_train_features = vectorizer_freq.fit_transform(x_train)\n",
    "freq_val_features = vectorizer_freq.transform(x_val)\n",
    "freq_test_features = vectorizer_freq.transform(x_test)\n",
    "\n",
    "print('term count created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 373, 1636,    1, ...,    9,    3,    5]], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_train_features.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '000005',\n",
       " '00001',\n",
       " '0001',\n",
       " '0002',\n",
       " '0004g',\n",
       " '0005',\n",
       " '001',\n",
       " '0019522',\n",
       " '002',\n",
       " '003',\n",
       " '004',\n",
       " '005',\n",
       " '006',\n",
       " '007',\n",
       " '0073',\n",
       " '008',\n",
       " '009',\n",
       " '01',\n",
       " '010',\n",
       " '011',\n",
       " '011108',\n",
       " '012',\n",
       " '0125',\n",
       " '013',\n",
       " '014',\n",
       " '01411',\n",
       " '015',\n",
       " '015455128',\n",
       " '015461110',\n",
       " '015879572',\n",
       " '01587960',\n",
       " '016',\n",
       " '017',\n",
       " '0171',\n",
       " '0176',\n",
       " '018',\n",
       " '019',\n",
       " '01as',\n",
       " '01nothing',\n",
       " '01subject',\n",
       " '01the',\n",
       " '02',\n",
       " '020',\n",
       " '021',\n",
       " '0210',\n",
       " '021000089',\n",
       " '02109',\n",
       " '02110',\n",
       " '022',\n",
       " '02210',\n",
       " '023',\n",
       " '023135ad8',\n",
       " '023135af3',\n",
       " '0238',\n",
       " '024',\n",
       " '025',\n",
       " '026',\n",
       " '027',\n",
       " '027490646',\n",
       " '0275',\n",
       " '028',\n",
       " '029',\n",
       " '02each',\n",
       " '03',\n",
       " '030',\n",
       " '031',\n",
       " '032',\n",
       " '033',\n",
       " '034',\n",
       " '035',\n",
       " '036',\n",
       " '037',\n",
       " '0372',\n",
       " '03763',\n",
       " '038',\n",
       " '039',\n",
       " '039754029',\n",
       " '03if',\n",
       " '03the',\n",
       " '04',\n",
       " '040',\n",
       " '041',\n",
       " '04113',\n",
       " '042',\n",
       " '043',\n",
       " '0433',\n",
       " '044',\n",
       " '04423',\n",
       " '045',\n",
       " '046',\n",
       " '047',\n",
       " '048',\n",
       " '049',\n",
       " '0495',\n",
       " '04any',\n",
       " '04the',\n",
       " '04whenever',\n",
       " '05',\n",
       " '050',\n",
       " '051',\n",
       " '052',\n",
       " '053',\n",
       " '054',\n",
       " '0543',\n",
       " '055',\n",
       " '056',\n",
       " '057',\n",
       " '0572',\n",
       " '058',\n",
       " '059',\n",
       " '0595',\n",
       " '0597',\n",
       " '05the',\n",
       " '06',\n",
       " '060',\n",
       " '061',\n",
       " '062',\n",
       " '06217',\n",
       " '0626',\n",
       " '06298',\n",
       " '063',\n",
       " '065',\n",
       " '066',\n",
       " '067',\n",
       " '0676870',\n",
       " '068',\n",
       " '069',\n",
       " '06901',\n",
       " '06in',\n",
       " '06notwithstanding',\n",
       " '06the',\n",
       " '07',\n",
       " '070',\n",
       " '07068',\n",
       " '07087',\n",
       " '071',\n",
       " '0711',\n",
       " '072',\n",
       " '073',\n",
       " '074',\n",
       " '075',\n",
       " '076',\n",
       " '077',\n",
       " '0781',\n",
       " '079',\n",
       " '07960',\n",
       " '07the',\n",
       " '08',\n",
       " '080',\n",
       " '081',\n",
       " '082',\n",
       " '0820',\n",
       " '083',\n",
       " '084',\n",
       " '085',\n",
       " '086',\n",
       " '087',\n",
       " '0871985',\n",
       " '088',\n",
       " '089',\n",
       " '08if',\n",
       " '08the',\n",
       " '09',\n",
       " '090',\n",
       " '09055',\n",
       " '091',\n",
       " '092',\n",
       " '093',\n",
       " '094',\n",
       " '0943',\n",
       " '095',\n",
       " '096',\n",
       " '097',\n",
       " '098',\n",
       " '0987654',\n",
       " '09876544',\n",
       " '09876545',\n",
       " '0987655',\n",
       " '099',\n",
       " '09the',\n",
       " '0b',\n",
       " '0x',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10004',\n",
       " '10005',\n",
       " '10006',\n",
       " '1001',\n",
       " '10010',\n",
       " '10011',\n",
       " '10013',\n",
       " '10017',\n",
       " '10018',\n",
       " '10019',\n",
       " '10020',\n",
       " '10036',\n",
       " '1004',\n",
       " '10055',\n",
       " '1008',\n",
       " '10080',\n",
       " '1009',\n",
       " '100m',\n",
       " '100th',\n",
       " '101',\n",
       " '1010',\n",
       " '101034',\n",
       " '1012',\n",
       " '10171',\n",
       " '102',\n",
       " '102240',\n",
       " '102603',\n",
       " '10281',\n",
       " '102870',\n",
       " '102872',\n",
       " '10292',\n",
       " '102b',\n",
       " '103',\n",
       " '103471',\n",
       " '1037',\n",
       " '1039',\n",
       " '103b',\n",
       " '104',\n",
       " '1048',\n",
       " '104806',\n",
       " '104b',\n",
       " '105',\n",
       " '1050',\n",
       " '10504',\n",
       " '106',\n",
       " '1066064',\n",
       " '106b',\n",
       " '107',\n",
       " '1072',\n",
       " '108',\n",
       " '1080p',\n",
       " '1081436',\n",
       " '1088',\n",
       " '108843',\n",
       " '109',\n",
       " '109185',\n",
       " '1094',\n",
       " '10a',\n",
       " '10b',\n",
       " '10b5',\n",
       " '10th',\n",
       " '10the',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '11001',\n",
       " '110107',\n",
       " '1107',\n",
       " '111',\n",
       " '1110',\n",
       " '1112',\n",
       " '1114',\n",
       " '111m',\n",
       " '112',\n",
       " '1120',\n",
       " '11220',\n",
       " '1126',\n",
       " '1128b',\n",
       " '112b',\n",
       " '113',\n",
       " '113148',\n",
       " '113b',\n",
       " '114',\n",
       " '1140',\n",
       " '114190',\n",
       " '114253',\n",
       " '114254',\n",
       " '114255',\n",
       " '114346',\n",
       " '115',\n",
       " '11522',\n",
       " '115b',\n",
       " '116',\n",
       " '11614488',\n",
       " '117',\n",
       " '118',\n",
       " '118764',\n",
       " '1188',\n",
       " '119',\n",
       " '11971',\n",
       " '1199',\n",
       " '11a',\n",
       " '11b',\n",
       " '11g',\n",
       " '11m',\n",
       " '11n',\n",
       " '11th',\n",
       " '11the',\n",
       " '11x',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1201',\n",
       " '1202',\n",
       " '120511',\n",
       " '12060047',\n",
       " '1209',\n",
       " '120th',\n",
       " '121',\n",
       " '122',\n",
       " '1221',\n",
       " '1228',\n",
       " '123',\n",
       " '1231',\n",
       " '1239',\n",
       " '123m',\n",
       " '123r',\n",
       " '123revised',\n",
       " '124',\n",
       " '124280',\n",
       " '124281',\n",
       " '124282',\n",
       " '1248',\n",
       " '124b',\n",
       " '125',\n",
       " '1251',\n",
       " '1252977',\n",
       " '12555',\n",
       " '125m',\n",
       " '126',\n",
       " '126163',\n",
       " '1265',\n",
       " '127',\n",
       " '128',\n",
       " '1281',\n",
       " '128m',\n",
       " '129',\n",
       " '1297',\n",
       " '129863',\n",
       " '12b',\n",
       " '12m',\n",
       " '12th',\n",
       " '12the',\n",
       " '13',\n",
       " '130',\n",
       " '1307',\n",
       " '130nm',\n",
       " '131',\n",
       " '1310',\n",
       " '131406',\n",
       " '131934',\n",
       " '132',\n",
       " '132100',\n",
       " '1322',\n",
       " '132813',\n",
       " '132865',\n",
       " '132_155_161',\n",
       " '132r',\n",
       " '133',\n",
       " '134',\n",
       " '134327',\n",
       " '134m',\n",
       " '135',\n",
       " '1350',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '138326',\n",
       " '138327',\n",
       " '138783',\n",
       " '139',\n",
       " '13a',\n",
       " '13any',\n",
       " '13d',\n",
       " '13e',\n",
       " '13g',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '140857',\n",
       " '140m',\n",
       " '141',\n",
       " '141r',\n",
       " '142',\n",
       " '142175',\n",
       " '142243',\n",
       " '143',\n",
       " '143632',\n",
       " '144',\n",
       " '1445',\n",
       " '144a',\n",
       " '145',\n",
       " '145104',\n",
       " '145920',\n",
       " '146',\n",
       " '146630',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '149437',\n",
       " '14984',\n",
       " '14a',\n",
       " '14b',\n",
       " '14c',\n",
       " '14d',\n",
       " '14e',\n",
       " '14f',\n",
       " '14k',\n",
       " '14m',\n",
       " '14th',\n",
       " '14the',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1501',\n",
       " '1502',\n",
       " '1504',\n",
       " '1506',\n",
       " '151',\n",
       " '152',\n",
       " '1522',\n",
       " '153',\n",
       " '153302',\n",
       " '154',\n",
       " '1542',\n",
       " '1549',\n",
       " '155',\n",
       " '155m',\n",
       " '156',\n",
       " '157',\n",
       " '15717130',\n",
       " '158',\n",
       " '1585',\n",
       " '159',\n",
       " '15all',\n",
       " '15c2',\n",
       " '15d',\n",
       " '15mondays',\n",
       " '15pm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '1604',\n",
       " '161',\n",
       " '16190',\n",
       " '162',\n",
       " '1624',\n",
       " '1628',\n",
       " '163',\n",
       " '164',\n",
       " '1649',\n",
       " '165',\n",
       " '166',\n",
       " '16665',\n",
       " '167',\n",
       " '1672743',\n",
       " '168',\n",
       " '1687',\n",
       " '169',\n",
       " '16a',\n",
       " '16any',\n",
       " '16b',\n",
       " '16e',\n",
       " '16th',\n",
       " '17',\n",
       " '170',\n",
       " '1703985',\n",
       " '171',\n",
       " '172',\n",
       " '173',\n",
       " '174',\n",
       " '175',\n",
       " '17550',\n",
       " '176',\n",
       " '177',\n",
       " '1773',\n",
       " '1776',\n",
       " '178',\n",
       " '179',\n",
       " '1798',\n",
       " '179b',\n",
       " '17cfr240',\n",
       " '17m',\n",
       " '17the',\n",
       " '18',\n",
       " '180',\n",
       " '1801',\n",
       " '181',\n",
       " '182',\n",
       " '1826',\n",
       " '183',\n",
       " '1833',\n",
       " '184',\n",
       " '184m',\n",
       " '185',\n",
       " '186',\n",
       " '187',\n",
       " '1872',\n",
       " '188',\n",
       " '189',\n",
       " '1896',\n",
       " '18b',\n",
       " '18nothing',\n",
       " '18th',\n",
       " '18will',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '190th',\n",
       " '191',\n",
       " '1916',\n",
       " '192',\n",
       " '193',\n",
       " '1930s',\n",
       " '1933',\n",
       " '1934',\n",
       " '1939',\n",
       " '194',\n",
       " '1940',\n",
       " '195',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '196',\n",
       " '1961',\n",
       " '1963',\n",
       " '1964',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '197',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '198',\n",
       " '1980',\n",
       " '19801',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1993546',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '19971999',\n",
       " '1998',\n",
       " '1999',\n",
       " '19the',\n",
       " '1a',\n",
       " '1b',\n",
       " '1gb',\n",
       " '1h',\n",
       " '1h01',\n",
       " '1h02',\n",
       " '1h03',\n",
       " '1k',\n",
       " '1m',\n",
       " '1of',\n",
       " '1q',\n",
       " '1q02',\n",
       " '1q03',\n",
       " '1q04',\n",
       " '1q05',\n",
       " '1q06',\n",
       " '1q07',\n",
       " '1q08',\n",
       " '1st',\n",
       " '1the',\n",
       " '1u',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2001and',\n",
       " '2002',\n",
       " '2002e',\n",
       " '2002hp',\n",
       " '2002the',\n",
       " '2002thomas',\n",
       " '2003',\n",
       " '2003amazon',\n",
       " '2003and',\n",
       " '2003apple',\n",
       " '2003ibm',\n",
       " '2003william',\n",
       " '2003with',\n",
       " '2004',\n",
       " '2004amazon',\n",
       " '2004apple',\n",
       " '2004john',\n",
       " '2004myrtle',\n",
       " '2005',\n",
       " '20050514',\n",
       " '20050624z',\n",
       " '2005adobe',\n",
       " '2005amazon',\n",
       " '2005annual',\n",
       " '2005apple',\n",
       " '2005by',\n",
       " '2005code',\n",
       " '2005excluding',\n",
       " '2006',\n",
       " '2006amazon',\n",
       " '2006apple',\n",
       " '2006as',\n",
       " '2006the',\n",
       " '2007',\n",
       " '2007amazon',\n",
       " '2007apple',\n",
       " '2007google',\n",
       " '2008',\n",
       " '20086',\n",
       " '2008amazon',\n",
       " '2008apple',\n",
       " '2008google',\n",
       " '2009',\n",
       " '200_',\n",
       " '200__',\n",
       " '200mm',\n",
       " '201',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '201494',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '202',\n",
       " '2021',\n",
       " '2023',\n",
       " '2025',\n",
       " '2027',\n",
       " '2029',\n",
       " '203',\n",
       " '2032',\n",
       " '2035',\n",
       " '2038',\n",
       " '204',\n",
       " '2042',\n",
       " '205',\n",
       " '2050',\n",
       " '2051',\n",
       " '20549',\n",
       " '20554',\n",
       " '2057',\n",
       " '206',\n",
       " '2064',\n",
       " '2066',\n",
       " '207',\n",
       " '2070643',\n",
       " '208',\n",
       " '2084',\n",
       " '209',\n",
       " '2099',\n",
       " '20__',\n",
       " '20liddellearningsqa',\n",
       " '20m',\n",
       " '20notwithstanding',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '210',\n",
       " '2106',\n",
       " '21073',\n",
       " '210m',\n",
       " '211',\n",
       " '2112',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '216',\n",
       " '217',\n",
       " '2171',\n",
       " '218',\n",
       " '219',\n",
       " '21b',\n",
       " '21e',\n",
       " '21notwithstanding',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '2200',\n",
       " '2200bg',\n",
       " '2201',\n",
       " '2202',\n",
       " '221',\n",
       " '222',\n",
       " '223',\n",
       " '2231',\n",
       " '224',\n",
       " '225',\n",
       " '22572',\n",
       " '226',\n",
       " '2260624',\n",
       " '227',\n",
       " '228',\n",
       " '229',\n",
       " '22947',\n",
       " '22notwithstanding',\n",
       " '23',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '23315',\n",
       " '2338',\n",
       " '234',\n",
       " '2346',\n",
       " '235',\n",
       " '236',\n",
       " '2360',\n",
       " '2363028',\n",
       " '237',\n",
       " '23795',\n",
       " '238',\n",
       " '2381',\n",
       " '239',\n",
       " '23985',\n",
       " '23andme',\n",
       " '23b',\n",
       " '23notwithstanding',\n",
       " '23rd',\n",
       " '24',\n",
       " '240',\n",
       " '24013e',\n",
       " '241',\n",
       " '2414',\n",
       " '242',\n",
       " '2420',\n",
       " '243',\n",
       " '244',\n",
       " '2445002',\n",
       " '2449',\n",
       " '245',\n",
       " '2458',\n",
       " '246',\n",
       " '247',\n",
       " '2470',\n",
       " '2475',\n",
       " '248',\n",
       " '249',\n",
       " '24notwithstanding',\n",
       " '24th',\n",
       " '24x7',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '2502',\n",
       " '250k',\n",
       " '251',\n",
       " '25100',\n",
       " '25102',\n",
       " '2511',\n",
       " '25110',\n",
       " '2516',\n",
       " '25193118',\n",
       " '252',\n",
       " '2520',\n",
       " '2522',\n",
       " '253',\n",
       " '254',\n",
       " '255',\n",
       " '2550',\n",
       " '25532',\n",
       " '256',\n",
       " '257',\n",
       " '258',\n",
       " '259',\n",
       " '25a',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2601',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '263a',\n",
       " '264',\n",
       " '2642',\n",
       " '265',\n",
       " '266',\n",
       " '267',\n",
       " '268',\n",
       " '269',\n",
       " '26k',\n",
       " '26m',\n",
       " '26th',\n",
       " '26the',\n",
       " '27',\n",
       " '270',\n",
       " '2700',\n",
       " '2701',\n",
       " '2704',\n",
       " '2704080',\n",
       " '271',\n",
       " '2713',\n",
       " '272',\n",
       " '273',\n",
       " '2730',\n",
       " '274',\n",
       " '2740',\n",
       " '275',\n",
       " '2750',\n",
       " '275m',\n",
       " '276',\n",
       " '2760445',\n",
       " '27669',\n",
       " '277',\n",
       " '278',\n",
       " '279',\n",
       " '27a',\n",
       " '27m',\n",
       " '27th',\n",
       " '27the',\n",
       " '28',\n",
       " '280',\n",
       " '2802',\n",
       " '280g',\n",
       " '281',\n",
       " '2813',\n",
       " '2817',\n",
       " '282',\n",
       " '28255',\n",
       " '2826',\n",
       " '283',\n",
       " '284',\n",
       " '285',\n",
       " '286',\n",
       " '287',\n",
       " '2870',\n",
       " '2872',\n",
       " '288',\n",
       " '2883',\n",
       " '289',\n",
       " '28b',\n",
       " '28th',\n",
       " '29',\n",
       " '290',\n",
       " '2900',\n",
       " '2901',\n",
       " '29022',\n",
       " '291',\n",
       " '2912',\n",
       " '2915abg',\n",
       " '292',\n",
       " '2922',\n",
       " '293',\n",
       " '294',\n",
       " '2948',\n",
       " '2949',\n",
       " '295',\n",
       " '296',\n",
       " '2960',\n",
       " '297',\n",
       " '298',\n",
       " '2983',\n",
       " '299',\n",
       " '29th',\n",
       " '2b',\n",
       " '2h',\n",
       " '2h02',\n",
       " '2m',\n",
       " '2mb',\n",
       " '2nd',\n",
       " '2q',\n",
       " '2q02',\n",
       " '2q03',\n",
       " '2q04',\n",
       " '2q05',\n",
       " '2q06',\n",
       " '2q07',\n",
       " '2q08',\n",
       " '2way',\n",
       " '2x',\n",
       " '2x2mb',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30032',\n",
       " '300f',\n",
       " '300m',\n",
       " '300mm',\n",
       " '301',\n",
       " '302',\n",
       " '30247',\n",
       " '30261',\n",
       " '3028',\n",
       " '303',\n",
       " '304',\n",
       " '30424',\n",
       " '30459',\n",
       " '305',\n",
       " '30517',\n",
       " '306',\n",
       " '30604518',\n",
       " '307',\n",
       " '30765',\n",
       " '30786',\n",
       " '308',\n",
       " '309',\n",
       " '30am',\n",
       " '30pm',\n",
       " '30th',\n",
       " '30x',\n",
       " '31',\n",
       " '310',\n",
       " '3100',\n",
       " '311',\n",
       " '312',\n",
       " '313',\n",
       " '31305',\n",
       " '314',\n",
       " '3140',\n",
       " '31496',\n",
       " '315',\n",
       " '316',\n",
       " '317',\n",
       " '31732',\n",
       " '3175',\n",
       " '3177549',\n",
       " '318',\n",
       " '319',\n",
       " '31st',\n",
       " '32',\n",
       " '320',\n",
       " '3200',\n",
       " '320m',\n",
       " '321',\n",
       " '322',\n",
       " '323',\n",
       " '324',\n",
       " '325',\n",
       " '3257',\n",
       " '3258',\n",
       " '326',\n",
       " '32690',\n",
       " '327',\n",
       " '328',\n",
       " '329',\n",
       " '32nm',\n",
       " '33',\n",
       " '330',\n",
       " '3300',\n",
       " '33000',\n",
       " '331',\n",
       " '332',\n",
       " '3324',\n",
       " '333',\n",
       " '334',\n",
       " '33432',\n",
       " '33458',\n",
       " '33470390',\n",
       " '335',\n",
       " '33590',\n",
       " '336',\n",
       " '33692',\n",
       " '337',\n",
       " '338',\n",
       " '339',\n",
       " '34',\n",
       " '340',\n",
       " '3400',\n",
       " '340k',\n",
       " '341',\n",
       " '342',\n",
       " '343',\n",
       " '3435',\n",
       " '344',\n",
       " '34406',\n",
       " '345',\n",
       " '346',\n",
       " '347',\n",
       " '3475',\n",
       " '348',\n",
       " ...]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_freq.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9146724040163547"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.sort(np.ravel(unigrams_train_features.sum(axis=0)))[::-1], 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2056x12811 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 966533 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "################## PART 5 ##################\n",
    "############################################\n",
    "\n",
    "# combine all features to one feature space\n",
    "\n",
    "# 1. NMF 50 features\n",
    "\n",
    "nmf_50_x_train = hstack([unigrams_train_features, \n",
    "                         nmf_50_train_features])\n",
    "\n",
    "nmf_50_x_val = hstack([unigrams_val_features,   \n",
    "                       nmf_50_val_features])\n",
    "\n",
    "nmf_50_x_test = hstack([unigrams_test_features,  \n",
    "                        nmf_50_test_features])\n",
    "\n",
    "# 2. NMF 100 features\n",
    "nmf_100_x_train = hstack([unigrams_train_features, \n",
    "                         nmf_100_train_features])\n",
    "\n",
    "nmf_100_x_val = hstack([unigrams_val_features,   \n",
    "                       nmf_100_val_features])\n",
    "\n",
    "nmf_100_x_test = hstack([unigrams_test_features,  \n",
    "                        nmf_100_test_features])\n",
    "\n",
    "# 3. NMF 200 features\n",
    "nmf_200_x_train = hstack([unigrams_train_features, \n",
    "                         nmf_200_train_features])\n",
    "\n",
    "nmf_200_x_val = hstack([unigrams_val_features,   \n",
    "                       nmf_200_val_features])\n",
    "\n",
    "nmf_200_x_test = hstack([unigrams_test_features,  \n",
    "                        nmf_200_test_features])\n",
    "\n",
    "# 4. Ensemble features\n",
    "ensemble_x_train = hstack([unigrams_train_features, \n",
    "                           nmf_50_train_features, \n",
    "                           nmf_100_train_features, \n",
    "                           nmf_200_train_features])\n",
    "\n",
    "ensemble_x_val = hstack([unigrams_val_features, \n",
    "                           nmf_50_val_features, \n",
    "                           nmf_100_val_features, \n",
    "                           nmf_200_val_features])\n",
    "\n",
    "ensemble_x_test = hstack([unigrams_test_features, \n",
    "                           nmf_50_test_features, \n",
    "                           nmf_100_test_features, \n",
    "                           nmf_200_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_train_features_cv = []\n",
    "nmf_50_x_train_cv = []\n",
    "nmf_100_x_train_cv = []\n",
    "nmf_200_x_train_cv = []\n",
    "ensemble_x_train_cv = []\n",
    "y_train_cv = []\n",
    "\n",
    "unigrams_test_features_cv = []\n",
    "nmf_50_x_test_cv = []\n",
    "nmf_100_x_test_cv = []\n",
    "nmf_200_x_test_cv = []\n",
    "ensemble_x_test_cv = []\n",
    "y_test_cv = []\n",
    "\n",
    "#\n",
    "# CV 1 features & classifications\n",
    "#\n",
    "\n",
    "# Train 1\n",
    "\n",
    "idx_start = 0\n",
    "idx_end = int(cv_size * 0.6)\n",
    "unigrams_train_features_cv1 = unigrams_train_features[idx_start : idx_end]\n",
    "nmf_50_train_features_cv1 = nmf_50_train_features[idx_start : idx_end]\n",
    "nmf_100_train_features_cv1 = nmf_100_train_features[idx_start : idx_end]\n",
    "nmf_200_train_features_cv1 = nmf_200_train_features[idx_start : idx_end]\n",
    "\n",
    "nmf_50_x_train_cv1 = hstack([unigrams_train_features_cv1, nmf_50_train_features_cv1])\n",
    "nmf_100_x_train_cv1 = hstack([unigrams_train_features_cv1, nmf_100_train_features_cv1])\n",
    "nmf_200_x_train_cv1 = hstack([unigrams_train_features_cv1, nmf_200_train_features_cv1])\n",
    "ensemble_x_train_cv1 = hstack([unigrams_train_features_cv1, nmf_50_train_features_cv1, \n",
    "                               nmf_100_train_features_cv1, nmf_200_train_features_cv1])\n",
    "\n",
    "y_train_cv1 = y_train[idx_start : idx_end]\n",
    "\n",
    "# Test 1\n",
    "\n",
    "idx_start = int(cv_size * 0.6)\n",
    "idx_end = cv_size\n",
    "unigrams_test_features_cv1 = unigrams_train_features[idx_start : idx_end]\n",
    "nmf_50_test_features_cv1 = nmf_50_train_features[idx_start : idx_end]\n",
    "nmf_100_test_features_cv1 = nmf_100_train_features[idx_start : idx_end]\n",
    "nmf_200_test_features_cv1 = nmf_200_train_features[idx_start : idx_end]\n",
    "\n",
    "nmf_50_x_test_cv1 = hstack([unigrams_test_features_cv1, nmf_50_test_features_cv1])\n",
    "nmf_100_x_test_cv1 = hstack([unigrams_test_features_cv1, nmf_100_test_features_cv1])\n",
    "nmf_200_x_test_cv1 = hstack([unigrams_test_features_cv1, nmf_200_test_features_cv1])\n",
    "ensemble_x_test_cv1 = hstack([unigrams_test_features_cv1, nmf_50_test_features_cv1, \n",
    "                               nmf_100_test_features_cv1, nmf_200_test_features_cv1])\n",
    "\n",
    "y_test_cv1 = y_train[idx_start : idx_end]\n",
    "\n",
    "#\n",
    "# CV 2 features & classifications\n",
    "#\n",
    "\n",
    "# Train 2\n",
    "\n",
    "idx_start = cv_size\n",
    "idx_end = cv_size + int(cv_size * 0.6)\n",
    "unigrams_train_features_cv2 = unigrams_train_features[idx_start : idx_end]\n",
    "nmf_50_train_features_cv2 = nmf_50_train_features[idx_start : idx_end]\n",
    "nmf_100_train_features_cv2 = nmf_100_train_features[idx_start : idx_end]\n",
    "nmf_200_train_features_cv2 = nmf_200_train_features[idx_start : idx_end]\n",
    "\n",
    "nmf_50_x_train_cv2 = hstack([unigrams_train_features_cv2, nmf_50_train_features_cv2])\n",
    "nmf_100_x_train_cv2 = hstack([unigrams_train_features_cv2, nmf_100_train_features_cv2])\n",
    "nmf_200_x_train_cv2 = hstack([unigrams_train_features_cv2, nmf_200_train_features_cv2])\n",
    "ensemble_x_train_cv2 = hstack([unigrams_train_features_cv2, nmf_50_train_features_cv2, \n",
    "                               nmf_100_train_features_cv2, nmf_200_train_features_cv2])\n",
    "\n",
    "y_train_cv2 = y_train[idx_start : idx_end]\n",
    "\n",
    "# Test 2\n",
    "\n",
    "idx_start = cv_size + int(cv_size * 0.6)\n",
    "idx_end = 2 * cv_size\n",
    "unigrams_test_features_cv2 = unigrams_train_features[idx_start : idx_end]\n",
    "nmf_50_test_features_cv2 = nmf_50_train_features[idx_start : idx_end]\n",
    "nmf_100_test_features_cv2 = nmf_100_train_features[idx_start : idx_end]\n",
    "nmf_200_test_features_cv2 = nmf_200_train_features[idx_start : idx_end]\n",
    "\n",
    "nmf_50_x_test_cv2 = hstack([unigrams_test_features_cv2, nmf_50_test_features_cv2])\n",
    "nmf_100_x_test_cv2 = hstack([unigrams_test_features_cv2, nmf_100_test_features_cv2])\n",
    "nmf_200_x_test_cv2 = hstack([unigrams_test_features_cv2, nmf_200_test_features_cv2])\n",
    "ensemble_x_test_cv2 = hstack([unigrams_test_features_cv2, nmf_50_test_features_cv2, \n",
    "                               nmf_100_test_features_cv2, nmf_200_test_features_cv2])\n",
    "\n",
    "y_test_cv2 = y_train[idx_start : idx_end]\n",
    "\n",
    "#\n",
    "# CV 3 features & classifications\n",
    "#\n",
    "\n",
    "# Train 3\n",
    "\n",
    "idx_start = 2 * cv_size\n",
    "idx_end = 2 * cv_size + int(cv_size * 0.6)\n",
    "unigrams_train_features_cv3 = unigrams_train_features[idx_start : idx_end]\n",
    "nmf_50_train_features_cv3 = nmf_50_train_features[idx_start : idx_end]\n",
    "nmf_100_train_features_cv3 = nmf_100_train_features[idx_start : idx_end]\n",
    "nmf_200_train_features_cv3 = nmf_200_train_features[idx_start : idx_end]\n",
    "\n",
    "nmf_50_x_train_cv3 = hstack([unigrams_train_features_cv3, nmf_50_train_features_cv3])\n",
    "nmf_100_x_train_cv3 = hstack([unigrams_train_features_cv3, nmf_100_train_features_cv3])\n",
    "nmf_200_x_train_cv3 = hstack([unigrams_train_features_cv3, nmf_200_train_features_cv3])\n",
    "ensemble_x_train_cv3 = hstack([unigrams_train_features_cv3, nmf_50_train_features_cv3, \n",
    "                               nmf_100_train_features_cv3, nmf_200_train_features_cv3])\n",
    "\n",
    "y_train_cv3 = y_train[idx_start : idx_end]\n",
    "\n",
    "# Test 3\n",
    "\n",
    "idx_start = 2 * cv_size + int(cv_size * 0.6)\n",
    "unigrams_test_features_cv3 = unigrams_train_features[idx_start : ]\n",
    "nmf_50_test_features_cv3 = nmf_50_train_features[idx_start : ]\n",
    "nmf_100_test_features_cv3 = nmf_100_train_features[idx_start : ]\n",
    "nmf_200_test_features_cv3 = nmf_200_train_features[idx_start : ]\n",
    "\n",
    "nmf_50_x_test_cv3 = hstack([unigrams_test_features_cv3, nmf_50_test_features_cv3])\n",
    "nmf_100_x_test_cv3 = hstack([unigrams_test_features_cv3, nmf_100_test_features_cv3])\n",
    "nmf_200_x_test_cv3 = hstack([unigrams_test_features_cv3, nmf_200_test_features_cv3])\n",
    "ensemble_x_test_cv3 = hstack([unigrams_test_features_cv3, nmf_50_test_features_cv3, \n",
    "                               nmf_100_test_features_cv3, nmf_200_test_features_cv3])\n",
    "\n",
    "y_test_cv3 = y_train[idx_start : ]\n",
    "\n",
    "\n",
    "unigrams_train_features_cv.append(unigrams_train_features_cv1)\n",
    "unigrams_train_features_cv.append(unigrams_train_features_cv2)\n",
    "unigrams_train_features_cv.append(unigrams_train_features_cv3)\n",
    "nmf_50_x_train_cv.append(nmf_50_x_train_cv1)\n",
    "nmf_50_x_train_cv.append(nmf_50_x_train_cv2)\n",
    "nmf_50_x_train_cv.append(nmf_50_x_train_cv3)\n",
    "nmf_100_x_train_cv.append(nmf_100_x_train_cv1)\n",
    "nmf_100_x_train_cv.append(nmf_100_x_train_cv2)\n",
    "nmf_100_x_train_cv.append(nmf_100_x_train_cv3)\n",
    "nmf_200_x_train_cv.append(nmf_200_x_train_cv1)\n",
    "nmf_200_x_train_cv.append(nmf_200_x_train_cv2)\n",
    "nmf_200_x_train_cv.append(nmf_200_x_train_cv3)\n",
    "ensemble_x_train_cv.append(ensemble_x_train_cv1)\n",
    "ensemble_x_train_cv.append(ensemble_x_train_cv2)\n",
    "ensemble_x_train_cv.append(ensemble_x_train_cv3)\n",
    "y_train_cv.append(y_train_cv1)\n",
    "y_train_cv.append(y_train_cv2)\n",
    "y_train_cv.append(y_train_cv3)\n",
    "\n",
    "unigrams_test_features_cv.append(unigrams_test_features_cv1)\n",
    "unigrams_test_features_cv.append(unigrams_test_features_cv2)\n",
    "unigrams_test_features_cv.append(unigrams_test_features_cv3)\n",
    "nmf_50_x_test_cv.append(nmf_50_x_test_cv1)\n",
    "nmf_50_x_test_cv.append(nmf_50_x_test_cv2)\n",
    "nmf_50_x_test_cv.append(nmf_50_x_test_cv3)\n",
    "nmf_100_x_test_cv.append(nmf_100_x_test_cv1)\n",
    "nmf_100_x_test_cv.append(nmf_100_x_test_cv2)\n",
    "nmf_100_x_test_cv.append(nmf_100_x_test_cv3)\n",
    "nmf_200_x_test_cv.append(nmf_200_x_test_cv1)\n",
    "nmf_200_x_test_cv.append(nmf_200_x_test_cv2)\n",
    "nmf_200_x_test_cv.append(nmf_200_x_test_cv3)\n",
    "ensemble_x_test_cv.append(ensemble_x_test_cv1)\n",
    "ensemble_x_test_cv.append(ensemble_x_test_cv2)\n",
    "ensemble_x_test_cv.append(ensemble_x_test_cv3)\n",
    "y_test_cv.append(y_test_cv1)\n",
    "y_test_cv.append(y_test_cv2)\n",
    "y_test_cv.append(y_test_cv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV1 models trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV2 models trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV3 models trained\n",
      "finished. time elapsed: 69.98 sec\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "rf_unigrams_model_cv = []\n",
    "rf_nmf_50_model_cv = []\n",
    "rf_nmf_100_model_cv = []\n",
    "rf_nmf_200_model_cv = []\n",
    "rf_ensemble_model_cv = []\n",
    "\n",
    "xgb_unigrams_model_cv = []\n",
    "xgb_nmf_50_model_cv = []\n",
    "xgb_nmf_100_model_cv = []\n",
    "xgb_nmf_200_model_cv = []\n",
    "xgb_ensemble_model_cv = []\n",
    "\n",
    "lr_unigrams_model_cv = []\n",
    "lr_nmf_50_model_cv = []\n",
    "lr_nmf_100_model_cv = []\n",
    "lr_nmf_200_model_cv = []\n",
    "lr_ensemble_model_cv = []\n",
    "\n",
    "lsvc_unigrams_model_cv = []\n",
    "lsvc_nmf_50_model_cv = []\n",
    "lsvc_nmf_100_model_cv = []\n",
    "lsvc_nmf_200_model_cv = []\n",
    "lsvc_ensemble_model_cv = []\n",
    "\n",
    "#\n",
    "# CV 1\n",
    "#\n",
    "\n",
    "# Unigrams\n",
    "rf_unigrams_model_cv1 = RandomForestClassifier()\n",
    "rf_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "xgb_unigrams_model_cv1 = XGBClassifier()\n",
    "xgb_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "lr_unigrams_model_cv1 = LogisticRegression()\n",
    "lr_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "lsvc_unigrams_model_cv1 = LinearSVC()\n",
    "lsvc_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "\n",
    "# NMF 50\n",
    "rf_nmf_50_model_cv1 = RandomForestClassifier()\n",
    "rf_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)\n",
    "xgb_nmf_50_model_cv1 = XGBClassifier()\n",
    "xgb_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)\n",
    "lr_nmf_50_model_cv1 = LogisticRegression()\n",
    "lr_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)\n",
    "lsvc_nmf_50_model_cv1 = LinearSVC()\n",
    "lsvc_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)\n",
    "\n",
    "# NMF 100\n",
    "rf_nmf_100_model_cv1 = RandomForestClassifier()\n",
    "rf_nmf_100_model_cv1.fit(nmf_100_x_train_cv1, y_train_cv1)\n",
    "xgb_nmf_100_model_cv1 = XGBClassifier()\n",
    "xgb_nmf_100_model_cv1.fit(nmf_100_x_train_cv1, y_train_cv1)\n",
    "lr_nmf_100_model_cv1 = LogisticRegression()\n",
    "lr_nmf_100_model_cv1.fit(nmf_100_x_train_cv1, y_train_cv1)\n",
    "lsvc_nmf_100_model_cv1 = LinearSVC()\n",
    "lsvc_nmf_100_model_cv1.fit(nmf_100_x_train_cv1, y_train_cv1)\n",
    "\n",
    "# NMF 200\n",
    "rf_nmf_200_model_cv1 = RandomForestClassifier()\n",
    "rf_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "xgb_nmf_200_model_cv1 = XGBClassifier()\n",
    "xgb_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "lr_nmf_200_model_cv1 = LogisticRegression()\n",
    "lr_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "lsvc_nmf_200_model_cv1 = LinearSVC()\n",
    "lsvc_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "\n",
    "# Ensemble\n",
    "rf_ensemble_model_cv1 = RandomForestClassifier()\n",
    "rf_ensemble_model_cv1.fit(ensemble_x_train_cv1, y_train_cv1)\n",
    "xgb_ensemble_model_cv1 = XGBClassifier()\n",
    "xgb_ensemble_model_cv1.fit(ensemble_x_train_cv1, y_train_cv1)\n",
    "lr_ensemble_model_cv1 = LogisticRegression()\n",
    "lr_ensemble_model_cv1.fit(ensemble_x_train_cv1, y_train_cv1)\n",
    "lsvc_ensemble_model_cv1 = LinearSVC()\n",
    "lsvc_ensemble_model_cv1.fit(ensemble_x_train_cv1, y_train_cv1)\n",
    "\n",
    "print('CV1 models trained')\n",
    "\n",
    "#\n",
    "# CV 2\n",
    "#\n",
    "\n",
    "# Unigrams\n",
    "rf_unigrams_model_cv2 = RandomForestClassifier()\n",
    "rf_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "xgb_unigrams_model_cv2 = XGBClassifier()\n",
    "xgb_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "lr_unigrams_model_cv2 = LogisticRegression()\n",
    "lr_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "lsvc_unigrams_model_cv2 = LinearSVC()\n",
    "lsvc_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "\n",
    "# NMF 50\n",
    "rf_nmf_50_model_cv2 = RandomForestClassifier()\n",
    "rf_nmf_50_model_cv2.fit(nmf_50_x_train_cv2, y_train_cv2)\n",
    "xgb_nmf_50_model_cv2 = XGBClassifier()\n",
    "xgb_nmf_50_model_cv2.fit(nmf_50_x_train_cv2, y_train_cv2)\n",
    "lr_nmf_50_model_cv2 = LogisticRegression()\n",
    "lr_nmf_50_model_cv2.fit(nmf_50_x_train_cv2, y_train_cv2)\n",
    "lsvc_nmf_50_model_cv2 = LinearSVC()\n",
    "lsvc_nmf_50_model_cv2.fit(nmf_50_x_train_cv2, y_train_cv2)\n",
    "\n",
    "# NMF 100\n",
    "rf_nmf_100_model_cv2 = RandomForestClassifier()\n",
    "rf_nmf_100_model_cv2.fit(nmf_100_x_train_cv2, y_train_cv2)\n",
    "xgb_nmf_100_model_cv2 = XGBClassifier()\n",
    "xgb_nmf_100_model_cv2.fit(nmf_100_x_train_cv2, y_train_cv2)\n",
    "lr_nmf_100_model_cv2 = LogisticRegression()\n",
    "lr_nmf_100_model_cv2.fit(nmf_100_x_train_cv2, y_train_cv2)\n",
    "lsvc_nmf_100_model_cv2 = LinearSVC()\n",
    "lsvc_nmf_100_model_cv2.fit(nmf_100_x_train_cv2, y_train_cv2)\n",
    "\n",
    "# NMF 200\n",
    "rf_nmf_200_model_cv2 = RandomForestClassifier()\n",
    "rf_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "xgb_nmf_200_model_cv2 = XGBClassifier()\n",
    "xgb_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "lr_nmf_200_model_cv2 = LogisticRegression()\n",
    "lr_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "lsvc_nmf_200_model_cv2 = LinearSVC()\n",
    "lsvc_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "\n",
    "# Ensemble\n",
    "rf_ensemble_model_cv2 = RandomForestClassifier()\n",
    "rf_ensemble_model_cv2.fit(ensemble_x_train_cv2, y_train_cv2)\n",
    "xgb_ensemble_model_cv2 = XGBClassifier()\n",
    "xgb_ensemble_model_cv2.fit(ensemble_x_train_cv2, y_train_cv2)\n",
    "lr_ensemble_model_cv2 = LogisticRegression()\n",
    "lr_ensemble_model_cv2.fit(ensemble_x_train_cv2, y_train_cv2)\n",
    "lsvc_ensemble_model_cv2 = LinearSVC()\n",
    "lsvc_ensemble_model_cv2.fit(ensemble_x_train_cv2, y_train_cv2)\n",
    "\n",
    "print('CV2 models trained')\n",
    "\n",
    "#\n",
    "# CV 3\n",
    "#\n",
    "\n",
    "# Unigrams\n",
    "rf_unigrams_model_cv3 = RandomForestClassifier()\n",
    "rf_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "xgb_unigrams_model_cv3 = XGBClassifier()\n",
    "xgb_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "lr_unigrams_model_cv3 = LogisticRegression()\n",
    "lr_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "lsvc_unigrams_model_cv3 = LinearSVC()\n",
    "lsvc_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "\n",
    "# NMF 50\n",
    "rf_nmf_50_model_cv3 = RandomForestClassifier()\n",
    "rf_nmf_50_model_cv3.fit(nmf_50_x_train_cv3, y_train_cv3)\n",
    "xgb_nmf_50_model_cv3 = XGBClassifier()\n",
    "xgb_nmf_50_model_cv3.fit(nmf_50_x_train_cv3, y_train_cv3)\n",
    "lr_nmf_50_model_cv3 = LogisticRegression()\n",
    "lr_nmf_50_model_cv3.fit(nmf_50_x_train_cv3, y_train_cv3)\n",
    "lsvc_nmf_50_model_cv3 = LinearSVC()\n",
    "lsvc_nmf_50_model_cv3.fit(nmf_50_x_train_cv3, y_train_cv3)\n",
    "\n",
    "# NMF 100\n",
    "rf_nmf_100_model_cv3 = RandomForestClassifier()\n",
    "rf_nmf_100_model_cv3.fit(nmf_100_x_train_cv3, y_train_cv3)\n",
    "xgb_nmf_100_model_cv3 = XGBClassifier()\n",
    "xgb_nmf_100_model_cv3.fit(nmf_100_x_train_cv3, y_train_cv3)\n",
    "lr_nmf_100_model_cv3 = LogisticRegression()\n",
    "lr_nmf_100_model_cv3.fit(nmf_100_x_train_cv3, y_train_cv3)\n",
    "lsvc_nmf_100_model_cv3 = LinearSVC()\n",
    "lsvc_nmf_100_model_cv3.fit(nmf_100_x_train_cv3, y_train_cv3)\n",
    "\n",
    "# NMF 200\n",
    "rf_nmf_200_model_cv3 = RandomForestClassifier()\n",
    "rf_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "xgb_nmf_200_model_cv3 = XGBClassifier()\n",
    "xgb_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "lr_nmf_200_model_cv3 = LogisticRegression()\n",
    "lr_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "lsvc_nmf_200_model_cv3 = LinearSVC()\n",
    "lsvc_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "\n",
    "# Ensemble\n",
    "rf_ensemble_model_cv3 = RandomForestClassifier()\n",
    "rf_ensemble_model_cv3.fit(ensemble_x_train_cv3, y_train_cv3)\n",
    "xgb_ensemble_model_cv3 = XGBClassifier()\n",
    "xgb_ensemble_model_cv3.fit(ensemble_x_train_cv3, y_train_cv3)\n",
    "lr_ensemble_model_cv3 = LogisticRegression()\n",
    "lr_ensemble_model_cv3.fit(ensemble_x_train_cv3, y_train_cv3)\n",
    "lsvc_ensemble_model_cv3 = LinearSVC()\n",
    "lsvc_ensemble_model_cv3.fit(ensemble_x_train_cv3, y_train_cv3)\n",
    "\n",
    "print('CV3 models trained')\n",
    "\n",
    "rf_unigrams_model_cv.append(rf_unigrams_model_cv1)\n",
    "rf_unigrams_model_cv.append(rf_unigrams_model_cv2)\n",
    "rf_unigrams_model_cv.append(rf_unigrams_model_cv3)\n",
    "\n",
    "rf_nmf_50_model_cv.append(rf_nmf_50_model_cv1)\n",
    "rf_nmf_50_model_cv.append(rf_nmf_50_model_cv2)\n",
    "rf_nmf_50_model_cv.append(rf_nmf_50_model_cv3)\n",
    "\n",
    "rf_nmf_100_model_cv.append(rf_nmf_100_model_cv1)\n",
    "rf_nmf_100_model_cv.append(rf_nmf_100_model_cv2)\n",
    "rf_nmf_100_model_cv.append(rf_nmf_100_model_cv3)\n",
    "\n",
    "rf_nmf_200_model_cv.append(rf_nmf_200_model_cv1)\n",
    "rf_nmf_200_model_cv.append(rf_nmf_200_model_cv2)\n",
    "rf_nmf_200_model_cv.append(rf_nmf_200_model_cv3)\n",
    "\n",
    "rf_ensemble_model_cv.append(rf_ensemble_model_cv1)\n",
    "rf_ensemble_model_cv.append(rf_ensemble_model_cv2)\n",
    "rf_ensemble_model_cv.append(rf_ensemble_model_cv3)\n",
    "\n",
    "xgb_unigrams_model_cv.append(xgb_unigrams_model_cv1)\n",
    "xgb_unigrams_model_cv.append(xgb_unigrams_model_cv2)\n",
    "xgb_unigrams_model_cv.append(xgb_unigrams_model_cv3)\n",
    "\n",
    "xgb_nmf_50_model_cv.append(xgb_nmf_50_model_cv1)\n",
    "xgb_nmf_50_model_cv.append(xgb_nmf_50_model_cv2)\n",
    "xgb_nmf_50_model_cv.append(xgb_nmf_50_model_cv3)\n",
    "\n",
    "xgb_nmf_100_model_cv.append(xgb_nmf_100_model_cv1)\n",
    "xgb_nmf_100_model_cv.append(xgb_nmf_100_model_cv2)\n",
    "xgb_nmf_100_model_cv.append(xgb_nmf_100_model_cv3)\n",
    "\n",
    "xgb_nmf_200_model_cv.append(xgb_nmf_200_model_cv1)\n",
    "xgb_nmf_200_model_cv.append(xgb_nmf_200_model_cv2)\n",
    "xgb_nmf_200_model_cv.append(xgb_nmf_200_model_cv3)\n",
    "\n",
    "xgb_ensemble_model_cv.append(xgb_ensemble_model_cv1)\n",
    "xgb_ensemble_model_cv.append(xgb_ensemble_model_cv2)\n",
    "xgb_ensemble_model_cv.append(xgb_ensemble_model_cv3)\n",
    "\n",
    "lr_unigrams_model_cv.append(lr_unigrams_model_cv1)\n",
    "lr_unigrams_model_cv.append(lr_unigrams_model_cv2)\n",
    "lr_unigrams_model_cv.append(lr_unigrams_model_cv3)\n",
    "\n",
    "lr_nmf_50_model_cv.append(lr_nmf_50_model_cv1)\n",
    "lr_nmf_50_model_cv.append(lr_nmf_50_model_cv2)\n",
    "lr_nmf_50_model_cv.append(lr_nmf_50_model_cv3)\n",
    "\n",
    "lr_nmf_100_model_cv.append(lr_nmf_100_model_cv1)\n",
    "lr_nmf_100_model_cv.append(lr_nmf_100_model_cv2)\n",
    "lr_nmf_100_model_cv.append(lr_nmf_100_model_cv3)\n",
    "\n",
    "lr_nmf_200_model_cv.append(lr_nmf_200_model_cv1)\n",
    "lr_nmf_200_model_cv.append(lr_nmf_200_model_cv2)\n",
    "lr_nmf_200_model_cv.append(lr_nmf_200_model_cv3)\n",
    "\n",
    "lr_ensemble_model_cv.append(lr_ensemble_model_cv1)\n",
    "lr_ensemble_model_cv.append(lr_ensemble_model_cv2)\n",
    "lr_ensemble_model_cv.append(lr_ensemble_model_cv3)\n",
    "\n",
    "lsvc_unigrams_model_cv.append(lsvc_unigrams_model_cv1)\n",
    "lsvc_unigrams_model_cv.append(lsvc_unigrams_model_cv2)\n",
    "lsvc_unigrams_model_cv.append(lsvc_unigrams_model_cv3)\n",
    "\n",
    "lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv1)\n",
    "lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv2)\n",
    "lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv3)\n",
    "\n",
    "lsvc_nmf_100_model_cv.append(lsvc_nmf_100_model_cv1)\n",
    "lsvc_nmf_100_model_cv.append(lsvc_nmf_100_model_cv2)\n",
    "lsvc_nmf_100_model_cv.append(lsvc_nmf_100_model_cv3)\n",
    "\n",
    "lsvc_nmf_200_model_cv.append(lsvc_nmf_200_model_cv1)\n",
    "lsvc_nmf_200_model_cv.append(lsvc_nmf_200_model_cv2)\n",
    "lsvc_nmf_200_model_cv.append(lsvc_nmf_200_model_cv3)\n",
    "\n",
    "lsvc_ensemble_model_cv.append(lsvc_ensemble_model_cv1)\n",
    "lsvc_ensemble_model_cv.append(lsvc_ensemble_model_cv2)\n",
    "lsvc_ensemble_model_cv.append(lsvc_ensemble_model_cv3)\n",
    "\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    print('CV', i, '\\n')\n",
    "\n",
    "    #\n",
    "    # RANDOM FOREST\n",
    "    #\n",
    "    \n",
    "    cv_list.append(i)\n",
    "    model_list.append('RandomForestClassifier')\n",
    "    preproc_list.append('Unigrams')\n",
    "    f1_list.append(f1_score(y_test_cv[i], rf_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], rf_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('RandomForestClassifier')\n",
    "    preproc_list.append('NMF_50')\n",
    "    f1_list.append(f1_score(y_test_cv[i], rf_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], rf_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('RandomForestClassifier')\n",
    "    preproc_list.append('NMF_100')\n",
    "    f1_list.append(f1_score(y_test_cv[i], rf_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], rf_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('RandomForestClassifier')\n",
    "    preproc_list.append('NMF_200')\n",
    "    f1_list.append(f1_score(y_test_cv[i], rf_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], rf_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('RandomForestClassifier')\n",
    "    preproc_list.append('Ensemble')\n",
    "    f1_list.append(f1_score(y_test_cv[i], rf_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], rf_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "    \n",
    "    #\n",
    "    # XGBOOST\n",
    "    #\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('XGBClassifier')\n",
    "    preproc_list.append('Unigrams')\n",
    "    f1_list.append(f1_score(y_test_cv[i], xgb_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], xgb_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('XGBClassifier')\n",
    "    preproc_list.append('NMF_50')\n",
    "    f1_list.append(f1_score(y_test_cv[i], xgb_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], xgb_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('XGBClassifier')\n",
    "    preproc_list.append('NMF_100')\n",
    "    f1_list.append(f1_score(y_test_cv[i], xgb_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], xgb_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('XGBClassifier')\n",
    "    preproc_list.append('NMF_200')\n",
    "    f1_list.append(f1_score(y_test_cv[i], xgb_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], xgb_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('XGBClassifier')\n",
    "    preproc_list.append('Ensemble')\n",
    "    f1_list.append(f1_score(y_test_cv[i], xgb_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], xgb_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "\n",
    "    #\n",
    "    # LOGISTIC REGRESSION\n",
    "    #\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LogisticRegression')\n",
    "    preproc_list.append('Unigrams')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lr_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lr_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LogisticRegression')\n",
    "    preproc_list.append('NMF_50')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lr_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lr_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LogisticRegression')\n",
    "    preproc_list.append('NMF_100')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lr_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lr_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LogisticRegression')\n",
    "    preproc_list.append('NMF_200')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LogisticRegression')\n",
    "    preproc_list.append('Ensemble')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lr_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lr_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "\n",
    "    #\n",
    "    # LINEAR SUPPORT VECTOR CLASSIFIER\n",
    "    #\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LinearSVC')\n",
    "    preproc_list.append('Unigrams')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lsvc_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LinearSVC')\n",
    "    preproc_list.append('NMF_50')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lsvc_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LinearSVC')\n",
    "    preproc_list.append('NMF_100')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lsvc_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_nmf_100_model_cv[i].predict(nmf_100_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LinearSVC')\n",
    "    preproc_list.append('NMF_200')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lsvc_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "\n",
    "    cv_list.append(i)\n",
    "    model_list.append('LinearSVC')\n",
    "    preproc_list.append('Ensemble')\n",
    "    f1_list.append(f1_score(y_test_cv[i], lsvc_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))\n",
    "    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_ensemble_model_cv[i].predict(ensemble_x_test_cv[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>0.588594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.711555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.673153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.777174</td>\n",
       "      <td>0.655869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.702856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.762319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.821333</td>\n",
       "      <td>0.707463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.831522</td>\n",
       "      <td>0.734276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.735077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.652578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.687260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.819338</td>\n",
       "      <td>0.673239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.672409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.683140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.817259</td>\n",
       "      <td>0.668288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.595690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.580839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.793269</td>\n",
       "      <td>0.590740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.598581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.800959</td>\n",
       "      <td>0.601471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.505682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>0.516850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.861345</td>\n",
       "      <td>0.491077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.850325</td>\n",
       "      <td>0.536643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.781176</td>\n",
       "      <td>0.536358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.820862</td>\n",
       "      <td>0.558240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.864301</td>\n",
       "      <td>0.484574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.491029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.879346</td>\n",
       "      <td>0.480302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.473657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.873706</td>\n",
       "      <td>0.493307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.525964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_50</td>\n",
       "      <td>0.891170</td>\n",
       "      <td>0.528147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_100</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.523780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.525964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.519413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Set                   Model Features Method  F1-score   AUC ROC\n",
       "0          0  RandomForestClassifier        Unigrams  0.720222  0.588594\n",
       "1          0  RandomForestClassifier          NMF_50  0.795455  0.711555\n",
       "2          0  RandomForestClassifier         NMF_100  0.744048  0.673153\n",
       "3          0  RandomForestClassifier         NMF_200  0.777174  0.655869\n",
       "4          0  RandomForestClassifier        Ensemble  0.757576  0.702856\n",
       "5          0           XGBClassifier        Unigrams  0.837079  0.762319\n",
       "6          0           XGBClassifier          NMF_50  0.821333  0.707463\n",
       "7          0           XGBClassifier         NMF_100  0.831522  0.734276\n",
       "8          0           XGBClassifier         NMF_200  0.812500  0.735077\n",
       "9          0           XGBClassifier        Ensemble  0.784000  0.652578\n",
       "10         0      LogisticRegression        Unigrams  0.821705  0.687260\n",
       "11         0      LogisticRegression          NMF_50  0.819338  0.673239\n",
       "12         0      LogisticRegression         NMF_100  0.815385  0.672409\n",
       "13         0      LogisticRegression         NMF_200  0.823529  0.683140\n",
       "14         0      LogisticRegression        Ensemble  0.817259  0.668288\n",
       "15         0               LinearSVC        Unigrams  0.795181  0.595690\n",
       "16         0               LinearSVC          NMF_50  0.789474  0.580839\n",
       "17         0               LinearSVC         NMF_100  0.793269  0.590740\n",
       "18         0               LinearSVC         NMF_200  0.798077  0.598581\n",
       "19         0               LinearSVC        Ensemble  0.800959  0.601471\n",
       "20         1  RandomForestClassifier        Unigrams  0.806100  0.497312\n",
       "21         1  RandomForestClassifier          NMF_50  0.806100  0.497312\n",
       "22         1  RandomForestClassifier         NMF_100  0.810458  0.505682\n",
       "23         1  RandomForestClassifier         NMF_200  0.808696  0.500000\n",
       "24         1  RandomForestClassifier        Ensemble  0.806100  0.497312\n",
       "25         1           XGBClassifier        Unigrams  0.803493  0.494624\n",
       "26         1           XGBClassifier          NMF_50  0.803493  0.494624\n",
       "27         1           XGBClassifier         NMF_100  0.803493  0.494624\n",
       "28         1           XGBClassifier         NMF_200  0.808696  0.500000\n",
       "29         1           XGBClassifier        Ensemble  0.803493  0.494624\n",
       "30         1      LogisticRegression        Unigrams  0.808696  0.500000\n",
       "31         1      LogisticRegression          NMF_50  0.808696  0.500000\n",
       "32         1      LogisticRegression         NMF_100  0.808696  0.500000\n",
       "33         1      LogisticRegression         NMF_200  0.808696  0.500000\n",
       "34         1      LogisticRegression        Ensemble  0.808696  0.500000\n",
       "35         1               LinearSVC        Unigrams  0.808696  0.500000\n",
       "36         1               LinearSVC          NMF_50  0.808696  0.500000\n",
       "37         1               LinearSVC         NMF_100  0.808696  0.500000\n",
       "38         1               LinearSVC         NMF_200  0.808696  0.500000\n",
       "39         1               LinearSVC        Ensemble  0.808696  0.500000\n",
       "40         2  RandomForestClassifier        Unigrams  0.792627  0.516850\n",
       "41         2  RandomForestClassifier          NMF_50  0.861345  0.491077\n",
       "42         2  RandomForestClassifier         NMF_100  0.850325  0.536643\n",
       "43         2  RandomForestClassifier         NMF_200  0.781176  0.536358\n",
       "44         2  RandomForestClassifier        Ensemble  0.820862  0.558240\n",
       "45         2           XGBClassifier        Unigrams  0.864301  0.484574\n",
       "46         2           XGBClassifier          NMF_50  0.851064  0.491029\n",
       "47         2           XGBClassifier         NMF_100  0.879346  0.480302\n",
       "48         2           XGBClassifier         NMF_200  0.852321  0.473657\n",
       "49         2           XGBClassifier        Ensemble  0.873706  0.493307\n",
       "50         2      LogisticRegression        Unigrams  0.908730  0.500000\n",
       "51         2      LogisticRegression          NMF_50  0.908730  0.500000\n",
       "52         2      LogisticRegression         NMF_100  0.908730  0.500000\n",
       "53         2      LogisticRegression         NMF_200  0.908730  0.500000\n",
       "54         2      LogisticRegression        Ensemble  0.908730  0.500000\n",
       "55         2               LinearSVC        Unigrams  0.888889  0.525964\n",
       "56         2               LinearSVC          NMF_50  0.891170  0.528147\n",
       "57         2               LinearSVC         NMF_100  0.886598  0.523780\n",
       "58         2               LinearSVC         NMF_200  0.888889  0.525964\n",
       "59         2               LinearSVC        Ensemble  0.881988  0.519413"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list})\n",
    "                       #columns=['model', 'n_features', 'F1'])\n",
    "    \n",
    "#cv_results.to_csv('data/cv_results.csv', index=False)\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'solver']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.01, 0.1, 1, 10, 100, 1000]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_by_key():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty={'C': 0.001, 'solver': 'newton-cg'}, random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_params = {\n",
    "            'C': params['C'][0],\n",
    "            'solver': params['solver'][0]\n",
    "        }\n",
    "\n",
    "LogisticRegression(selected_params)\n",
    "\n",
    "selected_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "param_list = []\n",
    "\n",
    "for solver_param in params['solver']:\n",
    "    for C_param in params['C']:\n",
    "        \n",
    "        selected_params = {\n",
    "            'C': C_param,\n",
    "            'solver': solver_param\n",
    "        }\n",
    "\n",
    "        lr_nmf_200_model_cv1 = LogisticRegression(C = selected_params['C'], solver = selected_params['solver'])\n",
    "        lr_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "\n",
    "        lr_nmf_200_model_cv2 = LogisticRegression(C = selected_params['C'], solver = selected_params['solver'])\n",
    "        lr_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "\n",
    "        lr_nmf_200_model_cv3 = LogisticRegression(C = selected_params['C'], solver = selected_params['solver'])\n",
    "        lr_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "\n",
    "        for i in range(3):\n",
    "            cv_list.append(i)\n",
    "            model_list.append('LogisticRegression')\n",
    "            preproc_list.append('NMF_200')\n",
    "            f1_list.append(f1_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "            auc_list.append(roc_auc_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "            param_list.append(selected_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.001, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.01, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 10, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 100, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 1000, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'newton-cg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.001, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.01, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 10, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 100, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 1000, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.001, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.001, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.01, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.01, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 0.1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 0.1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 10, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 10, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 100, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 100, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>{'C': 1000, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF_200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>{'C': 1000, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Set               Model Features Method  F1-score  AUC ROC  \\\n",
       "0          0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "1          1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "2          2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "3          0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "4          1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "5          2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "6          0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "7          1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "8          2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "9          0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "10         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "11         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "12         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "13         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "14         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "15         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "16         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "17         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "18         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "19         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "20         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "21         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "22         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "23         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "24         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "25         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "26         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "27         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "28         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "29         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "..       ...                 ...             ...       ...      ...   \n",
       "33         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "34         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "35         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "36         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "37         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "38         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "39         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "40         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "41         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "42         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "43         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "44         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "45         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "46         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "47         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "48         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "49         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "50         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "51         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "52         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "53         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "54         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "55         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "56         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "57         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "58         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "59         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "60         0  LogisticRegression         NMF_200  0.823529  0.68314   \n",
       "61         1  LogisticRegression         NMF_200  0.808696  0.50000   \n",
       "62         2  LogisticRegression         NMF_200  0.908730  0.50000   \n",
       "\n",
       "                                 params  \n",
       "0   {'C': 0.001, 'solver': 'newton-cg'}  \n",
       "1   {'C': 0.001, 'solver': 'newton-cg'}  \n",
       "2   {'C': 0.001, 'solver': 'newton-cg'}  \n",
       "3    {'C': 0.01, 'solver': 'newton-cg'}  \n",
       "4    {'C': 0.01, 'solver': 'newton-cg'}  \n",
       "5    {'C': 0.01, 'solver': 'newton-cg'}  \n",
       "6     {'C': 0.1, 'solver': 'newton-cg'}  \n",
       "7     {'C': 0.1, 'solver': 'newton-cg'}  \n",
       "8     {'C': 0.1, 'solver': 'newton-cg'}  \n",
       "9       {'C': 1, 'solver': 'newton-cg'}  \n",
       "10      {'C': 1, 'solver': 'newton-cg'}  \n",
       "11      {'C': 1, 'solver': 'newton-cg'}  \n",
       "12     {'C': 10, 'solver': 'newton-cg'}  \n",
       "13     {'C': 10, 'solver': 'newton-cg'}  \n",
       "14     {'C': 10, 'solver': 'newton-cg'}  \n",
       "15    {'C': 100, 'solver': 'newton-cg'}  \n",
       "16    {'C': 100, 'solver': 'newton-cg'}  \n",
       "17    {'C': 100, 'solver': 'newton-cg'}  \n",
       "18   {'C': 1000, 'solver': 'newton-cg'}  \n",
       "19   {'C': 1000, 'solver': 'newton-cg'}  \n",
       "20   {'C': 1000, 'solver': 'newton-cg'}  \n",
       "21      {'C': 0.001, 'solver': 'lbfgs'}  \n",
       "22      {'C': 0.001, 'solver': 'lbfgs'}  \n",
       "23      {'C': 0.001, 'solver': 'lbfgs'}  \n",
       "24       {'C': 0.01, 'solver': 'lbfgs'}  \n",
       "25       {'C': 0.01, 'solver': 'lbfgs'}  \n",
       "26       {'C': 0.01, 'solver': 'lbfgs'}  \n",
       "27        {'C': 0.1, 'solver': 'lbfgs'}  \n",
       "28        {'C': 0.1, 'solver': 'lbfgs'}  \n",
       "29        {'C': 0.1, 'solver': 'lbfgs'}  \n",
       "..                                  ...  \n",
       "33         {'C': 10, 'solver': 'lbfgs'}  \n",
       "34         {'C': 10, 'solver': 'lbfgs'}  \n",
       "35         {'C': 10, 'solver': 'lbfgs'}  \n",
       "36        {'C': 100, 'solver': 'lbfgs'}  \n",
       "37        {'C': 100, 'solver': 'lbfgs'}  \n",
       "38        {'C': 100, 'solver': 'lbfgs'}  \n",
       "39       {'C': 1000, 'solver': 'lbfgs'}  \n",
       "40       {'C': 1000, 'solver': 'lbfgs'}  \n",
       "41       {'C': 1000, 'solver': 'lbfgs'}  \n",
       "42  {'C': 0.001, 'solver': 'liblinear'}  \n",
       "43  {'C': 0.001, 'solver': 'liblinear'}  \n",
       "44  {'C': 0.001, 'solver': 'liblinear'}  \n",
       "45   {'C': 0.01, 'solver': 'liblinear'}  \n",
       "46   {'C': 0.01, 'solver': 'liblinear'}  \n",
       "47   {'C': 0.01, 'solver': 'liblinear'}  \n",
       "48    {'C': 0.1, 'solver': 'liblinear'}  \n",
       "49    {'C': 0.1, 'solver': 'liblinear'}  \n",
       "50    {'C': 0.1, 'solver': 'liblinear'}  \n",
       "51      {'C': 1, 'solver': 'liblinear'}  \n",
       "52      {'C': 1, 'solver': 'liblinear'}  \n",
       "53      {'C': 1, 'solver': 'liblinear'}  \n",
       "54     {'C': 10, 'solver': 'liblinear'}  \n",
       "55     {'C': 10, 'solver': 'liblinear'}  \n",
       "56     {'C': 10, 'solver': 'liblinear'}  \n",
       "57    {'C': 100, 'solver': 'liblinear'}  \n",
       "58    {'C': 100, 'solver': 'liblinear'}  \n",
       "59    {'C': 100, 'solver': 'liblinear'}  \n",
       "60   {'C': 1000, 'solver': 'liblinear'}  \n",
       "61   {'C': 1000, 'solver': 'liblinear'}  \n",
       "62   {'C': 1000, 'solver': 'liblinear'}  \n",
       "\n",
       "[63 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list,\n",
    "                           'params': param_list})\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.01 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.1 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 3 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 3 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 3 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 3 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 9 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 9 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 9 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.3 9 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3353.608211040497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "#booster_list = ['gbtree', 'gblinear', 'dart']\n",
    "gamma_list = [0, 0.2]\n",
    "learning_rate_list = [0.01, 0.1, 0.3]\n",
    "max_depth_list = [3, 9]\n",
    "n_estimators_list = [50, 100, 500, 1000]\n",
    "\n",
    "#booster_param_list = []\n",
    "gamma_param_list = []\n",
    "learning_rate_param_list = []\n",
    "max_depth_param_list = []\n",
    "n_estimators_param_list = []\n",
    "\n",
    "#for booster in booster_list:\n",
    "for gamma in gamma_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            for n_estimators in n_estimators_list:\n",
    "                \n",
    "                xgb_unigrams_model_cv = []\n",
    "\n",
    "                print(gamma, learning_rate, max_depth, n_estimators)\n",
    "\n",
    "                # booster=booster, \n",
    "                xgb_unigrams_model_cv1 = XGBClassifier(gamma=gamma, learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "                xgb_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "\n",
    "                xgb_unigrams_model_cv2 = XGBClassifier(gamma=gamma, learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "                xgb_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "\n",
    "                xgb_unigrams_model_cv3 = XGBClassifier(gamma=gamma, learning_rate=learning_rate, max_depth=max_depth, n_estimators=n_estimators)\n",
    "                xgb_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "\n",
    "                xgb_unigrams_model_cv.append(xgb_unigrams_model_cv1)\n",
    "                xgb_unigrams_model_cv.append(xgb_unigrams_model_cv2)\n",
    "                xgb_unigrams_model_cv.append(xgb_unigrams_model_cv3)\n",
    "\n",
    "                for i in range(3):\n",
    "                    cv_list.append(i)\n",
    "                    model_list.append('XGBClassifier')\n",
    "                    preproc_list.append('Unigrams')\n",
    "                    f1_list.append(f1_score(y_test_cv[i], xgb_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "                    auc_list.append(roc_auc_score(y_test_cv[i], xgb_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "                    #booster_param_list.append(booster)\n",
    "                    gamma_param_list.append(gamma)\n",
    "                    learning_rate_param_list.append(learning_rate)\n",
    "                    max_depth_param_list.append(max_depth)\n",
    "                    n_estimators_param_list.append(n_estimators)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.619184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.882957</td>\n",
       "      <td>0.502041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.796954</td>\n",
       "      <td>0.636926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.887526</td>\n",
       "      <td>0.506408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>0.724775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.881148</td>\n",
       "      <td>0.491171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.814404</td>\n",
       "      <td>0.721885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.480254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.795756</td>\n",
       "      <td>0.666199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>0.501851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.639386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.541058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.819843</td>\n",
       "      <td>0.691381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.504177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.817942</td>\n",
       "      <td>0.695502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.882474</td>\n",
       "      <td>0.510727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.829132</td>\n",
       "      <td>0.749528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.887984</td>\n",
       "      <td>0.497722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.762319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.864301</td>\n",
       "      <td>0.484574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.475888</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.475888</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.705803</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.844350</td>\n",
       "      <td>0.475793</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.473562</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.832972</td>\n",
       "      <td>0.484431</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.718594</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.832972</td>\n",
       "      <td>0.484431</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.870488</td>\n",
       "      <td>0.545424</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.870488</td>\n",
       "      <td>0.545424</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.870488</td>\n",
       "      <td>0.545424</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.828338</td>\n",
       "      <td>0.731386</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.870488</td>\n",
       "      <td>0.545424</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data Set          Model Features Method  F1-score   AUC ROC  gamma  \\\n",
       "0           0  XGBClassifier        Unigrams  0.787879  0.619184    0.0   \n",
       "1           1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "2           2  XGBClassifier        Unigrams  0.882957  0.502041    0.0   \n",
       "3           0  XGBClassifier        Unigrams  0.796954  0.636926    0.0   \n",
       "4           1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "5           2  XGBClassifier        Unigrams  0.887526  0.506408    0.0   \n",
       "6           0  XGBClassifier        Unigrams  0.817680  0.724775    0.0   \n",
       "7           1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "8           2  XGBClassifier        Unigrams  0.881148  0.491171    0.0   \n",
       "9           0  XGBClassifier        Unigrams  0.814404  0.721885    0.0   \n",
       "10          1  XGBClassifier        Unigrams  0.803493  0.494624    0.0   \n",
       "11          2  XGBClassifier        Unigrams  0.869565  0.480254    0.0   \n",
       "12          0  XGBClassifier        Unigrams  0.795756  0.666199    0.0   \n",
       "13          1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "14          2  XGBClassifier        Unigrams  0.842333  0.501851    0.0   \n",
       "15          0  XGBClassifier        Unigrams  0.786458  0.639386    0.0   \n",
       "16          1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "17          2  XGBClassifier        Unigrams  0.865672  0.541058    0.0   \n",
       "18          0  XGBClassifier        Unigrams  0.819843  0.691381    0.0   \n",
       "19          1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "20          2  XGBClassifier        Unigrams  0.875519  0.504177    0.0   \n",
       "21          0  XGBClassifier        Unigrams  0.817942  0.695502    0.0   \n",
       "22          1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "23          2  XGBClassifier        Unigrams  0.882474  0.510727    0.0   \n",
       "24          0  XGBClassifier        Unigrams  0.829132  0.749528    0.0   \n",
       "25          1  XGBClassifier        Unigrams  0.808696  0.500000    0.0   \n",
       "26          2  XGBClassifier        Unigrams  0.887984  0.497722    0.0   \n",
       "27          0  XGBClassifier        Unigrams  0.837079  0.762319    0.0   \n",
       "28          1  XGBClassifier        Unigrams  0.803493  0.494624    0.0   \n",
       "29          2  XGBClassifier        Unigrams  0.864301  0.484574    0.0   \n",
       "..        ...            ...             ...       ...       ...    ...   \n",
       "114         0  XGBClassifier        Unigrams  0.842667  0.738826    0.2   \n",
       "115         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "116         2  XGBClassifier        Unigrams  0.864865  0.475888    0.2   \n",
       "117         0  XGBClassifier        Unigrams  0.842667  0.738826    0.2   \n",
       "118         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "119         2  XGBClassifier        Unigrams  0.864865  0.475888    0.2   \n",
       "120         0  XGBClassifier        Unigrams  0.813008  0.705803    0.2   \n",
       "121         1  XGBClassifier        Unigrams  0.803493  0.494624    0.2   \n",
       "122         2  XGBClassifier        Unigrams  0.844350  0.475793    0.2   \n",
       "123         0  XGBClassifier        Unigrams  0.820652  0.718594    0.2   \n",
       "124         1  XGBClassifier        Unigrams  0.803493  0.494624    0.2   \n",
       "125         2  XGBClassifier        Unigrams  0.831169  0.473562    0.2   \n",
       "126         0  XGBClassifier        Unigrams  0.820652  0.718594    0.2   \n",
       "127         1  XGBClassifier        Unigrams  0.803493  0.494624    0.2   \n",
       "128         2  XGBClassifier        Unigrams  0.832972  0.484431    0.2   \n",
       "129         0  XGBClassifier        Unigrams  0.820652  0.718594    0.2   \n",
       "130         1  XGBClassifier        Unigrams  0.803493  0.494624    0.2   \n",
       "131         2  XGBClassifier        Unigrams  0.832972  0.484431    0.2   \n",
       "132         0  XGBClassifier        Unigrams  0.828338  0.731386    0.2   \n",
       "133         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "134         2  XGBClassifier        Unigrams  0.870488  0.545424    0.2   \n",
       "135         0  XGBClassifier        Unigrams  0.828338  0.731386    0.2   \n",
       "136         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "137         2  XGBClassifier        Unigrams  0.870488  0.545424    0.2   \n",
       "138         0  XGBClassifier        Unigrams  0.828338  0.731386    0.2   \n",
       "139         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "140         2  XGBClassifier        Unigrams  0.870488  0.545424    0.2   \n",
       "141         0  XGBClassifier        Unigrams  0.828338  0.731386    0.2   \n",
       "142         1  XGBClassifier        Unigrams  0.808696  0.500000    0.2   \n",
       "143         2  XGBClassifier        Unigrams  0.870488  0.545424    0.2   \n",
       "\n",
       "     learning_rate  max_depth  n_estimators  \n",
       "0             0.01          3            50  \n",
       "1             0.01          3            50  \n",
       "2             0.01          3            50  \n",
       "3             0.01          3           100  \n",
       "4             0.01          3           100  \n",
       "5             0.01          3           100  \n",
       "6             0.01          3           500  \n",
       "7             0.01          3           500  \n",
       "8             0.01          3           500  \n",
       "9             0.01          3          1000  \n",
       "10            0.01          3          1000  \n",
       "11            0.01          3          1000  \n",
       "12            0.01          9            50  \n",
       "13            0.01          9            50  \n",
       "14            0.01          9            50  \n",
       "15            0.01          9           100  \n",
       "16            0.01          9           100  \n",
       "17            0.01          9           100  \n",
       "18            0.01          9           500  \n",
       "19            0.01          9           500  \n",
       "20            0.01          9           500  \n",
       "21            0.01          9          1000  \n",
       "22            0.01          9          1000  \n",
       "23            0.01          9          1000  \n",
       "24            0.10          3            50  \n",
       "25            0.10          3            50  \n",
       "26            0.10          3            50  \n",
       "27            0.10          3           100  \n",
       "28            0.10          3           100  \n",
       "29            0.10          3           100  \n",
       "..             ...        ...           ...  \n",
       "114           0.10          9           500  \n",
       "115           0.10          9           500  \n",
       "116           0.10          9           500  \n",
       "117           0.10          9          1000  \n",
       "118           0.10          9          1000  \n",
       "119           0.10          9          1000  \n",
       "120           0.30          3            50  \n",
       "121           0.30          3            50  \n",
       "122           0.30          3            50  \n",
       "123           0.30          3           100  \n",
       "124           0.30          3           100  \n",
       "125           0.30          3           100  \n",
       "126           0.30          3           500  \n",
       "127           0.30          3           500  \n",
       "128           0.30          3           500  \n",
       "129           0.30          3          1000  \n",
       "130           0.30          3          1000  \n",
       "131           0.30          3          1000  \n",
       "132           0.30          9            50  \n",
       "133           0.30          9            50  \n",
       "134           0.30          9            50  \n",
       "135           0.30          9           100  \n",
       "136           0.30          9           100  \n",
       "137           0.30          9           100  \n",
       "138           0.30          9           500  \n",
       "139           0.30          9           500  \n",
       "140           0.30          9           500  \n",
       "141           0.30          9          1000  \n",
       "142           0.30          9          1000  \n",
       "143           0.30          9          1000  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list,\n",
    "                            \n",
    "                           #'booster': booster_param_list,\n",
    "                           'gamma': gamma_param_list,\n",
    "                           'learning_rate': learning_rate_param_list,\n",
    "                           'max_depth': max_depth_param_list,\n",
    "                           'n_estimators': n_estimators_param_list})\n",
    "\n",
    "xgb_results.to_csv('data/xgb_results.csv', index=False)\n",
    "\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_leaf=3, min_samples_split=5, n_estimators=500)\n",
    "# RandomForestClassifier(criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 1 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 3 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 1 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 2 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 2 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 2 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 2 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 5 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 5 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 5 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 3 5 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 511.37990951538086\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "#criterion_list = ['gini', 'entropy']\n",
    "max_depth_list = [10, 50, None]\n",
    "min_samples_leaf_list = [1, 3]\n",
    "min_samples_split_list = [2, 5]\n",
    "n_estimators_list = [10, 100, 1000, 2000]\n",
    "\n",
    "#criterion_param_list = []\n",
    "max_depth_param_list = []\n",
    "min_samples_leaf_param_list = []\n",
    "min_samples_split_param_list = []\n",
    "n_estimators_param_list = []\n",
    "\n",
    "#for criterion in criterion_list:\n",
    "for max_depth in max_depth_list:\n",
    "    for min_samples_leaf in min_samples_leaf_list:\n",
    "        for min_samples_split in min_samples_split_list:\n",
    "            for n_estimators in n_estimators_list:\n",
    "\n",
    "                rf_unigrams_model_cv = []\n",
    "\n",
    "                print(max_depth, min_samples_leaf, min_samples_split, n_estimators)\n",
    "\n",
    "                # criterion=criterion, \n",
    "                rf_unigrams_model_cv1 = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "                rf_unigrams_model_cv1.fit(unigrams_train_features_cv1, y_train_cv1)\n",
    "\n",
    "                rf_unigrams_model_cv2 = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "                rf_unigrams_model_cv2.fit(unigrams_train_features_cv2, y_train_cv2)\n",
    "\n",
    "                rf_unigrams_model_cv3 = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "                rf_unigrams_model_cv3.fit(unigrams_train_features_cv3, y_train_cv3)\n",
    "\n",
    "                rf_unigrams_model_cv.append(rf_unigrams_model_cv1)\n",
    "                rf_unigrams_model_cv.append(rf_unigrams_model_cv2)\n",
    "                rf_unigrams_model_cv.append(rf_unigrams_model_cv3)\n",
    "\n",
    "                for i in range(3):\n",
    "                    cv_list.append(i)\n",
    "                    model_list.append('RandomForestClassifier')\n",
    "                    preproc_list.append('Unigrams')\n",
    "                    f1_list.append(f1_score(y_test_cv[i], rf_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "                    auc_list.append(roc_auc_score(y_test_cv[i], rf_unigrams_model_cv[i].predict(unigrams_test_features_cv[i])))\n",
    "\n",
    "                    #criterion_param_list.append(criterion)\n",
    "                    max_depth_param_list.append(max_depth)\n",
    "                    min_samples_leaf_param_list.append(min_samples_leaf)\n",
    "                    min_samples_split_param_list.append(min_samples_split)\n",
    "                    n_estimators_param_list.append(n_estimators)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.614605</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.473657</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.860158</td>\n",
       "      <td>0.758227</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.902834</td>\n",
       "      <td>0.530378</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.860892</td>\n",
       "      <td>0.756167</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.510822</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.861619</td>\n",
       "      <td>0.754106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.513006</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.740056</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.893878</td>\n",
       "      <td>0.521644</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.855643</td>\n",
       "      <td>0.748326</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.493450</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.856397</td>\n",
       "      <td>0.746266</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.517372</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>0.751216</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.513006</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.690551</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.818584</td>\n",
       "      <td>0.490887</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.742546</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908367</td>\n",
       "      <td>0.508686</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.860158</td>\n",
       "      <td>0.758227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.513006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.761117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.899194</td>\n",
       "      <td>0.508639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.814208</td>\n",
       "      <td>0.712814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.534697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.848958</td>\n",
       "      <td>0.733475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.517372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.864721</td>\n",
       "      <td>0.768128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.517372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.775139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908367</td>\n",
       "      <td>0.508686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.842667</td>\n",
       "      <td>0.738826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.543193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.745436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.493450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.862434</td>\n",
       "      <td>0.763177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.517372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.867725</td>\n",
       "      <td>0.771018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.517372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data Set                   Model Features Method  F1-score   AUC ROC  \\\n",
       "0           0  RandomForestClassifier        Unigrams  0.751351  0.614605   \n",
       "1           1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "2           2  RandomForestClassifier        Unigrams  0.852321  0.473657   \n",
       "3           0  RandomForestClassifier        Unigrams  0.860158  0.758227   \n",
       "4           1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "5           2  RandomForestClassifier        Unigrams  0.902834  0.530378   \n",
       "6           0  RandomForestClassifier        Unigrams  0.860892  0.756167   \n",
       "7           1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "8           2  RandomForestClassifier        Unigrams  0.901408  0.510822   \n",
       "9           0  RandomForestClassifier        Unigrams  0.861619  0.754106   \n",
       "10          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "11          2  RandomForestClassifier        Unigrams  0.903614  0.513006   \n",
       "12          0  RandomForestClassifier        Unigrams  0.837838  0.740056   \n",
       "13          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "14          2  RandomForestClassifier        Unigrams  0.893878  0.521644   \n",
       "15          0  RandomForestClassifier        Unigrams  0.855643  0.748326   \n",
       "16          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "17          2  RandomForestClassifier        Unigrams  0.902196  0.493450   \n",
       "18          0  RandomForestClassifier        Unigrams  0.856397  0.746266   \n",
       "19          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "20          2  RandomForestClassifier        Unigrams  0.908000  0.517372   \n",
       "21          0  RandomForestClassifier        Unigrams  0.858639  0.751216   \n",
       "22          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "23          2  RandomForestClassifier        Unigrams  0.903614  0.513006   \n",
       "24          0  RandomForestClassifier        Unigrams  0.815789  0.690551   \n",
       "25          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "26          2  RandomForestClassifier        Unigrams  0.818584  0.490887   \n",
       "27          0  RandomForestClassifier        Unigrams  0.849604  0.742546   \n",
       "28          1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "29          2  RandomForestClassifier        Unigrams  0.908367  0.508686   \n",
       "..        ...                     ...             ...       ...       ...   \n",
       "114         0  RandomForestClassifier        Unigrams  0.860158  0.758227   \n",
       "115         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "116         2  RandomForestClassifier        Unigrams  0.903614  0.513006   \n",
       "117         0  RandomForestClassifier        Unigrams  0.863158  0.761117   \n",
       "118         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "119         2  RandomForestClassifier        Unigrams  0.899194  0.508639   \n",
       "120         0  RandomForestClassifier        Unigrams  0.814208  0.712814   \n",
       "121         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "122         2  RandomForestClassifier        Unigrams  0.897959  0.534697   \n",
       "123         0  RandomForestClassifier        Unigrams  0.848958  0.733475   \n",
       "124         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "125         2  RandomForestClassifier        Unigrams  0.908000  0.517372   \n",
       "126         0  RandomForestClassifier        Unigrams  0.864721  0.768128   \n",
       "127         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "128         2  RandomForestClassifier        Unigrams  0.908000  0.517372   \n",
       "129         0  RandomForestClassifier        Unigrams  0.866310  0.775139   \n",
       "130         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "131         2  RandomForestClassifier        Unigrams  0.908367  0.508686   \n",
       "132         0  RandomForestClassifier        Unigrams  0.842667  0.738826   \n",
       "133         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "134         2  RandomForestClassifier        Unigrams  0.857759  0.543193   \n",
       "135         0  RandomForestClassifier        Unigrams  0.852632  0.745436   \n",
       "136         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "137         2  RandomForestClassifier        Unigrams  0.902196  0.493450   \n",
       "138         0  RandomForestClassifier        Unigrams  0.862434  0.763177   \n",
       "139         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "140         2  RandomForestClassifier        Unigrams  0.908000  0.517372   \n",
       "141         0  RandomForestClassifier        Unigrams  0.867725  0.771018   \n",
       "142         1  RandomForestClassifier        Unigrams  0.808696  0.500000   \n",
       "143         2  RandomForestClassifier        Unigrams  0.908000  0.517372   \n",
       "\n",
       "     max_depth  min_samples_leaf  min_samples_split  n_estimators  \n",
       "0         10.0                 1                  2            10  \n",
       "1         10.0                 1                  2            10  \n",
       "2         10.0                 1                  2            10  \n",
       "3         10.0                 1                  2           100  \n",
       "4         10.0                 1                  2           100  \n",
       "5         10.0                 1                  2           100  \n",
       "6         10.0                 1                  2          1000  \n",
       "7         10.0                 1                  2          1000  \n",
       "8         10.0                 1                  2          1000  \n",
       "9         10.0                 1                  2          2000  \n",
       "10        10.0                 1                  2          2000  \n",
       "11        10.0                 1                  2          2000  \n",
       "12        10.0                 1                  5            10  \n",
       "13        10.0                 1                  5            10  \n",
       "14        10.0                 1                  5            10  \n",
       "15        10.0                 1                  5           100  \n",
       "16        10.0                 1                  5           100  \n",
       "17        10.0                 1                  5           100  \n",
       "18        10.0                 1                  5          1000  \n",
       "19        10.0                 1                  5          1000  \n",
       "20        10.0                 1                  5          1000  \n",
       "21        10.0                 1                  5          2000  \n",
       "22        10.0                 1                  5          2000  \n",
       "23        10.0                 1                  5          2000  \n",
       "24        10.0                 3                  2            10  \n",
       "25        10.0                 3                  2            10  \n",
       "26        10.0                 3                  2            10  \n",
       "27        10.0                 3                  2           100  \n",
       "28        10.0                 3                  2           100  \n",
       "29        10.0                 3                  2           100  \n",
       "..         ...               ...                ...           ...  \n",
       "114        NaN                 1                  5          1000  \n",
       "115        NaN                 1                  5          1000  \n",
       "116        NaN                 1                  5          1000  \n",
       "117        NaN                 1                  5          2000  \n",
       "118        NaN                 1                  5          2000  \n",
       "119        NaN                 1                  5          2000  \n",
       "120        NaN                 3                  2            10  \n",
       "121        NaN                 3                  2            10  \n",
       "122        NaN                 3                  2            10  \n",
       "123        NaN                 3                  2           100  \n",
       "124        NaN                 3                  2           100  \n",
       "125        NaN                 3                  2           100  \n",
       "126        NaN                 3                  2          1000  \n",
       "127        NaN                 3                  2          1000  \n",
       "128        NaN                 3                  2          1000  \n",
       "129        NaN                 3                  2          2000  \n",
       "130        NaN                 3                  2          2000  \n",
       "131        NaN                 3                  2          2000  \n",
       "132        NaN                 3                  5            10  \n",
       "133        NaN                 3                  5            10  \n",
       "134        NaN                 3                  5            10  \n",
       "135        NaN                 3                  5           100  \n",
       "136        NaN                 3                  5           100  \n",
       "137        NaN                 3                  5           100  \n",
       "138        NaN                 3                  5          1000  \n",
       "139        NaN                 3                  5          1000  \n",
       "140        NaN                 3                  5          1000  \n",
       "141        NaN                 3                  5          2000  \n",
       "142        NaN                 3                  5          2000  \n",
       "143        NaN                 3                  5          2000  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list,\n",
    "                           \n",
    "                           #'criterion': criterion_param_list,\n",
    "                           'max_depth': max_depth_param_list,\n",
    "                           'min_samples_leaf': min_samples_leaf_param_list,\n",
    "                           'min_samples_split': min_samples_split_param_list,\n",
    "                           'n_estimators': n_estimators_param_list})\n",
    "\n",
    "rf_results.to_csv('data/rf_results.csv', index=False)\n",
    "\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearSVC()\n",
    "\n",
    "#lsvc_nmf_50_model_cv1 = LinearSVC()\n",
    "#lsvc_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 squared_hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 squared_hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 squared_hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 squared_hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared_hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared_hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared_hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 squared_hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 squared_hinge 1000 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 squared_hinge 1000 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 squared_hinge 1500 ovr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 squared_hinge 1500 crammer_singer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1500,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.75700569152832\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "C_list = [0.1, 1, 10]\n",
    "loss_list = ['hinge', 'squared_hinge']\n",
    "max_iter_list = [1000, 1500]\n",
    "multi_class_list = ['ovr', 'crammer_singer']\n",
    "#penalty_list = ['l1', 'l2']\n",
    "\n",
    "C_param_list = []\n",
    "loss_param_list = []\n",
    "max_iter_param_list = []\n",
    "multi_class_param_list = []\n",
    "#penalty_param_list = []\n",
    "\n",
    "for C in C_list:\n",
    "    for loss in loss_list:\n",
    "        for max_iter in max_iter_list:\n",
    "            for multi_class in multi_class_list:\n",
    "\n",
    "                print(C, loss, max_iter, multi_class)\n",
    "\n",
    "                lsvc_nmf_50_model_cv = []\n",
    "\n",
    "                lsvc_nmf_50_model_cv1 = LinearSVC(C=C, loss=loss, max_iter=max_iter, multi_class=multi_class)\n",
    "                lsvc_nmf_50_model_cv1.fit(nmf_50_x_train_cv1, y_train_cv1)\n",
    "\n",
    "                lsvc_nmf_50_model_cv2 = LinearSVC(C=C, loss=loss, max_iter=max_iter, multi_class=multi_class)\n",
    "                lsvc_nmf_50_model_cv2.fit(nmf_50_x_train_cv2, y_train_cv2)\n",
    "\n",
    "                lsvc_nmf_50_model_cv3 = LinearSVC(C=C, loss=loss, max_iter=max_iter, multi_class=multi_class)\n",
    "                lsvc_nmf_50_model_cv3.fit(nmf_50_x_train_cv3, y_train_cv3)\n",
    "\n",
    "                lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv1)\n",
    "                lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv2)\n",
    "                lsvc_nmf_50_model_cv.append(lsvc_nmf_50_model_cv3)\n",
    "\n",
    "                for i in range(3):\n",
    "                    cv_list.append(i)\n",
    "                    model_list.append('LinearSVC')\n",
    "                    preproc_list.append('NMF 50')\n",
    "                    f1_list.append(f1_score(y_test_cv[i], lsvc_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "                    auc_list.append(roc_auc_score(y_test_cv[i], lsvc_nmf_50_model_cv[i].predict(nmf_50_x_test_cv[i])))\n",
    "\n",
    "                    C_param_list.append(C)\n",
    "                    loss_param_list.append(loss)\n",
    "                    max_iter_param_list.append(max_iter)\n",
    "                    multi_class_param_list.append(multi_class)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>C</th>\n",
       "      <th>loss</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.576289</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.598151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.576289</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.598151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.815190</td>\n",
       "      <td>0.663338</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.598151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.815190</td>\n",
       "      <td>0.663338</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.598151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.784119</td>\n",
       "      <td>0.600212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.587421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.900204</td>\n",
       "      <td>0.536881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.580839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.891170</td>\n",
       "      <td>0.528147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.587421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.900204</td>\n",
       "      <td>0.536881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.574229</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.551107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.525679</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.574229</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.499668</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.551107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.525679</td>\n",
       "      <td>10.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.577119</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.551107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.525679</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.577119</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.825893</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.551107</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NMF 50</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.525679</td>\n",
       "      <td>10.0</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1500</td>\n",
       "      <td>crammer_singer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Set      Model Features Method  F1-score   AUC ROC     C  \\\n",
       "0          0  LinearSVC          NMF 50  0.778589  0.576289   0.1   \n",
       "1          1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "2          2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "3          0  LinearSVC          NMF 50  0.785185  0.598151   0.1   \n",
       "4          1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "5          2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "6          0  LinearSVC          NMF 50  0.778589  0.576289   0.1   \n",
       "7          1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "8          2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "9          0  LinearSVC          NMF 50  0.785185  0.598151   0.1   \n",
       "10         1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "11         2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "12         0  LinearSVC          NMF 50  0.815190  0.663338   0.1   \n",
       "13         1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "14         2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "15         0  LinearSVC          NMF 50  0.785185  0.598151   0.1   \n",
       "16         1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "17         2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "18         0  LinearSVC          NMF 50  0.815190  0.663338   0.1   \n",
       "19         1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "20         2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "21         0  LinearSVC          NMF 50  0.785185  0.598151   0.1   \n",
       "22         1  LinearSVC          NMF 50  0.808696  0.500000   0.1   \n",
       "23         2  LinearSVC          NMF 50  0.908730  0.500000   0.1   \n",
       "24         0  LinearSVC          NMF 50  0.784119  0.600212   1.0   \n",
       "25         1  LinearSVC          NMF 50  0.808696  0.500000   1.0   \n",
       "26         2  LinearSVC          NMF 50  0.908730  0.500000   1.0   \n",
       "27         0  LinearSVC          NMF 50  0.777228  0.587421   1.0   \n",
       "28         1  LinearSVC          NMF 50  0.808696  0.500000   1.0   \n",
       "29         2  LinearSVC          NMF 50  0.900204  0.536881   1.0   \n",
       "..       ...        ...             ...       ...       ...   ...   \n",
       "42         0  LinearSVC          NMF 50  0.789474  0.580839   1.0   \n",
       "43         1  LinearSVC          NMF 50  0.808696  0.500000   1.0   \n",
       "44         2  LinearSVC          NMF 50  0.891170  0.528147   1.0   \n",
       "45         0  LinearSVC          NMF 50  0.777228  0.587421   1.0   \n",
       "46         1  LinearSVC          NMF 50  0.808696  0.500000   1.0   \n",
       "47         2  LinearSVC          NMF 50  0.900204  0.536881   1.0   \n",
       "48         0  LinearSVC          NMF 50  0.779661  0.574229  10.0   \n",
       "49         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "50         2  LinearSVC          NMF 50  0.839827  0.499668  10.0   \n",
       "51         0  LinearSVC          NMF 50  0.755556  0.551107  10.0   \n",
       "52         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "53         2  LinearSVC          NMF 50  0.826667  0.525679  10.0   \n",
       "54         0  LinearSVC          NMF 50  0.779661  0.574229  10.0   \n",
       "55         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "56         2  LinearSVC          NMF 50  0.839827  0.499668  10.0   \n",
       "57         0  LinearSVC          NMF 50  0.755556  0.551107  10.0   \n",
       "58         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "59         2  LinearSVC          NMF 50  0.826667  0.525679  10.0   \n",
       "60         0  LinearSVC          NMF 50  0.782609  0.577119  10.0   \n",
       "61         1  LinearSVC          NMF 50  0.803493  0.494624  10.0   \n",
       "62         2  LinearSVC          NMF 50  0.825893  0.534365  10.0   \n",
       "63         0  LinearSVC          NMF 50  0.755556  0.551107  10.0   \n",
       "64         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "65         2  LinearSVC          NMF 50  0.826667  0.525679  10.0   \n",
       "66         0  LinearSVC          NMF 50  0.782609  0.577119  10.0   \n",
       "67         1  LinearSVC          NMF 50  0.803493  0.494624  10.0   \n",
       "68         2  LinearSVC          NMF 50  0.825893  0.534365  10.0   \n",
       "69         0  LinearSVC          NMF 50  0.755556  0.551107  10.0   \n",
       "70         1  LinearSVC          NMF 50  0.808696  0.500000  10.0   \n",
       "71         2  LinearSVC          NMF 50  0.826667  0.525679  10.0   \n",
       "\n",
       "             loss  max_iter     multi_class  \n",
       "0           hinge      1000             ovr  \n",
       "1           hinge      1000             ovr  \n",
       "2           hinge      1000             ovr  \n",
       "3           hinge      1000  crammer_singer  \n",
       "4           hinge      1000  crammer_singer  \n",
       "5           hinge      1000  crammer_singer  \n",
       "6           hinge      1500             ovr  \n",
       "7           hinge      1500             ovr  \n",
       "8           hinge      1500             ovr  \n",
       "9           hinge      1500  crammer_singer  \n",
       "10          hinge      1500  crammer_singer  \n",
       "11          hinge      1500  crammer_singer  \n",
       "12  squared_hinge      1000             ovr  \n",
       "13  squared_hinge      1000             ovr  \n",
       "14  squared_hinge      1000             ovr  \n",
       "15  squared_hinge      1000  crammer_singer  \n",
       "16  squared_hinge      1000  crammer_singer  \n",
       "17  squared_hinge      1000  crammer_singer  \n",
       "18  squared_hinge      1500             ovr  \n",
       "19  squared_hinge      1500             ovr  \n",
       "20  squared_hinge      1500             ovr  \n",
       "21  squared_hinge      1500  crammer_singer  \n",
       "22  squared_hinge      1500  crammer_singer  \n",
       "23  squared_hinge      1500  crammer_singer  \n",
       "24          hinge      1000             ovr  \n",
       "25          hinge      1000             ovr  \n",
       "26          hinge      1000             ovr  \n",
       "27          hinge      1000  crammer_singer  \n",
       "28          hinge      1000  crammer_singer  \n",
       "29          hinge      1000  crammer_singer  \n",
       "..            ...       ...             ...  \n",
       "42  squared_hinge      1500             ovr  \n",
       "43  squared_hinge      1500             ovr  \n",
       "44  squared_hinge      1500             ovr  \n",
       "45  squared_hinge      1500  crammer_singer  \n",
       "46  squared_hinge      1500  crammer_singer  \n",
       "47  squared_hinge      1500  crammer_singer  \n",
       "48          hinge      1000             ovr  \n",
       "49          hinge      1000             ovr  \n",
       "50          hinge      1000             ovr  \n",
       "51          hinge      1000  crammer_singer  \n",
       "52          hinge      1000  crammer_singer  \n",
       "53          hinge      1000  crammer_singer  \n",
       "54          hinge      1500             ovr  \n",
       "55          hinge      1500             ovr  \n",
       "56          hinge      1500             ovr  \n",
       "57          hinge      1500  crammer_singer  \n",
       "58          hinge      1500  crammer_singer  \n",
       "59          hinge      1500  crammer_singer  \n",
       "60  squared_hinge      1000             ovr  \n",
       "61  squared_hinge      1000             ovr  \n",
       "62  squared_hinge      1000             ovr  \n",
       "63  squared_hinge      1000  crammer_singer  \n",
       "64  squared_hinge      1000  crammer_singer  \n",
       "65  squared_hinge      1000  crammer_singer  \n",
       "66  squared_hinge      1500             ovr  \n",
       "67  squared_hinge      1500             ovr  \n",
       "68  squared_hinge      1500             ovr  \n",
       "69  squared_hinge      1500  crammer_singer  \n",
       "70  squared_hinge      1500  crammer_singer  \n",
       "71  squared_hinge      1500  crammer_singer  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list,\n",
    "                             \n",
    "                           'C': C_param_list,\n",
    "                           'loss': loss_param_list,\n",
    "                           'max_iter': max_iter_param_list,\n",
    "                           'multi_class': multi_class_param_list})\n",
    "\n",
    "lsvc_results.to_csv('data/lsvc_results.csv', index=False)\n",
    "\n",
    "lsvc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression()\n",
    "\n",
    "#lr_nmf_200_model_cv1 = LogisticRegression()\n",
    "#lr_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 100 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 100 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 100 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 150 newton-cg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 150 lbfgs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 150 liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=150, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.87606406211853\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "C_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "max_iter_list = [100, 150]\n",
    "solver_list = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "#multi_class_list = ['ovr', 'multinomial']\n",
    "\n",
    "C_param_list = []\n",
    "max_iter_param_list = []\n",
    "solver_param_list = []\n",
    "#multi_class_param_list = []\n",
    "\n",
    "for C in C_list:\n",
    "    for max_iter in max_iter_list:\n",
    "        for solver in solver_list:\n",
    "            #for multi_class in multi_class_list:\n",
    "\n",
    "            print(C, max_iter, solver)\n",
    "\n",
    "            lr_nmf_200_model_cv = []\n",
    "\n",
    "            lr_nmf_200_model_cv1 = LogisticRegression(C=C, max_iter=max_iter, solver=solver)\n",
    "            lr_nmf_200_model_cv1.fit(nmf_200_x_train_cv1, y_train_cv1)\n",
    "\n",
    "            lr_nmf_200_model_cv2 = LogisticRegression(C=C, max_iter=max_iter, solver=solver)\n",
    "            lr_nmf_200_model_cv2.fit(nmf_200_x_train_cv2, y_train_cv2)\n",
    "\n",
    "            lr_nmf_200_model_cv3 = LogisticRegression(C=C, max_iter=max_iter, solver=solver)\n",
    "            lr_nmf_200_model_cv3.fit(nmf_200_x_train_cv3, y_train_cv3)\n",
    "\n",
    "            lr_nmf_200_model_cv.append(lr_nmf_200_model_cv1)\n",
    "            lr_nmf_200_model_cv.append(lr_nmf_200_model_cv2)\n",
    "            lr_nmf_200_model_cv.append(lr_nmf_200_model_cv3)\n",
    "\n",
    "            for i in range(3):\n",
    "                cv_list.append(i)\n",
    "                model_list.append('LogisticRegression')\n",
    "                preproc_list.append('NMF 200')\n",
    "                f1_list.append(f1_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "                auc_list.append(roc_auc_score(y_test_cv[i], lr_nmf_200_model_cv[i].predict(nmf_200_x_test_cv[i])))\n",
    "\n",
    "                C_param_list.append(C)\n",
    "                max_iter_param_list.append(max_iter)\n",
    "                solver_param_list.append(solver)\n",
    "                #multi_class_param_list.append(multi_class)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Model</th>\n",
       "      <th>Features Method</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>C</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.774049</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.589510</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.589510</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.504035</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.589510</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.504035</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>0.589510</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>100.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.567218</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.501709</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.780723</td>\n",
       "      <td>0.572168</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.819599</td>\n",
       "      <td>0.510442</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.780723</td>\n",
       "      <td>0.572168</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.501709</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>100</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.567218</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.501709</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.567218</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.814318</td>\n",
       "      <td>0.506076</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.780723</td>\n",
       "      <td>0.572168</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.489553</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NMF 200</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.501709</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>150</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data Set               Model Features Method  F1-score   AUC ROC  \\\n",
       "0           0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "1           1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "2           2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "3           0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "4           1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "5           2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "6           0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "7           1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "8           2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "9           0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "10          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "11          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "12          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "13          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "14          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "15          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "16          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "17          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "18          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "19          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "20          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "21          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "22          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "23          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "24          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "25          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "26          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "27          0  LogisticRegression         NMF 200  0.774049  0.500000   \n",
       "28          1  LogisticRegression         NMF 200  0.808696  0.500000   \n",
       "29          2  LogisticRegression         NMF 200  0.908730  0.500000   \n",
       "..        ...                 ...             ...       ...       ...   \n",
       "96          0  LogisticRegression         NMF 200  0.798100  0.589510   \n",
       "97          1  LogisticRegression         NMF 200  0.806100  0.497312   \n",
       "98          2  LogisticRegression         NMF 200  0.848485  0.525774   \n",
       "99          0  LogisticRegression         NMF 200  0.798100  0.589510   \n",
       "100         1  LogisticRegression         NMF 200  0.806100  0.497312   \n",
       "101         2  LogisticRegression         NMF 200  0.844828  0.504035   \n",
       "102         0  LogisticRegression         NMF 200  0.798100  0.589510   \n",
       "103         1  LogisticRegression         NMF 200  0.806100  0.497312   \n",
       "104         2  LogisticRegression         NMF 200  0.844828  0.504035   \n",
       "105         0  LogisticRegression         NMF 200  0.798100  0.589510   \n",
       "106         1  LogisticRegression         NMF 200  0.806100  0.497312   \n",
       "107         2  LogisticRegression         NMF 200  0.848485  0.525774   \n",
       "108         0  LogisticRegression         NMF 200  0.778846  0.567218   \n",
       "109         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "110         2  LogisticRegression         NMF 200  0.808989  0.501709   \n",
       "111         0  LogisticRegression         NMF 200  0.780723  0.572168   \n",
       "112         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "113         2  LogisticRegression         NMF 200  0.819599  0.510442   \n",
       "114         0  LogisticRegression         NMF 200  0.780723  0.572168   \n",
       "115         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "116         2  LogisticRegression         NMF 200  0.808989  0.501709   \n",
       "117         0  LogisticRegression         NMF 200  0.778846  0.567218   \n",
       "118         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "119         2  LogisticRegression         NMF 200  0.808989  0.501709   \n",
       "120         0  LogisticRegression         NMF 200  0.778846  0.567218   \n",
       "121         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "122         2  LogisticRegression         NMF 200  0.814318  0.506076   \n",
       "123         0  LogisticRegression         NMF 200  0.780723  0.572168   \n",
       "124         1  LogisticRegression         NMF 200  0.794702  0.489553   \n",
       "125         2  LogisticRegression         NMF 200  0.808989  0.501709   \n",
       "\n",
       "            C  max_iter     solver  \n",
       "0       0.001       100  newton-cg  \n",
       "1       0.001       100  newton-cg  \n",
       "2       0.001       100  newton-cg  \n",
       "3       0.001       100      lbfgs  \n",
       "4       0.001       100      lbfgs  \n",
       "5       0.001       100      lbfgs  \n",
       "6       0.001       100  liblinear  \n",
       "7       0.001       100  liblinear  \n",
       "8       0.001       100  liblinear  \n",
       "9       0.001       150  newton-cg  \n",
       "10      0.001       150  newton-cg  \n",
       "11      0.001       150  newton-cg  \n",
       "12      0.001       150      lbfgs  \n",
       "13      0.001       150      lbfgs  \n",
       "14      0.001       150      lbfgs  \n",
       "15      0.001       150  liblinear  \n",
       "16      0.001       150  liblinear  \n",
       "17      0.001       150  liblinear  \n",
       "18      0.010       100  newton-cg  \n",
       "19      0.010       100  newton-cg  \n",
       "20      0.010       100  newton-cg  \n",
       "21      0.010       100      lbfgs  \n",
       "22      0.010       100      lbfgs  \n",
       "23      0.010       100      lbfgs  \n",
       "24      0.010       100  liblinear  \n",
       "25      0.010       100  liblinear  \n",
       "26      0.010       100  liblinear  \n",
       "27      0.010       150  newton-cg  \n",
       "28      0.010       150  newton-cg  \n",
       "29      0.010       150  newton-cg  \n",
       "..        ...       ...        ...  \n",
       "96    100.000       100  liblinear  \n",
       "97    100.000       100  liblinear  \n",
       "98    100.000       100  liblinear  \n",
       "99    100.000       150  newton-cg  \n",
       "100   100.000       150  newton-cg  \n",
       "101   100.000       150  newton-cg  \n",
       "102   100.000       150      lbfgs  \n",
       "103   100.000       150      lbfgs  \n",
       "104   100.000       150      lbfgs  \n",
       "105   100.000       150  liblinear  \n",
       "106   100.000       150  liblinear  \n",
       "107   100.000       150  liblinear  \n",
       "108  1000.000       100  newton-cg  \n",
       "109  1000.000       100  newton-cg  \n",
       "110  1000.000       100  newton-cg  \n",
       "111  1000.000       100      lbfgs  \n",
       "112  1000.000       100      lbfgs  \n",
       "113  1000.000       100      lbfgs  \n",
       "114  1000.000       100  liblinear  \n",
       "115  1000.000       100  liblinear  \n",
       "116  1000.000       100  liblinear  \n",
       "117  1000.000       150  newton-cg  \n",
       "118  1000.000       150  newton-cg  \n",
       "119  1000.000       150  newton-cg  \n",
       "120  1000.000       150      lbfgs  \n",
       "121  1000.000       150      lbfgs  \n",
       "122  1000.000       150      lbfgs  \n",
       "123  1000.000       150  liblinear  \n",
       "124  1000.000       150  liblinear  \n",
       "125  1000.000       150  liblinear  \n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pd.DataFrame({'Data Set': cv_list,\n",
    "                           'Model': model_list,\n",
    "                           'Features Method': preproc_list,\n",
    "                           'F1-score': f1_list,\n",
    "                           'AUC ROC': auc_list,\n",
    "                             \n",
    "                           'C': C_param_list,\n",
    "                           'max_iter': max_iter_param_list,\n",
    "                           'solver': solver_param_list})\n",
    "\n",
    "lr_results.to_csv('data/lr_results.csv', index=False)\n",
    "\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_unigrams_model_cv1.get_params()\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['gini', 'entropy'], ['auto', 'sqrt', 'log2'], [500]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_list = []\n",
    "model_list = []\n",
    "preproc_list = []\n",
    "f1_list = []\n",
    "auc_list = []\n",
    "\n",
    "\n",
    "eta_list = [0.05, 0.1, 0.2, 0.3]\n",
    "max_depth = [3, 6, 9]\n",
    "\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_unigrams_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_50_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_100_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_200_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_ensemble_model trained\n",
      "finished. time elapsed: 224.63 sec\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "################## PART 6 ##################\n",
    "############################################\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "# set basic classifier parameters, fit classifiers. \n",
    "# Hint: initialize new basic classifier before new training process\n",
    "\n",
    "# example: basic_classifier_params = {}\n",
    "#          basic_classifier = BasicClassifier(**basic_classifier_params)\n",
    "\n",
    "\n",
    "# 1. Unigrams\n",
    "# example: rf_unigrams_model = ...\n",
    "# ...\n",
    "#basic_classifier = BasicClassifier(**basic_classifier_params)\n",
    "#clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "#                             min_samples_split=2, random_state=0)\n",
    "rf_unigrams_model = RandomForestClassifier(n_estimators=2000)\n",
    "rf_unigrams_model.fit(unigrams_train_features, y_train)\n",
    "#print(clf.feature_importances_)\n",
    "#scores = cross_val_score(clf, X, y, cv=5)\n",
    "#scores.mean()\n",
    "print('rf_unigrams_model trained')\n",
    "\n",
    "# 2. NMF 50\n",
    "rf_nmf_50_model = RandomForestClassifier(n_estimators=2000)\n",
    "rf_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "\n",
    "print('rf_nmf_50_model trained')\n",
    "\n",
    "# 3. NMF 100\n",
    "rf_nmf_100_model = RandomForestClassifier(n_estimators=2000)\n",
    "rf_nmf_100_model.fit(nmf_100_x_train, y_train)\n",
    "\n",
    "print('rf_nmf_100_model trained')\n",
    "\n",
    "# 4. NMF 200\n",
    "rf_nmf_200_model = RandomForestClassifier(n_estimators=2000)\n",
    "rf_nmf_200_model.fit(nmf_200_x_train, y_train)\n",
    "\n",
    "print('rf_nmf_200_model trained')\n",
    "\n",
    "# 5. Ensemble\n",
    "rf_ensemble_model = RandomForestClassifier(n_estimators=2000)\n",
    "rf_ensemble_model.fit(ensemble_x_train, y_train)\n",
    "\n",
    "print('rf_ensemble_model trained')\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_unigrams_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_50_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_100_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_nmf_200_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_ensemble_model trained\n",
      "finished. time elapsed: 2.68 sec\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "# 1. Unigrams\n",
    "rf_unigrams_model = RandomForestClassifier()\n",
    "rf_unigrams_model.fit(unigrams_train_features, y_train)\n",
    "print('rf_unigrams_model trained')\n",
    "\n",
    "# 2. NMF 50\n",
    "rf_nmf_50_model = RandomForestClassifier()\n",
    "rf_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "print('rf_nmf_50_model trained')\n",
    "\n",
    "# 3. NMF 100\n",
    "rf_nmf_100_model = RandomForestClassifier()\n",
    "rf_nmf_100_model.fit(nmf_100_x_train, y_train)\n",
    "print('rf_nmf_100_model trained')\n",
    "\n",
    "# 4. NMF 200\n",
    "rf_nmf_200_model = RandomForestClassifier()\n",
    "rf_nmf_200_model.fit(nmf_200_x_train, y_train)\n",
    "print('rf_nmf_200_model trained')\n",
    "\n",
    "# 5. Ensemble\n",
    "rf_ensemble_model = RandomForestClassifier()\n",
    "rf_ensemble_model.fit(ensemble_x_train, y_train)\n",
    "print('rf_ensemble_model trained')\n",
    "\n",
    "print('finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_unigrams_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_nmf_50_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_nmf_100_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_nmf_200_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_ensemble_model trained\n",
      "Finished. time elapsed: 195.43 sec\n"
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "\n",
    "# 6. Unigrams\n",
    "xgb_unigrams_model = XGBClassifier()\n",
    "xgb_unigrams_model.fit(unigrams_train_features, y_train)\n",
    "print('xgb_unigrams_model trained')\n",
    "\n",
    "# 7. NMF 50\n",
    "xgb_nmf_50_model = XGBClassifier()\n",
    "xgb_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "print('xgb_nmf_50_model trained')\n",
    "\n",
    "# 8. NMF 100\n",
    "xgb_nmf_100_model = XGBClassifier()\n",
    "xgb_nmf_100_model.fit(nmf_100_x_train, y_train)\n",
    "print('xgb_nmf_100_model trained')\n",
    "\n",
    "# 9. NMF 200\n",
    "xgb_nmf_200_model = XGBClassifier()\n",
    "xgb_nmf_200_model.fit(nmf_200_x_train, y_train)\n",
    "print('xgb_nmf_200_model trained')\n",
    "\n",
    "# 10. Ensemble\n",
    "xgb_ensemble_model = XGBClassifier()\n",
    "xgb_ensemble_model.fit(ensemble_x_train, y_train)\n",
    "print('xgb_ensemble_model trained')\n",
    "\n",
    "print('Finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_unigrams_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_nmf_50_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_nmf_100_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_nmf_200_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_ensemble_model trained\n",
      "Finished. time elapsed: 1.58 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "# 11. Unigrams\n",
    "lr_unigrams_model = LogisticRegression()\n",
    "lr_unigrams_model.fit(unigrams_train_features, y_train)\n",
    "print('lr_unigrams_model trained')\n",
    "\n",
    "# 12. NMF 50\n",
    "lr_nmf_50_model = LogisticRegression()\n",
    "lr_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "print('lr_nmf_50_model trained')\n",
    "\n",
    "# 13. NMF 100\n",
    "lr_nmf_100_model = LogisticRegression()\n",
    "lr_nmf_100_model.fit(nmf_100_x_train, y_train)\n",
    "print('lr_nmf_100_model trained')\n",
    "\n",
    "# 14. NMF 200\n",
    "lr_nmf_200_model = LogisticRegression()\n",
    "lr_nmf_200_model.fit(nmf_200_x_train, y_train)\n",
    "print('lr_nmf_200_model trained')\n",
    "\n",
    "# 15. Ensemble\n",
    "lr_ensemble_model = LogisticRegression()\n",
    "lr_ensemble_model.fit(ensemble_x_train, y_train)\n",
    "print('lr_ensemble_model trained')\n",
    "\n",
    "print('Finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvc_unigrams_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvc_nmf_50_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvc_nmf_100_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvc_nmf_200_model trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsvc_ensemble_model trained\n",
      "Finished. time elapsed: 2.14 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "# 16. Unigrams\n",
    "lsvc_unigrams_model = LinearSVC()\n",
    "lsvc_unigrams_model.fit(unigrams_train_features, y_train)\n",
    "print('lsvc_unigrams_model trained')\n",
    "\n",
    "# 17. NMF 50\n",
    "lsvc_nmf_50_model = LinearSVC()\n",
    "lsvc_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "print('lsvc_nmf_50_model trained')\n",
    "\n",
    "# 18. NMF 100\n",
    "lsvc_nmf_100_model = LinearSVC()\n",
    "lsvc_nmf_100_model.fit(nmf_100_x_train, y_train)\n",
    "print('lsvc_nmf_100_model trained')\n",
    "\n",
    "# 19. NMF 200\n",
    "lsvc_nmf_200_model = LinearSVC()\n",
    "lsvc_nmf_200_model.fit(nmf_200_x_train, y_train)\n",
    "print('lsvc_nmf_200_model trained')\n",
    "\n",
    "# 20. Ensemble\n",
    "lsvc_ensemble_model = LinearSVC()\n",
    "lsvc_ensemble_model.fit(ensemble_x_train, y_train)\n",
    "print('lsvc_ensemble_model trained')\n",
    "\n",
    "print('Finished. time elapsed: %.2f sec' % (time.time() - time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50      STAY\n",
       "51      MOVE\n",
       "52      STAY\n",
       "53      MOVE\n",
       "54      STAY\n",
       "55      MOVE\n",
       "56      STAY\n",
       "57      MOVE\n",
       "58      MOVE\n",
       "59      STAY\n",
       "60      STAY\n",
       "61      MOVE\n",
       "62      MOVE\n",
       "63      MOVE\n",
       "64      MOVE\n",
       "146     STAY\n",
       "147     MOVE\n",
       "148     MOVE\n",
       "149     MOVE\n",
       "150     STAY\n",
       "151     MOVE\n",
       "152     MOVE\n",
       "153     STAY\n",
       "154     STAY\n",
       "155     MOVE\n",
       "156     MOVE\n",
       "157     STAY\n",
       "158     STAY\n",
       "159     STAY\n",
       "160     MOVE\n",
       "        ... \n",
       "3099    STAY\n",
       "3100    STAY\n",
       "3101    STAY\n",
       "3102    MOVE\n",
       "3103    MOVE\n",
       "3104    MOVE\n",
       "3105    MOVE\n",
       "3106    MOVE\n",
       "3107    STAY\n",
       "3108    STAY\n",
       "3109    STAY\n",
       "3110    STAY\n",
       "3111    STAY\n",
       "3112    MOVE\n",
       "3113    STAY\n",
       "3114    STAY\n",
       "3115    STAY\n",
       "3116    STAY\n",
       "3117    STAY\n",
       "3118    STAY\n",
       "3119    MOVE\n",
       "3120    STAY\n",
       "3121    STAY\n",
       "3122    STAY\n",
       "3123    MOVE\n",
       "3124    MOVE\n",
       "3125    STAY\n",
       "3126    STAY\n",
       "3127    STAY\n",
       "3128    STAY\n",
       "Name: label, Length: 396, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST \n",
      "\n",
      "rf_unigrams_model\n",
      "0.7008547008547009\n",
      "0.6340909090909091\n",
      "\n",
      "\n",
      "rf_nmf_50_model\n",
      "0.6918238993710694\n",
      "0.6136363636363636\n",
      "\n",
      "\n",
      "rf_nmf_100_model\n",
      "0.6590909090909091\n",
      "0.6460227272727272\n",
      "\n",
      "\n",
      "rf_nmf_200_model\n",
      "0.6338383838383839\n",
      "0.6215909090909091\n",
      "\n",
      "\n",
      "rf_ensemble_model\n",
      "0.6388888888888888\n",
      "0.6278409090909091\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#\n",
    "# RANDOM FOREST\n",
    "#\n",
    "\n",
    "print('RANDOM FOREST \\n')\n",
    "\n",
    "print('rf_unigrams_model')\n",
    "#print(accuracy_score(y_val, rf_unigrams_model.predict(unigrams_val_features)))\n",
    "print(      f1_score(y_val, rf_unigrams_model.predict(unigrams_val_features)))  #, average='micro'\n",
    "print( roc_auc_score(y_val, rf_unigrams_model.predict(unigrams_val_features)))\n",
    "print('\\n')\n",
    "\n",
    "print('rf_nmf_50_model')\n",
    "#print(accuracy_score(y_val, rf_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print(      f1_score(y_val, rf_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print( roc_auc_score(y_val, rf_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print('\\n')\n",
    "\n",
    "print('rf_nmf_100_model')\n",
    "#print(accuracy_score(y_val, rf_nmf_100_model.predict(nmf_100_x_val)))\n",
    "print(      f1_score(y_val, rf_nmf_100_model.predict(nmf_100_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, rf_nmf_100_model.predict(nmf_100_x_val)))\n",
    "print('\\n')\n",
    "\n",
    "print('rf_nmf_200_model')\n",
    "#print(accuracy_score(y_val, rf_nmf_200_model.predict(nmf_200_x_val)))\n",
    "print(      f1_score(y_val, rf_nmf_200_model.predict(nmf_200_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, rf_nmf_200_model.predict(nmf_200_x_val)))\n",
    "print('\\n')\n",
    "\n",
    "print('rf_ensemble_model')\n",
    "#print(accuracy_score(y_val, rf_ensemble_model.predict(ensemble_x_val)))\n",
    "print(      f1_score(y_val, rf_ensemble_model.predict(ensemble_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, rf_ensemble_model.predict(ensemble_x_val)))\n",
    "print('\\n')\n",
    "\n",
    "#\n",
    "# XGBOOST\n",
    "#\n",
    "\n",
    "print('XGBOOST \\n')\n",
    "\n",
    "print('xgb_unigrams_model')\n",
    "print(accuracy_score(y_val, xgb_unigrams_model.predict(unigrams_val_features)))\n",
    "print(      f1_score(y_val, xgb_unigrams_model.predict(unigrams_val_features), average='micro'))\n",
    "print( roc_auc_score(y_val, xgb_unigrams_model.predict(unigrams_val_features)))\n",
    "\n",
    "print('xgb_nmf_50_model')\n",
    "print(accuracy_score(y_val, xgb_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print(      f1_score(y_val, xgb_nmf_50_model.predict(nmf_50_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, xgb_nmf_50_model.predict(nmf_50_x_val)))\n",
    "\n",
    "print('xgb_nmf_100_model')\n",
    "print(accuracy_score(y_val, xgb_nmf_100_model.predict(nmf_100_x_val)))\n",
    "print(      f1_score(y_val, xgb_nmf_100_model.predict(nmf_100_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, xgb_nmf_100_model.predict(nmf_100_x_val)))\n",
    "\n",
    "print('xgb_nmf_200_model')\n",
    "print(accuracy_score(y_val, xgb_nmf_200_model.predict(nmf_200_x_val)))\n",
    "print(      f1_score(y_val, xgb_nmf_200_model.predict(nmf_200_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, xgb_nmf_200_model.predict(nmf_200_x_val)))\n",
    "\n",
    "print('xgb_ensemble_model')\n",
    "print(accuracy_score(y_val, xgb_ensemble_model.predict(ensemble_x_val)))\n",
    "print(      f1_score(y_val, xgb_ensemble_model.predict(ensemble_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, xgb_ensemble_model.predict(ensemble_x_val)))\n",
    "\n",
    "#\n",
    "# LOGISTIC REGRESSION\n",
    "#\n",
    "\n",
    "print('LOGISTIC REGRESSION \\n')\n",
    "\n",
    "print('lr_unigrams_model')\n",
    "print(accuracy_score(y_val, lr_unigrams_model.predict(unigrams_val_features)))\n",
    "print(      f1_score(y_val, lr_unigrams_model.predict(unigrams_val_features), average='micro'))\n",
    "print( roc_auc_score(y_val, lr_unigrams_model.predict(unigrams_val_features)))\n",
    "\n",
    "print('lr_nmf_50_model')\n",
    "print(accuracy_score(y_val, lr_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print(      f1_score(y_val, lr_nmf_50_model.predict(nmf_50_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lr_nmf_50_model.predict(nmf_50_x_val)))\n",
    "\n",
    "print('lr_nmf_100_model')\n",
    "print(accuracy_score(y_val, lr_nmf_100_model.predict(nmf_100_x_val)))\n",
    "print(      f1_score(y_val, lr_nmf_100_model.predict(nmf_100_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lr_nmf_100_model.predict(nmf_100_x_val)))\n",
    "\n",
    "print('lr_nmf_200_model')\n",
    "print(accuracy_score(y_val, lr_nmf_200_model.predict(nmf_200_x_val)))\n",
    "print(      f1_score(y_val, lr_nmf_200_model.predict(nmf_200_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lr_nmf_200_model.predict(nmf_200_x_val)))\n",
    "\n",
    "print('lr_ensemble_model')\n",
    "print(accuracy_score(y_val, lr_ensemble_model.predict(ensemble_x_val)))\n",
    "print(      f1_score(y_val, lr_ensemble_model.predict(ensemble_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lr_ensemble_model.predict(ensemble_x_val)))\n",
    "\n",
    "#\n",
    "# LINEAR SUPPORT VECTOR CLASSIFIER\n",
    "#\n",
    "\n",
    "print('LINEAR SUPPORT VECTOR CLASSIFIER \\n')\n",
    "\n",
    "print('lsvc_unigrams_model')\n",
    "print(accuracy_score(y_val, lsvc_unigrams_model.predict(unigrams_val_features)))\n",
    "print(      f1_score(y_val, lsvc_unigrams_model.predict(unigrams_val_features), average='micro'))\n",
    "print( roc_auc_score(y_val, lsvc_unigrams_model.predict(unigrams_val_features)))\n",
    "\n",
    "print('lsvc_nmf_50_model')\n",
    "print(accuracy_score(y_val, lsvc_nmf_50_model.predict(nmf_50_x_val)))\n",
    "print(      f1_score(y_val, lsvc_nmf_50_model.predict(nmf_50_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lsvc_nmf_50_model.predict(nmf_50_x_val)))\n",
    "\n",
    "print('lsvc_nmf_100_model')\n",
    "print(accuracy_score(y_val, lsvc_nmf_100_model.predict(nmf_100_x_val)))\n",
    "print(      f1_score(y_val, lsvc_nmf_100_model.predict(nmf_100_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lsvc_nmf_100_model.predict(nmf_100_x_val)))\n",
    "\n",
    "print('lsvc_nmf_200_model')\n",
    "print(accuracy_score(y_val, lsvc_nmf_200_model.predict(nmf_200_x_val)))\n",
    "print(      f1_score(y_val, lsvc_nmf_200_model.predict(nmf_200_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lsvc_nmf_200_model.predict(nmf_200_x_val)))\n",
    "\n",
    "print('lsvc_ensemble_model')\n",
    "print(accuracy_score(y_val, lsvc_ensemble_model.predict(ensemble_x_val)))\n",
    "print(      f1_score(y_val, lsvc_ensemble_model.predict(ensemble_x_val), average='micro'))\n",
    "print( roc_auc_score(y_val, lsvc_ensemble_model.predict(ensemble_x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38222222222222224"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import zero_one_loss\n",
    "zero_one_loss(y_val, rf_unigrams_model.predict(unigrams_val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 2000,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_nmf_50_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rf_nmf_50_model = RandomForestClassifier(n_estimators=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "rf_nmf_50_model.fit(nmf_50_x_train, y_train)\n",
    "CV_rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [500, 1000, 1500, 2000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 617.9883468151093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    #'criterion': ['gini', 'entropy'],\n",
    "    #'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [500, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "#rf_nmf_50_model = RandomForestClassifier(n_estimators=2000)\n",
    "CV_rfc = GridSearchCV(estimator=rf_unigrams_model, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(unigrams_train_features, y_train)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [500]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.77916264533997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "time_ = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    #'criterion': ['gini', 'entropy'],\n",
    "    #'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "\n",
    "#rf_nmf_50_model = RandomForestClassifier(n_estimators=2000)\n",
    "CV_rfc = GridSearchCV(estimator=rf_unigrams_model, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(unigrams_train_features, y_train)\n",
    "\n",
    "print('time:', time.time() - time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_.get_params()\n",
    "#grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6488888888888888"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, CV_rfc.predict(unigrams_val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF quality calculated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>n_features</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf_unigrams_model</td>\n",
       "      <td>16274</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_nmf_50_model</td>\n",
       "      <td>16324</td>\n",
       "      <td>0.648889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf_nmf_100_model</td>\n",
       "      <td>16374</td>\n",
       "      <td>0.648889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_nmf_200_model</td>\n",
       "      <td>16474</td>\n",
       "      <td>0.648889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf_ensemble_model</td>\n",
       "      <td>16624</td>\n",
       "      <td>0.648889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  n_features  accuracy\n",
       "0  rf_unigrams_model       16274  0.613333\n",
       "1    rf_nmf_50_model       16324  0.648889\n",
       "2   rf_nmf_100_model       16374  0.648889\n",
       "3   rf_nmf_200_model       16474  0.648889\n",
       "4  rf_ensemble_model       16624  0.648889"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "################## PART 7 ##################\n",
    "############################################\n",
    "\n",
    "# calculate quality measures\n",
    "\n",
    "# 1. Unigrams\n",
    "# example: rf_unigrams_quality = Quality(y_true, y_pred)\n",
    "rf_unigrams_quality = accuracy_score(y_val, rf_unigrams_model.predict(unigrams_val_features))\n",
    "\n",
    "# 2. NMF 50\n",
    "rf_nmf_50_quality = accuracy_score(y_val, rf_nmf_50_model.predict(nmf_50_x_val))\n",
    "\n",
    "# 3. NMF 100\n",
    "rf_nmf_100_quality = accuracy_score(y_val, rf_nmf_100_model.predict(nmf_100_x_val))\n",
    "\n",
    "# 4. NMF 200\n",
    "rf_nmf_200_quality = accuracy_score(y_val, rf_nmf_200_model.predict(nmf_200_x_val))\n",
    "\n",
    "# 5. Ensemble\n",
    "rf_ensemble_quality = accuracy_score(y_val, rf_ensemble_model.predict(ensemble_x_val))\n",
    "\n",
    "print('RF quality calculated')\n",
    "\n",
    "# # 6. Unigrams\n",
    "# xgb_unigrams_quality = accuracy_score(y_val, xgb_unigrams_model.predict(unigrams_val_features))\n",
    "\n",
    "# # 7. NMF 50\n",
    "# xgb_nmf_50_quality = accuracy_score(y_val, xgb_nmf_50_model.predict(nmf_50_x_val))\n",
    "\n",
    "# # 8. NMF 100\n",
    "# xgb_nmf_100_quality = accuracy_score(y_val, xgb_nmf_100_model.predict(nmf_100_x_val))\n",
    "\n",
    "# # 9. NMF 200\n",
    "# xgb_nmf_200_quality = accuracy_score(y_val, xgb_nmf_200_model.predict(nmf_200_x_val))\n",
    "\n",
    "# # 10. Ensemble\n",
    "# xgb_ensemble_quality = accuracy_score(y_val, xgb_ensemble_model.predict(ensemble_x_val))\n",
    "\n",
    "# print('XGB quality calculated')\n",
    "\n",
    "# save results\n",
    "results = pd.DataFrame({'model': ['rf_unigrams_model', 'rf_nmf_50_model', \n",
    "                                  'rf_nmf_100_model', 'rf_nmf_200_model', 'rf_ensemble_model'],\n",
    "                                 #'xgb_unigrams_model', 'xgb_nmf_50_model',\n",
    "                                 #'xgb_nmf_100_model', 'xgb_nmf_200_model', 'xgb_ensemble_model'], \n",
    "                        'n_features': [rf_unigrams_model.n_features_, rf_nmf_50_model.n_features_, \n",
    "                                       rf_nmf_100_model.n_features_, rf_nmf_200_model.n_features_, \n",
    "                                       rf_ensemble_model.n_features_],\n",
    "                                       #xgb_unigrams_model.feature_importances_.shape[0],\n",
    "                                       #xgb_nmf_50_model.feature_importances_.shape[0],\n",
    "                                       #xgb_nmf_100_model.feature_importances_.shape[0],\n",
    "                                       #xgb_nmf_200_model.feature_importances_.shape[0],\n",
    "                                       #xgb_ensemble_model.feature_importances_.shape[0]], \n",
    "                        'accuracy': [rf_unigrams_quality, rf_nmf_50_quality, \n",
    "                                     rf_nmf_100_quality, rf_nmf_200_quality, rf_ensemble_quality]},\n",
    "                                     #xgb_unigrams_quality, xgb_nmf_50_quality, \n",
    "                                     #xgb_nmf_100_quality, xgb_nmf_200_quality, xgb_ensemble_quality]}, \n",
    "                       columns=['model', 'n_features', 'accuracy'])\n",
    "results.to_csv('data/results12.csv', index=False)\n",
    "\n",
    "# results.csv no param\n",
    "# results2.csv min_df=3\n",
    "# results3.csv min_df=5  BEST\n",
    "### results4.csv min_df=3 max_df=0.5\n",
    "### results5.csv min_df=3 max_df=0.75\n",
    "# results6.csv min_df=5  BEST\n",
    "# results7.csv min_df=5, max_df=0.5\n",
    "# results8.csv min_df=5, max_df=0.75\n",
    "# results9.csv min_df=3 max_df=0.75\n",
    "# results10.csv min_df=3 max_df=0.5\n",
    "\n",
    "# results11.csv max_df=0.75\n",
    "# results12.csv max_df=0.5\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
